<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Computing Out-of-Sample Predicted Probabilities with Cross-Validation" href="pred_probs_cross_val.html" /><link rel="prev" title="Improve Consensus Labels for Multiannotator Data" href="multiannotator.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/a4483476d449f2f05a4c7cde329e72358099cc07/cleanlab/cleanlab_favicon.svg"/><meta name="generator" content="sphinx-5.1.1, furo 2022.06.21"/>
        <title>Find Label Errors in Token Classification (Text) Datasets - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a style="padding-bottom: 0px;" class="sidebar-brand centered" href="../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo" />
    </div>
    
    <span style="margin-bottom:0px" class="sidebar-brand-text">
        cleanlab
    </span>
    
</a>

<div class="centered">
    <a style="margin-top: 6px;" class="github-button" href="https://github.com/cleanlab/cleanlab" data-size="large" data-show-count="true"
    aria-label="Star cleanlab/cleanlab on GitHub">Star</a>
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="indepth_overview.html">The Workflows of Data-centric AI for Classification with Noisy Labels</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">Image Classification with PyTorch and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="text.html">Text Classification with TensorFlow, Keras, and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="tabular.html">Classification with Tabular Data using Scikit-Learn and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio.html">Audio Classification with SpeechBrain and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_health.html">Find Dataset-level Issues for Dataset Curation</a></li>
<li class="toctree-l1"><a class="reference internal" href="outliers.html">Detect Outliers with Cleanlab and PyTorch Image Models (timm)</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiannotator.html">Improve Consensus Labels for Multiannotator Data</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Find Label Errors in Token Classification (Text) Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_probs_cross_val.html">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/count.html">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/dataset.html">dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/outlier.html">outlier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/multiannotator.html">multiannotator</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/token_classification/index.html">token_classification</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/benchmarking/index.html">benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/benchmarking/noise_generation.html">noise_generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/experimental/index.html">experimental</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/keras.html">keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/fasttext.html">fasttext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/mnist_pytorch.html">mnist_pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/coteaching.html">coteaching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/cifar_cnn.html">cifar_cnn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/label_quality_utils.html">label_quality_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/token_classification_utils.html">token_classification_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/validation.html">validation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migrating/migrate_v2.html">Migrating to v2.x</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/master/"
                >developer</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.1.0"
                class="reference internal"
                href="/v2.1.0/"
                >v2.1.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.0.0"
                class="reference internal"
                href="/v2.0.0/"
                >v2.0.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v1.0.1"
                class="reference internal"
                href="/v1.0.1/"
                >v1.0.1</a
            >
        </li>
        
    </ul>
</div>

<br>
<br>

<script
    type="text/javascript"
    src="/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number) && !path_arr.includes("stable")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">v2.1.0</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }

    .output_area {
        max-height: 300px;
        overflow: auto;
    }

    .dataframe {
        background: #D7D7D7;
    }

    th {
        color:black;
    }
</style>

<script type="text/javascript">
    window.addEventListener('load', () => {
        const h1_element = document.getElementsByTagName("h1");
        h1_element[0].insertAdjacentHTML("afterend", `
        <p>
            <a style="background-color:white;color:black;padding:4px 12px;text-decoration:none;display:inline-block;border-radius:8px;box-shadow:0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 3px 10px 0 rgba(0, 0, 0, 0.19)" href="https://colab.research.google.com/github/cleanlab/cleanlab-docs/blob/master/v2.1.0/tutorials/token_classification.ipynb" target="_blank">
            <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="" style="width:40px;height:40px;vertical-align:middle">
            <span style="vertical-align:middle">Run in Google Colab</span>
            </a>
        </p>
        `);
    })

</script><section id="Find-Label-Errors-in-Token-Classification-(Text)-Datasets">
<h1>Find Label Errors in Token Classification (Text) Datasets<a class="headerlink" href="#Find-Label-Errors-in-Token-Classification-(Text)-Datasets" title="Permalink to this heading">#</a></h1>
<p>This tutorial shows how you can use cleanlab to find potential label errors in text datasets for token classification . In token-classification, our data consists of a bunch of sentences (aka documents) in which every token (aka word) is labeled with one of K classes, and we train models to predict the class of each token in a new sentence. Example applications in NLP include part-of-speech-tagging or entity recognition, which is the focus on this tutorial. Here we use the <a class="reference external" href="https://deepai.org/dataset/conll-2003-english">CoNLL-2003 named
entity recognition</a> dataset which contains around 20,000 sentences with 300,000 individual tokens. Each token is labeled with one of the following classes:</p>
<ul class="simple">
<li><p>LOC (location entity)</p></li>
<li><p>PER (person entity)</p></li>
<li><p>ORG (organization entity)</p></li>
<li><p>MISC (miscellaneous other type of entity)</p></li>
<li><p>O (other type of word that does not correspond to an entity)</p></li>
</ul>
<p><strong>Overview of what we’ll do in this tutorial:</strong></p>
<ul class="simple">
<li><p>Find tokens with label issues using <code class="docutils literal notranslate"><span class="pre">cleanlab.token_classification.filter.find_label_issues</span></code>.</p></li>
<li><p>Rank sentences based on their overall label quality using <code class="docutils literal notranslate"><span class="pre">cleanlab.token_classification.rank.get_label_quality_scores</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Quickstart</p>
<p>cleanlab uses three inputs to handle token classification data:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tokens</span></code>: List whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th element is a list of strings/words corresponding to tokenized version of the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence in dataset. Example: <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">[&quot;I&quot;,</span> <span class="pre">&quot;love&quot;,</span> <span class="pre">&quot;cleanlab&quot;],</span> <span class="pre">...]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labels</span></code>: List whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th element is a list of integers corresponding to class labels of each token in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence. Example: <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">1],</span> <span class="pre">...]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pred_probs</span></code>: List whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th element is a np.ndarray of shape <code class="docutils literal notranslate"><span class="pre">(N_i,</span> <span class="pre">K)</span></code> corresponding to predicted class probabilities for each token in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence (assuming this sentence contains <code class="docutils literal notranslate"><span class="pre">N_i</span></code> tokens and dataset has <code class="docutils literal notranslate"><span class="pre">K</span></code> possible classes). These should be out-of-sample <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> obtained from a token classification model via cross-validation. Example: <code class="docutils literal notranslate"><span class="pre">[...,</span> <span class="pre">np.array([[0.8,0.2],</span> <span class="pre">[0.9,0.1],</span> <span class="pre">[0.3,0.7]]),</span> <span class="pre">...]</span></code></p></li>
</ul>
<p>Using these, you can find/display label issues with this code:</p>
<div class="markdown" style="background:white;margin:16px"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cleanlab.token_classification.filter</span> <span class="kn">import</span> <span class="n">find_label_issues</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.summary</span> <span class="kn">import</span> <span class="n">display_issues</span>

<span class="n">issues</span> <span class="o">=</span> <span class="n">find_label_issues</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>
<span class="n">display_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">class_names</span><span class="o">=</span><span class="n">OPTIONAL_LIST_OF_ORDERED_CLASS_NAMES</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div><section id="1.-Install-required-dependencies-and-download-data">
<h2>1. Install required dependencies and download data<a class="headerlink" href="#1.-Install-required-dependencies-and-download-data" title="Permalink to this heading">#</a></h2>
<p>You can use <code class="docutils literal notranslate"><span class="pre">pip</span></code> to install all packages required for this tutorial as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>!pip install cleanlab
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget -nc https://data.deepai.org/conll2003.zip <span class="o">&amp;&amp;</span> mkdir data
<span class="o">!</span>unzip conll2003.zip -d data/ <span class="o">&amp;&amp;</span> rm conll2003.zip
<span class="o">!</span>wget -nc <span class="s1">&#39;https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz&#39;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2022-10-03 18:51:58--  https://data.deepai.org/conll2003.zip
Resolving data.deepai.org (data.deepai.org)... 5.9.140.253
Connecting to data.deepai.org (data.deepai.org)|5.9.140.253|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 982975 (960K) [application/x-zip-compressed]
Saving to: ‘conll2003.zip’

conll2003.zip       100%[===================&gt;] 959.94K  1.99MB/s    in 0.5s

2022-10-03 18:51:59 (1.99 MB/s) - ‘conll2003.zip’ saved [982975/982975]

mkdir: cannot create directory ‘data’: File exists
Archive:  conll2003.zip
  inflating: data/metadata
  inflating: data/test.txt
  inflating: data/train.txt
  inflating: data/valid.txt
--2022-10-03 18:52:00--  https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz
Resolving cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)... 52.217.77.236
Connecting to cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)|52.217.77.236|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17045998 (16M) [binary/octet-stream]
Saving to: ‘pred_probs.npz’

pred_probs.npz      100%[===================&gt;]  16.26M  37.9MB/s    in 0.4s

2022-10-03 18:52:00 (37.9 MB/s) - ‘pred_probs.npz’ saved [17045998/17045998]

</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.filter</span> <span class="kn">import</span> <span class="n">find_label_issues</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.rank</span> <span class="kn">import</span> <span class="n">get_label_quality_scores</span><span class="p">,</span> <span class="n">issues_from_scores</span>
<span class="kn">from</span> <span class="nn">cleanlab.internal.token_classification_utils</span> <span class="kn">import</span> <span class="n">get_sentence</span><span class="p">,</span> <span class="n">filter_sentence</span><span class="p">,</span> <span class="n">mapping</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.summary</span> <span class="kn">import</span> <span class="n">display_issues</span><span class="p">,</span> <span class="n">common_label_issues</span><span class="p">,</span> <span class="n">filter_by_token</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="2.-Get-data,-labels,-and-pred_probs">
<h2>2. Get data, labels, and pred_probs<a class="headerlink" href="#2.-Get-data,-labels,-and-pred_probs" title="Permalink to this heading">#</a></h2>
<p>In token classification tasks, each token in the dataset is labeled with one of <em>K</em> possible classes. To find label issues, cleanlab requires predicted class probabilities from a trained classifier. These <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> contain a length-<em>K</em> vector for <strong>each</strong> token in the dataset (which sums to 1 for each token). Here we use <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> which are out-of-sample predicted class probabilities for the full CoNLL-2003 dataset (merging training, development, and testing splits), obtained from a
BERT Transformer fit via cross-validation. Our example notebook <a class="reference external" href="https://github.com/cleanlab/examples/blob/master/entity_recognition/entity_recognition_training.ipynb">“Training Entity Recognition Model for Token Classification”</a> contains the code to produce such <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and save them in a <code class="docutils literal notranslate"><span class="pre">.npz</span></code> file, which we simply load here via a <code class="docutils literal notranslate"><span class="pre">read_npz</span></code> function (can skip these details).</p>
<details><summary><p>See the code for reading the <code class="docutils literal notranslate"><span class="pre">.npz</span></code> file <strong>(click to expand)</strong></p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.</span>

<span class="k">def</span> <span class="nf">read_npz</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">data</span>
</pre></div>
</div>
</details><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_probs</span> <span class="o">=</span> <span class="n">read_npz</span><span class="p">(</span><span class="s1">&#39;pred_probs.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> is a list of numpy arrays, which we’ll describe later. Let’s first also load the dataset and its labels. We collect sentences from the original text files defining:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tokens</span></code> as a nested list where <code class="docutils literal notranslate"><span class="pre">tokens[i]</span></code> is a list of strings corrsesponding to a (word-level) tokenized version of the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">given_labels</span></code> as a nested list of the given labels in the dataset where <code class="docutils literal notranslate"><span class="pre">given_labels[i]</span></code> is a list of labels for each token in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence.</p></li>
</ul>
<p>This version of CoNLL-2003 uses IOB2-formatting for tagging, where <code class="docutils literal notranslate"><span class="pre">B-</span></code> and <code class="docutils literal notranslate"><span class="pre">I-</span></code> prefixes in the class labels indicate whether the tokens are at the start of an entity or in the middle. We ignore these distinctions in this tutorial (as label errors that confuse <code class="docutils literal notranslate"><span class="pre">B-</span></code> and <code class="docutils literal notranslate"><span class="pre">I-</span></code> are less interesting), and thus have two sets of entities:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">given_entities</span></code> = [‘O’, ‘B-MISC’, ‘I-MISC’, ‘B-PER’, ‘I-PER’, ‘B-ORG’, ‘I-ORG’, ‘B-LOC’, ‘I-LOC’]</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entities</span></code> = [‘O’, ‘MISC’, ‘PER’, ‘ORG’, ‘LOC’]. These are our classes of interest for the token classification task.</p></li>
</ul>
<p>We use some helper methods to load the CoNLL data (can skip these details).</p>
<details><summary><p>See the code for reading the CoNLL data files <strong>(click to expand)</strong></p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.</span>

<span class="n">given_entities</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;O&#39;</span><span class="p">,</span> <span class="s1">&#39;B-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;B-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;I-PER&#39;</span><span class="p">,</span> <span class="s1">&#39;B-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;I-ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;B-LOC&#39;</span><span class="p">,</span> <span class="s1">&#39;I-LOC&#39;</span><span class="p">]</span>
<span class="n">entities</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;O&#39;</span><span class="p">,</span> <span class="s1">&#39;MISC&#39;</span><span class="p">,</span> <span class="s1">&#39;PER&#39;</span><span class="p">,</span> <span class="s1">&#39;ORG&#39;</span><span class="p">,</span> <span class="s1">&#39;LOC&#39;</span><span class="p">]</span>
<span class="n">entity_map</span> <span class="o">=</span> <span class="p">{</span><span class="n">entity</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">entity</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">given_entities</span><span class="p">)}</span>

<span class="k">def</span> <span class="nf">readfile</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;-DOCSTART&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sentence</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>
                <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="k">continue</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sep</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span><span class="o">.</span><span class="n">isupper</span><span class="p">():</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">label</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entity_map</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sentence</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>

    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="n">given_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">given_labels</span>
</pre></div>
</div>
</details><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filepaths</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;data/train.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;data/valid.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;data/test.txt&#39;</span><span class="p">]</span>
<span class="n">tokens</span><span class="p">,</span> <span class="n">given_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">:</span>
    <span class="n">words</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">readfile</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="n">tokens</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">given_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">get_sentence</span><span class="p">,</span> <span class="n">tokens</span><span class="p">))</span>

<span class="n">sentences</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">filter_sentence</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">words</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>
<span class="n">given_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">given_labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>

<span class="n">maps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">mapping</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">maps</span><span class="p">)</span> <span class="k">for</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">given_labels</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>To find label issues in token classification data, cleanlab requires <code class="docutils literal notranslate"><span class="pre">labels</span></code> and <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code>, which should look as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indices_to_preview</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># increase this to view more examples</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">indices_to_preview</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">sentences[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;labels[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;pred_probs[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

sentences[0]:   Eu rejects German call to boycott British lamb.
labels[0]:      [3, 0, 1, 0, 0, 0, 1, 0, 0]
pred_probs[0]:
[[0.00030412 0.00023826 0.99936208 0.00007009 0.00002545]
 [0.99998795 0.00000401 0.00000218 0.00000455 0.00000131]
 [0.00000749 0.99996115 0.00001371 0.0000087  0.00000895]
 [0.99998936 0.00000382 0.00000178 0.00000366 0.00000137]
 [0.99999101 0.00000266 0.00000174 0.0000035  0.00000109]
 [0.99998768 0.00000482 0.00000202 0.00000438 0.0000011 ]
 [0.00000465 0.99996392 0.00001105 0.0000116  0.00000878]
 [0.99998671 0.00000364 0.00000213 0.00000472 0.00000281]
 [0.99999073 0.00000211 0.00000159 0.00000442 0.00000115]]

sentences[1]:   Peter Blackburn
labels[1]:      [2, 2]
pred_probs[1]:
[[0.00000358 0.00000529 0.99995623 0.000022   0.0000129 ]
 [0.0000024  0.00001812 0.99994141 0.00001645 0.00002162]]

sentences[2]:   Brussels 1996-08-22
labels[2]:      [4, 0]
pred_probs[2]:
[[0.00001172 0.00000821 0.00004661 0.0000618  0.99987167]
 [0.99999061 0.00000201 0.00000195 0.00000408 0.00000135]]
</pre></div></div>
</div>
<p>Note that these correspond to the sentences in the dataset, where each sentence is treated as an individual training example (could be document instead of sentence). If using your own dataset, both <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code> should each be formatted as a nested-list where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> is a list whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th element is a np.ndarray of shape <code class="docutils literal notranslate"><span class="pre">(N_i,</span> <span class="pre">K)</span></code> corresponding to predicted class probabilities for each token in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence (assuming this sentence contains <code class="docutils literal notranslate"><span class="pre">N_i</span></code> tokens and dataset has <code class="docutils literal notranslate"><span class="pre">K</span></code> possible classes). Each row of one np.ndarray corresponds to a token <code class="docutils literal notranslate"><span class="pre">t</span></code> and contains a model’s predicted probability that <code class="docutils literal notranslate"><span class="pre">t</span></code> belongs to each possible class, for each of the K classes. The columns must be ordered such that the probabilities
correspond to class 0, 1, …, K-1. These should be out-of-sample <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> obtained from a token classification model via cross-validation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labels</span></code> is a list whose <code class="docutils literal notranslate"><span class="pre">i</span></code>-th element is a list of integers corresponding to class label of each token in the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence. For dataset with K classes, labels must take values in 0, 1, …, K-1.</p></li>
</ul>
</section>
<section id="3.-Use-cleanlab-to-find-label-issues">
<h2>3. Use cleanlab to find label issues<a class="headerlink" href="#3.-Use-cleanlab-to-find-label-issues" title="Permalink to this heading">#</a></h2>
<p>Based on the given labels and out-of-sample predicted probabilities, cleanlab can quickly help us identify label issues in our dataset. Here we request that the indices of the identified label issues be sorted by cleanlab’s self-confidence score, which measures the quality of each given label via the probability assigned to it in our model’s prediction. The returned <code class="docutils literal notranslate"><span class="pre">issues</span></code> are a list of tuples <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code>, which corresponds to the <code class="docutils literal notranslate"><span class="pre">j</span></code>th token of the <code class="docutils literal notranslate"><span class="pre">i</span></code>-th sentence in the dataset. These
are the tokens cleanlab thinks may be badly labeled in your dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">issues</span> <span class="o">=</span> <span class="n">find_label_issues</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s look at the top 20 tokens that cleanlab thinks are most likely mislabeled.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># increase this value to view more identified issues</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cleanlab found </span><span class="si">%d</span><span class="s1"> potential label issues. &#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">issues</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The top </span><span class="si">%d</span><span class="s1"> most likely label errors:&#39;</span> <span class="o">%</span> <span class="n">top</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">issues</span><span class="p">[:</span><span class="n">top</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cleanlab found 2255 potential label issues.
The top 20 most likely label errors:
[(2907, 0), (19392, 0), (9962, 4), (8904, 30), (19303, 0), (12918, 0), (9256, 0), (11855, 20), (18392, 4), (20426, 28), (19402, 21), (14744, 15), (19371, 0), (4645, 2), (83, 9), (10331, 3), (9430, 10), (6143, 25), (18367, 0), (12914, 3)]
</pre></div></div>
</div>
<p>We can better decide how to handle these issues by viewing the original sentences containing these tokens. Given that <code class="docutils literal notranslate"><span class="pre">O</span></code> and <code class="docutils literal notranslate"><span class="pre">MISC</span></code> classes (corresponding to integers 0 and 1 in our class ordering) can sometimes be ambiguous, they are excluded from our visualization below. This is achieved via the <code class="docutils literal notranslate"><span class="pre">exclude</span></code> argument, a list of tuples <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> such that tokens predicted as <code class="docutils literal notranslate"><span class="pre">entities[j]</span></code> but labeled as <code class="docutils literal notranslate"><span class="pre">entities[i]</span></code> are ignored.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 2907, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Little</span> change from today&#39;s weather expected.


Sentence 19392, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Let</span>&#39;s march together,&#34; Scalfaro, a northerner himself, said.


Sentence 9962, token 4:
Given label: LOC, predicted label according to provided pred_probs: O
----
3. Nastja Rysich (<span class="ansi-red-fg">germany</span>) 3.75


Sentence 8904, token 30:
Given label: LOC, predicted label according to provided pred_probs: O
----
The Spla has fought Khartoum&#39;s government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised <span class="ansi-red-fg">north</span>.


Sentence 12918, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Mayor</span> Antonio Gonzalez Garcia, of the opposition Revolutionary Workers&#39; Party, said in Wednesday&#39;s letter that army troops recently raided several local farms, stole cattle and raped women.


Sentence 9256, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Spring</span> Chg Hrw 12pct Chg White Chg


Sentence 11855, token 20:
Given label: PER, predicted label according to provided pred_probs: O
----
&#34; We have seen the photos but for the moment the palace has no comment,&#34; a spokeswoman for <span class="ansi-red-fg">Prince</span> Rainier told Reuters.


Sentence 18392, token 4:
Given label: O, predicted label according to provided pred_probs: LOC
----
Danila 28.5 16<span class="ansi-red-fg">/</span>12 Caribs/ up W224 Mobil.


Sentence 19402, token 21:
Given label: ORG, predicted label according to provided pred_probs: O
----
A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next <span class="ansi-red-fg">Wednesday</span>.


Sentence 83, token 9:
Given label: LOC, predicted label according to provided pred_probs: O
----
Listing London Denoms (K) 1-10-100 Sale Limits <span class="ansi-red-fg">Us</span>/ Uk/ Jp/ Fr


Sentence 10331, token 3:
Given label: O, predicted label according to provided pred_probs: ORG
----
Hapoel Haifa 3 <span class="ansi-red-fg">Maccabi</span> Tel Aviv 1


Sentence 9430, token 10:
Given label: LOC, predicted label according to provided pred_probs: O
----
The revered Roman Catholic nun was admitted to the Calcutta <span class="ansi-red-fg">hospital</span> a week ago with high fever and severe vomiting.


Sentence 6143, token 25:
Given label: ORG, predicted label according to provided pred_probs: O
----
The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council <span class="ansi-red-fg">alliance</span> led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.


Sentence 18367, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Can</span>/ U.s. Dollar Exchange Rate: 1.3570


Sentence 12049, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Born</span> in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.


Sentence 16764, token 7:
Given label: PER, predicted label according to provided pred_probs: O
----
1990 - British historian Alan John Percivale <span class="ansi-red-fg">(</span>A.j.p.) Taylor died.


Sentence 20446, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Pace</span> bowler Ian Harvey claimed three for 81 for Victoria.


Sentence 15514, token 16:
Given label: O, predicted label according to provided pred_probs: PER
----
But one must not forget that the Osce only has limited powers there,&#34; said <span class="ansi-red-fg">Cotti</span>, who is also the Swiss foreign minister.&#34;


Sentence 7525, token 12:
Given label: PER, predicted label according to provided pred_probs: O
----
Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince <span class="ansi-red-fg">Sultan</span> in Jeddah, Saudi state television and the official Saudi Press Agency reported.


Sentence 2288, token 0:
Given label: ORG, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Sporting</span> his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada&#39;s reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.
</pre></div></div>
</div>
<p>More than half of the potential label issues correspond to tokens that are incorrectly labeled. As shown above, some examples are ambigious and may require more thoughful handling. cleanlab has also discovered some edge cases such as tokens which are simply punctuations such as <code class="docutils literal notranslate"><span class="pre">/</span></code> and <code class="docutils literal notranslate"><span class="pre">(</span></code>.</p>
<section id="Most-common-word-level-token-mislabels">
<h3>Most common word-level token mislabels<a class="headerlink" href="#Most-common-word-level-token-mislabels" title="Permalink to this heading">#</a></h3>
<p>We may also wish to understand which tokens tend to be most commonly mislabeled throughout the entire dataset:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">info</span> <span class="o">=</span> <span class="n">common_label_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span>
                           <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                           <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span>
                           <span class="n">class_names</span><span class="o">=</span><span class="n">entities</span><span class="p">,</span>
                           <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Token &#39;/&#39; is potentially mislabeled 42 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `LOC` 36 times
labeled as class `O` but predicted to actually be class `PER` 4 times
labeled as class `O` but predicted to actually be class `ORG` 2 times

Token &#39;Chicago&#39; is potentially mislabeled 27 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 22 times
labeled as class `LOC` but predicted to actually be class `ORG` 3 times
labeled as class `MISC` but predicted to actually be class `ORG` 2 times

Token &#39;U.s.&#39; is potentially mislabeled 21 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `LOC` but predicted to actually be class `ORG` 8 times
labeled as class `ORG` but predicted to actually be class `LOC` 6 times
labeled as class `LOC` but predicted to actually be class `O` 3 times
labeled as class `LOC` but predicted to actually be class `MISC` 2 times
labeled as class `MISC` but predicted to actually be class `LOC` 1 times
labeled as class `MISC` but predicted to actually be class `ORG` 1 times

Token &#39;Digest&#39; is potentially mislabeled 20 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `ORG` 20 times

Token &#39;Press&#39; is potentially mislabeled 20 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `ORG` 20 times

Token &#39;New&#39; is potentially mislabeled 17 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 13 times
labeled as class `LOC` but predicted to actually be class `ORG` 2 times
labeled as class `O` but predicted to actually be class `ORG` 1 times
labeled as class `MISC` but predicted to actually be class `LOC` 1 times

Token &#39;and&#39; is potentially mislabeled 16 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `O` 7 times
labeled as class `O` but predicted to actually be class `ORG` 5 times
labeled as class `O` but predicted to actually be class `LOC` 3 times
labeled as class `MISC` but predicted to actually be class `ORG` 1 times

Token &#39;Philadelphia&#39; is potentially mislabeled 15 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 14 times
labeled as class `LOC` but predicted to actually be class `ORG` 1 times

Token &#39;Usda&#39; is potentially mislabeled 13 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 7 times
labeled as class `ORG` but predicted to actually be class `PER` 5 times
labeled as class `ORG` but predicted to actually be class `MISC` 1 times

Token &#39;York&#39; is potentially mislabeled 12 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 11 times
labeled as class `LOC` but predicted to actually be class `ORG` 1 times

</pre></div></div>
</div>
<p>The printed information above is also stored in pd.DataFrame <code class="docutils literal notranslate"><span class="pre">info</span></code>.</p>
</section>
<section id="Find-issue-sentences-with-particular-word">
<h3>Find issue sentences with particular word<a class="headerlink" href="#Find-issue-sentences-with-particular-word" title="Permalink to this heading">#</a></h3>
<p>You can also only focus on the subset of potentially problematic sentences where a particular token may have been mislabeled.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">token_issues</span> <span class="o">=</span> <span class="n">filter_by_token</span><span class="p">(</span><span class="s1">&#39;United&#39;</span><span class="p">,</span> <span class="n">issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>

<span class="n">display_issues</span><span class="p">(</span><span class="n">token_issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 471, token 8:
Given label: LOC, predicted label according to provided pred_probs: ORG
----
Soccer - Keane Signs Four-year Contract With Manchester <span class="ansi-red-fg">United</span>.


Sentence 19072, token 5:
Given label: LOC, predicted label according to provided pred_probs: ORG
----
The Humane Society of the <span class="ansi-red-fg">United</span> States estimates that between 500,000 and one million bites are delivered by dogs each year, more than half of which are suffered by children.


Sentence 19910, token 5:
Given label: LOC, predicted label according to provided pred_probs: ORG
----
His father Clarence Woolmer represented <span class="ansi-red-fg">United</span> Province, now renamed Uttar Pradesh, in India&#39;s Ranji Trophy national championship and captained the state during 1949.


Sentence 15658, token 0:
Given label: ORG, predicted label according to provided pred_probs: LOC
----
<span class="ansi-red-fg">United</span> Nations 1996-08-29


Sentence 19879, token 1:
Given label: ORG, predicted label according to provided pred_probs: LOC
----
1. <span class="ansi-red-fg">United</span> States Iii (Brian Shimer, Randy Jones) one


Sentence 19104, token 0:
Given label: ORG, predicted label according to provided pred_probs: LOC
----
<span class="ansi-red-fg">United</span> Nations 1996-12-06
</pre></div></div>
</div>
</section>
<section id="Sentence-label-quality-score">
<h3>Sentence label quality score<a class="headerlink" href="#Sentence-label-quality-score" title="Permalink to this heading">#</a></h3>
<p>For best reviewing label issues in a token classification dataset, you want to look at sentences one at a time. Here sentences more likely to contain a label error should be ranked earlier. Cleanlab can provide an overall label quality score for each sentence (ranging from 0 to 1) such that lower scores indicate sentences more likely to contain some mislabeled token. We can also obtain label quality scores for each individual token and decide which of these are label issues by thresholding them.
This may be a superior approach if high precision (or high recall) is specifically preferred for your label error detection.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentence_scores</span><span class="p">,</span> <span class="n">token_scores</span> <span class="o">=</span> <span class="n">get_label_quality_scores</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>
<span class="n">issues</span> <span class="o">=</span> <span class="n">issues_from_scores</span><span class="p">(</span><span class="n">sentence_scores</span><span class="p">,</span> <span class="n">token_scores</span><span class="o">=</span><span class="n">token_scores</span><span class="p">)</span>
<span class="n">display_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 2907, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Little</span> change from today&#39;s weather expected.


Sentence 19392, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Let</span>&#39;s march together,&#34; Scalfaro, a northerner himself, said.


Sentence 9962, token 4:
Given label: LOC, predicted label according to provided pred_probs: O
----
3. Nastja Rysich (<span class="ansi-red-fg">germany</span>) 3.75


Sentence 8904, token 30:
Given label: LOC, predicted label according to provided pred_probs: O
----
The Spla has fought Khartoum&#39;s government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised <span class="ansi-red-fg">north</span>.


Sentence 12918, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Mayor</span> Antonio Gonzalez Garcia, of the opposition Revolutionary Workers&#39; Party, said in Wednesday&#39;s letter that army troops recently raided several local farms, stole cattle and raped women.


Sentence 9256, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Spring</span> Chg Hrw 12pct Chg White Chg


Sentence 11855, token 20:
Given label: PER, predicted label according to provided pred_probs: O
----
&#34; We have seen the photos but for the moment the palace has no comment,&#34; a spokeswoman for <span class="ansi-red-fg">Prince</span> Rainier told Reuters.


Sentence 18392, token 4:
Given label: O, predicted label according to provided pred_probs: LOC
----
Danila 28.5 16<span class="ansi-red-fg">/</span>12 Caribs/ up W224 Mobil.


Sentence 19402, token 21:
Given label: ORG, predicted label according to provided pred_probs: O
----
A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next <span class="ansi-red-fg">Wednesday</span>.


Sentence 83, token 9:
Given label: LOC, predicted label according to provided pred_probs: O
----
Listing London Denoms (K) 1-10-100 Sale Limits <span class="ansi-red-fg">Us</span>/ Uk/ Jp/ Fr


Sentence 10331, token 3:
Given label: O, predicted label according to provided pred_probs: ORG
----
Hapoel Haifa 3 <span class="ansi-red-fg">Maccabi</span> Tel Aviv 1


Sentence 9430, token 10:
Given label: LOC, predicted label according to provided pred_probs: O
----
The revered Roman Catholic nun was admitted to the Calcutta <span class="ansi-red-fg">hospital</span> a week ago with high fever and severe vomiting.


Sentence 6143, token 25:
Given label: ORG, predicted label according to provided pred_probs: O
----
The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council <span class="ansi-red-fg">alliance</span> led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.


Sentence 18367, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Can</span>/ U.s. Dollar Exchange Rate: 1.3570


Sentence 12049, token 0:
Given label: LOC, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Born</span> in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.


Sentence 16764, token 7:
Given label: PER, predicted label according to provided pred_probs: O
----
1990 - British historian Alan John Percivale <span class="ansi-red-fg">(</span>A.j.p.) Taylor died.


Sentence 20446, token 0:
Given label: PER, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Pace</span> bowler Ian Harvey claimed three for 81 for Victoria.


Sentence 15514, token 16:
Given label: O, predicted label according to provided pred_probs: PER
----
But one must not forget that the Osce only has limited powers there,&#34; said <span class="ansi-red-fg">Cotti</span>, who is also the Swiss foreign minister.&#34;


Sentence 7525, token 12:
Given label: PER, predicted label according to provided pred_probs: O
----
Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince <span class="ansi-red-fg">Sultan</span> in Jeddah, Saudi state television and the official Saudi Press Agency reported.


Sentence 2288, token 0:
Given label: ORG, predicted label according to provided pred_probs: O
----
<span class="ansi-red-fg">Sporting</span> his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada&#39;s reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.
</pre></div></div>
</div>
</section>
</section>
</section>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          <a class="next-page" href="pred_probs_cross_val.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="multiannotator.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Improve Consensus Labels for Multiannotator Data</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Find Label Errors in Token Classification (Text) Datasets</a><ul>
<li><a class="reference internal" href="#1.-Install-required-dependencies-and-download-data">1. Install required dependencies and download data</a></li>
<li><a class="reference internal" href="#2.-Get-data,-labels,-and-pred_probs">2. Get data, labels, and pred_probs</a></li>
<li><a class="reference internal" href="#3.-Use-cleanlab-to-find-label-issues">3. Use cleanlab to find label issues</a><ul>
<li><a class="reference internal" href="#Most-common-word-level-token-mislabels">Most common word-level token mislabels</a></li>
<li><a class="reference internal" href="#Find-issue-sentences-with-particular-word">Find issue sentences with particular word</a></li>
<li><a class="reference internal" href="#Sentence-label-quality-score">Sentence label quality score</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>