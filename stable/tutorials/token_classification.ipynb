{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d2e007",
   "metadata": {},
   "source": [
    "# Find Label Errors in Token Classification (Text) Datasets\n",
    "\n",
    "This tutorial shows how you can use cleanlab to find potential label errors in text datasets for token classification . In token-classification, our data consists of a bunch of sentences (aka documents) in which every token (aka word) is labeled with one of K classes, and we train models to predict the class of each token in a new sentence. Example applications in NLP include part-of-speech-tagging or entity recognition, which is the focus on this tutorial. Here we use the [CoNLL-2003 named entity recognition](https://deepai.org/dataset/conll-2003-english) dataset which contains around 20,000 sentences with 300,000 individual tokens. Each token is labeled with one of the following classes:\n",
    "\n",
    "- LOC (location entity)\n",
    "- PER (person entity)\n",
    "- ORG (organization entity)\n",
    "- MISC (miscellaneous other type of entity)\n",
    "- O (other type of word that does not correspond to an entity)\n",
    "\n",
    "**Overview of what we'll do in this tutorial:** \n",
    "\n",
    "- Find tokens with label issues using `cleanlab.token_classification.filter.find_label_issues`. \n",
    "- Rank sentences based on their overall label quality using `cleanlab.token_classification.rank.get_label_quality_scores`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07936a54",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "cleanlab uses three inputs to handle token classification data:\n",
    "\n",
    "- `tokens`: List whose `i`-th element is a list of strings/words corresponding to tokenized version of the `i`-th sentence in dataset. \n",
    "    Example: `[..., [\"I\", \"love\", \"cleanlab\"], ...]`\n",
    "- `labels`: List whose `i`-th element is a list of integers corresponding to class labels of each token in the `i`-th sentence. Example: `[..., [0, 0, 1], ...]`\n",
    "- `pred_probs`: List whose `i`-th element is a np.ndarray of shape `(N_i, K)` corresponding to predicted class probabilities for each token in the `i`-th sentence (assuming this sentence contains `N_i` tokens and dataset has `K` possible classes). These should be out-of-sample `pred_probs` obtained from a token classification model via cross-validation. \n",
    "    Example: `[..., np.array([[0.8,0.2], [0.9,0.1], [0.3,0.7]]), ...]`\n",
    "\n",
    "Using these, you can find/display label issues with this code: \n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.token_classification.filter import find_label_issues \n",
    "from cleanlab.token_classification.summary import display_issues\n",
    "    \n",
    "issues = find_label_issues(labels, pred_probs)\n",
    "display_issues(issues, tokens, pred_probs=pred_probs, labels=labels,\n",
    "               class_names=OPTIONAL_LIST_OF_ORDERED_CLASS_NAMES)\n",
    "\n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da020bc",
   "metadata": {},
   "source": [
    "## 1. Install required dependencies and download data\n",
    "\n",
    "You can use `pip` to install all packages required for this tutorial as follows: \n",
    "\n",
    "    !pip install cleanlab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8a08e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:51:58.639212Z",
     "iopub.status.busy": "2022-10-03T18:51:58.638744Z",
     "iopub.status.idle": "2022-10-03T18:52:00.926326Z",
     "shell.execute_reply": "2022-10-03T18:52:00.925045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-03 18:51:58--  https://data.deepai.org/conll2003.zip\r\n",
      "Resolving data.deepai.org (data.deepai.org)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.9.140.253\r\n",
      "Connecting to data.deepai.org (data.deepai.org)|5.9.140.253|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 982975 (960K) [application/x-zip-compressed]\r\n",
      "Saving to: ‘conll2003.zip’\r\n",
      "\r\n",
      "\r",
      "conll2003.zip         0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "conll2003.zip        22%[===>                ] 215.44K   763KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "conll2003.zip       100%[===================>] 959.94K  1.99MB/s    in 0.5s    \r\n",
      "\r\n",
      "2022-10-03 18:51:59 (1.99 MB/s) - ‘conll2003.zip’ saved [982975/982975]\r\n",
      "\r\n",
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  conll2003.zip\r\n",
      "  inflating: data/metadata           \r\n",
      "  inflating: data/test.txt           \r\n",
      "  inflating: data/train.txt          \r\n",
      "  inflating: data/valid.txt          \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-03 18:52:00--  https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz\r\n",
      "Resolving cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)... 52.217.77.236\r\n",
      "Connecting to cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)|52.217.77.236|:443... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 17045998 (16M) [binary/octet-stream]\r\n",
      "Saving to: ‘pred_probs.npz’\r\n",
      "\r\n",
      "\r",
      "pred_probs.npz        0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "pred_probs.npz        5%[>                   ] 840.64K  3.91MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "pred_probs.npz       90%[=================>  ]  14.74M  35.4MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "pred_probs.npz      100%[===================>]  16.26M  37.9MB/s    in 0.4s    \r\n",
      "\r\n",
      "2022-10-03 18:52:00 (37.9 MB/s) - ‘pred_probs.npz’ saved [17045998/17045998]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://data.deepai.org/conll2003.zip && mkdir data \n",
    "!unzip conll2003.zip -d data/ && rm conll2003.zip \n",
    "!wget -nc 'https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439b0305",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:00.930583Z",
     "iopub.status.busy": "2022-10-03T18:52:00.930181Z",
     "iopub.status.idle": "2022-10-03T18:52:01.514788Z",
     "shell.execute_reply": "2022-10-03T18:52:01.513744Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "\n",
    "dependencies = [\"cleanlab\"]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install cleanlab==v2.1.0\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")\n",
    "\n",
    "# Supress outputs that may appear if tensorflow happens to be improperly installed: \n",
    "import os \n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1349304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:01.518855Z",
     "iopub.status.busy": "2022-10-03T18:52:01.518244Z",
     "iopub.status.idle": "2022-10-03T18:52:01.527977Z",
     "shell.execute_reply": "2022-10-03T18:52:01.527387Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cleanlab.token_classification.filter import find_label_issues \n",
    "from cleanlab.token_classification.rank import get_label_quality_scores, issues_from_scores \n",
    "from cleanlab.internal.token_classification_utils import get_sentence, filter_sentence, mapping \n",
    "from cleanlab.token_classification.summary import display_issues, common_label_issues, filter_by_token \n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad75b45",
   "metadata": {},
   "source": [
    "## 2. Get data, labels, and pred_probs\n",
    "\n",
    "In token classification tasks, each token in the dataset is labeled with one of *K* possible classes.\n",
    "To find label issues, cleanlab requires predicted class probabilities from a trained classifier. These `pred_probs` contain a length-*K* vector for **each** token in the dataset (which sums to 1 for each token).  Here we use `pred_probs` which are out-of-sample predicted class probabilities for the full CoNLL-2003 dataset (merging training, development, and testing splits), obtained from a BERT Transformer fit via cross-validation. Our example notebook [\"Training Entity Recognition Model for Token Classification\"](https://github.com/cleanlab/examples/blob/master/entity_recognition/entity_recognition_training.ipynb) contains the code to produce such `pred_probs` and save them in a `.npz` file, which we simply load here via a `read_npz` function (can skip these details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc832fd",
   "metadata": {},
   "source": [
    "<details><summary>See the code for reading the `.npz` file **(click to expand)**</summary> \n",
    "\n",
    "```python\n",
    "# Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "def read_npz(filepath): \n",
    "    data = dict(np.load(filepath)) \n",
    "    data = [data[str(i)] for i in range(len(data))] \n",
    "    return data \n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9d59a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:01.531488Z",
     "iopub.status.busy": "2022-10-03T18:52:01.531137Z",
     "iopub.status.idle": "2022-10-03T18:52:01.535823Z",
     "shell.execute_reply": "2022-10-03T18:52:01.535248Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "def read_npz(filepath): \n",
    "    data = dict(np.load(filepath)) \n",
    "    data = [data[str(i)] for i in range(len(data))] \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519cb80c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:01.538992Z",
     "iopub.status.busy": "2022-10-03T18:52:01.538484Z",
     "iopub.status.idle": "2022-10-03T18:52:15.634025Z",
     "shell.execute_reply": "2022-10-03T18:52:15.633337Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_probs = read_npz('pred_probs.npz') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8136f37",
   "metadata": {},
   "source": [
    "`pred_probs` is a list of numpy arrays, which we'll describe later. Let's first also load the dataset and its labels. We collect sentences from the original text files defining: \n",
    "\n",
    "- `tokens` as a nested list where `tokens[i]` is a list of strings corrsesponding to a (word-level) tokenized version of the `i`-th sentence\n",
    "- `given_labels` as a nested list of the given labels in the dataset where `given_labels[i]` is a list of labels for each token in the `i`-th sentence. \n",
    "\n",
    "This version of CoNLL-2003 uses IOB2-formatting for tagging, where `B-` and `I-` prefixes in the class labels indicate whether the tokens are at the start of an entity or in the middle. We ignore these distinctions in this tutorial (as label errors that confuse `B-` and `I-` are less interesting), and thus have two sets of entities: \n",
    "\n",
    "- `given_entities` = ['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']  \n",
    "- `entities` = ['O', 'MISC', 'PER', 'ORG', 'LOC']. These are our classes of interest for the token classification task.\n",
    "\n",
    "We use some helper methods to load the CoNLL data (can skip these details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a87745",
   "metadata": {},
   "source": [
    "<details><summary>See the code for reading the CoNLL data files **(click to expand)**</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "# Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "given_entities = ['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "entities = ['O', 'MISC', 'PER', 'ORG', 'LOC'] \n",
    "entity_map = {entity: i for i, entity in enumerate(given_entities)} \n",
    "\n",
    "def readfile(filepath, sep=' '): \n",
    "    lines = open(filepath)\n",
    "    data, sentence, label = [], [], []\n",
    "    for line in lines:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == '\\n':\n",
    "            if len(sentence) > 0:\n",
    "                data.append((sentence, label))\n",
    "                sentence, label = [], []\n",
    "            continue\n",
    "        splits = line.split(sep) \n",
    "        word = splits[0]\n",
    "        if len(word) > 0 and word[0].isalpha() and word.isupper():\n",
    "            word = word[0] + word[1:].lower()\n",
    "        sentence.append(word)\n",
    "        label.append(entity_map[splits[-1][:-1]])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        data.append((sentence, label))\n",
    "\n",
    "    tokens = [d[0] for d in data] \n",
    "    given_labels = [d[1] for d in data]\n",
    "    return tokens, given_labels\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202f1526",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:15.637421Z",
     "iopub.status.busy": "2022-10-03T18:52:15.637189Z",
     "iopub.status.idle": "2022-10-03T18:52:15.644531Z",
     "shell.execute_reply": "2022-10-03T18:52:15.643588Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "given_entities = ['O', 'B-MISC', 'I-MISC', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n",
    "entities = ['O', 'MISC', 'PER', 'ORG', 'LOC'] \n",
    "entity_map = {entity: i for i, entity in enumerate(given_entities)} \n",
    "\n",
    "def readfile(filepath, sep=' '): \n",
    "    lines = open(filepath)\n",
    "    data, sentence, label = [], [], []\n",
    "    for line in lines:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == '\\n':\n",
    "            if len(sentence) > 0:\n",
    "                data.append((sentence, label))\n",
    "                sentence, label = [], []\n",
    "            continue\n",
    "        splits = line.split(sep) \n",
    "        word = splits[0]\n",
    "        if len(word) > 0 and word[0].isalpha() and word.isupper():\n",
    "            word = word[0] + word[1:].lower()\n",
    "        sentence.append(word)\n",
    "        label.append(entity_map[splits[-1][:-1]])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        data.append((sentence, label))\n",
    "        \n",
    "    tokens = [d[0] for d in data] \n",
    "    given_labels = [d[1] for d in data] \n",
    "    return tokens, given_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4381f03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:15.647285Z",
     "iopub.status.busy": "2022-10-03T18:52:15.646946Z",
     "iopub.status.idle": "2022-10-03T18:52:16.191546Z",
     "shell.execute_reply": "2022-10-03T18:52:16.190880Z"
    }
   },
   "outputs": [],
   "source": [
    "filepaths = ['data/train.txt', 'data/valid.txt', 'data/test.txt'] \n",
    "tokens, given_labels = [], [] \n",
    "\n",
    "for filepath in filepaths: \n",
    "    words, label = readfile(filepath) \n",
    "    tokens.extend(words) \n",
    "    given_labels.extend(label)\n",
    "    \n",
    "sentences = list(map(get_sentence, tokens)) \n",
    "\n",
    "sentences, mask = filter_sentence(sentences) \n",
    "tokens = [words for m, words in zip(mask, tokens) if m] \n",
    "given_labels = [labels for m, labels in zip(mask, given_labels) if m] \n",
    "\n",
    "maps = [0, 1, 1, 2, 2, 3, 3, 4, 4] \n",
    "labels = [mapping(labels, maps) for labels in given_labels] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb7c93",
   "metadata": {},
   "source": [
    "To find label issues in token classification data, cleanlab requires `labels` and `pred_probs`, which should look as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7842e4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:16.195007Z",
     "iopub.status.busy": "2022-10-03T18:52:16.194637Z",
     "iopub.status.idle": "2022-10-03T18:52:16.200735Z",
     "shell.execute_reply": "2022-10-03T18:52:16.200113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sentences[0]:\tEu rejects German call to boycott British lamb.\n",
      "labels[0]:\t[3, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "pred_probs[0]:\n",
      "[[0.00030412 0.00023826 0.99936208 0.00007009 0.00002545]\n",
      " [0.99998795 0.00000401 0.00000218 0.00000455 0.00000131]\n",
      " [0.00000749 0.99996115 0.00001371 0.0000087  0.00000895]\n",
      " [0.99998936 0.00000382 0.00000178 0.00000366 0.00000137]\n",
      " [0.99999101 0.00000266 0.00000174 0.0000035  0.00000109]\n",
      " [0.99998768 0.00000482 0.00000202 0.00000438 0.0000011 ]\n",
      " [0.00000465 0.99996392 0.00001105 0.0000116  0.00000878]\n",
      " [0.99998671 0.00000364 0.00000213 0.00000472 0.00000281]\n",
      " [0.99999073 0.00000211 0.00000159 0.00000442 0.00000115]]\n",
      "\n",
      "sentences[1]:\tPeter Blackburn\n",
      "labels[1]:\t[2, 2]\n",
      "pred_probs[1]:\n",
      "[[0.00000358 0.00000529 0.99995623 0.000022   0.0000129 ]\n",
      " [0.0000024  0.00001812 0.99994141 0.00001645 0.00002162]]\n",
      "\n",
      "sentences[2]:\tBrussels 1996-08-22\n",
      "labels[2]:\t[4, 0]\n",
      "pred_probs[2]:\n",
      "[[0.00001172 0.00000821 0.00004661 0.0000618  0.99987167]\n",
      " [0.99999061 0.00000201 0.00000195 0.00000408 0.00000135]]\n"
     ]
    }
   ],
   "source": [
    "indices_to_preview = 3  # increase this to view more examples\n",
    "for i in range(indices_to_preview):\n",
    "    print('\\nsentences[%d]:\\t' % i + str(sentences[i])) \n",
    "    print('labels[%d]:\\t' % i + str(labels[i])) \n",
    "    print('pred_probs[%d]:\\n' % i + str(pred_probs[i])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71eb4a",
   "metadata": {},
   "source": [
    "Note that these correspond to the sentences in the dataset, where each sentence is treated as an individual training example (could be document instead of sentence).  If using your own dataset, both `pred_probs` and `labels` should each be formatted as a nested-list where: \n",
    "\n",
    "- `pred_probs` is a list whose `i`-th element is a np.ndarray of shape `(N_i, K)` corresponding to predicted class probabilities for each token in the `i`-th sentence (assuming this sentence contains `N_i` tokens and dataset has `K` possible classes). Each row of one np.ndarray corresponds to a token `t` and contains a model's predicted probability  that `t` belongs to each possible class, for each of the K classes. The columns must be ordered such that the probabilities correspond to class 0, 1, ..., K-1. These should be out-of-sample `pred_probs` obtained from a token classification model via cross-validation. \n",
    "\n",
    "- `labels` is a list whose `i`-th element is a list of integers corresponding to class label of each token in the `i`-th sentence. For dataset with K classes, labels must take values in 0, 1, ..., K-1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3150f",
   "metadata": {},
   "source": [
    "## 3. Use cleanlab to find label issues \n",
    "\n",
    "Based on the given labels and out-of-sample predicted probabilities, cleanlab can quickly help us identify label issues in our dataset. Here we request that the indices of the identified label issues be sorted by cleanlab’s self-confidence score, which measures the quality of each given label via the probability assigned to it in our model’s prediction. The returned `issues` are a list of tuples `(i, j)`, which corresponds to the `j`th token of the `i`-th sentence in the dataset. These are the tokens cleanlab thinks may be badly labeled in your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2ad9ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:16.203509Z",
     "iopub.status.busy": "2022-10-03T18:52:16.203299Z",
     "iopub.status.idle": "2022-10-03T18:52:20.945641Z",
     "shell.execute_reply": "2022-10-03T18:52:20.944616Z"
    }
   },
   "outputs": [],
   "source": [
    "issues = find_label_issues(labels, pred_probs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221c12b",
   "metadata": {},
   "source": [
    "Let's look at the top 20 tokens that cleanlab thinks are most likely mislabeled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95dc7268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:20.950558Z",
     "iopub.status.busy": "2022-10-03T18:52:20.949392Z",
     "iopub.status.idle": "2022-10-03T18:52:20.954778Z",
     "shell.execute_reply": "2022-10-03T18:52:20.954106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleanlab found 2255 potential label issues. \n",
      "The top 20 most likely label errors:\n",
      "[(2907, 0), (19392, 0), (9962, 4), (8904, 30), (19303, 0), (12918, 0), (9256, 0), (11855, 20), (18392, 4), (20426, 28), (19402, 21), (14744, 15), (19371, 0), (4645, 2), (83, 9), (10331, 3), (9430, 10), (6143, 25), (18367, 0), (12914, 3)]\n"
     ]
    }
   ],
   "source": [
    "top = 20  # increase this value to view more identified issues\n",
    "print('Cleanlab found %d potential label issues. ' % len(issues)) \n",
    "print('The top %d most likely label errors:' % top) \n",
    "print(issues[:top]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65421a2d",
   "metadata": {},
   "source": [
    "We can better decide how to handle these issues by viewing the original sentences containing these tokens.\n",
    "Given that `O` and `MISC` classes (corresponding to integers 0 and 1 in our class ordering) can sometimes be ambiguous, they are excluded from our visualization below. This is achieved via the `exclude` argument, a list of tuples `(i, j)` such that tokens predicted as `entities[j]` but labeled as `entities[i]` are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e13de188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:20.958497Z",
     "iopub.status.busy": "2022-10-03T18:52:20.958281Z",
     "iopub.status.idle": "2022-10-03T18:52:20.982283Z",
     "shell.execute_reply": "2022-10-03T18:52:20.981647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2907, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mLittle\u001b[0m change from today's weather expected.\n",
      "\n",
      "\n",
      "Sentence 19392, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mLet\u001b[0m's march together,\" Scalfaro, a northerner himself, said.\n",
      "\n",
      "\n",
      "Sentence 9962, token 4:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "3. Nastja Rysich (\u001b[31mgermany\u001b[0m) 3.75\n",
      "\n",
      "\n",
      "Sentence 8904, token 30:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The Spla has fought Khartoum's government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised \u001b[31mnorth\u001b[0m.\n",
      "\n",
      "\n",
      "Sentence 12918, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mMayor\u001b[0m Antonio Gonzalez Garcia, of the opposition Revolutionary Workers' Party, said in Wednesday's letter that army troops recently raided several local farms, stole cattle and raped women.\n",
      "\n",
      "\n",
      "Sentence 9256, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mSpring\u001b[0m Chg Hrw 12pct Chg White Chg\n",
      "\n",
      "\n",
      "Sentence 11855, token 20:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\" We have seen the photos but for the moment the palace has no comment,\" a spokeswoman for \u001b[31mPrince\u001b[0m Rainier told Reuters.\n",
      "\n",
      "\n",
      "Sentence 18392, token 4:\n",
      "Given label: O, predicted label according to provided pred_probs: LOC\n",
      "----\n",
      "Danila 28.5 16\u001b[31m/\u001b[0m12 Caribs/ up W224 Mobil.\n",
      "\n",
      "\n",
      "Sentence 19402, token 21:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next \u001b[31mWednesday\u001b[0m.\n",
      "\n",
      "\n",
      "Sentence 83, token 9:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "Listing London Denoms (K) 1-10-100 Sale Limits \u001b[31mUs\u001b[0m/ Uk/ Jp/ Fr\n",
      "\n",
      "\n",
      "Sentence 10331, token 3:\n",
      "Given label: O, predicted label according to provided pred_probs: ORG\n",
      "----\n",
      "Hapoel Haifa 3 \u001b[31mMaccabi\u001b[0m Tel Aviv 1\n",
      "\n",
      "\n",
      "Sentence 9430, token 10:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The revered Roman Catholic nun was admitted to the Calcutta \u001b[31mhospital\u001b[0m a week ago with high fever and severe vomiting.\n",
      "\n",
      "\n",
      "Sentence 6143, token 25:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council \u001b[31malliance\u001b[0m led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.\n",
      "\n",
      "\n",
      "Sentence 18367, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mCan\u001b[0m/ U.s. Dollar Exchange Rate: 1.3570\n",
      "\n",
      "\n",
      "Sentence 12049, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mBorn\u001b[0m in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.\n",
      "\n",
      "\n",
      "Sentence 16764, token 7:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "1990 - British historian Alan John Percivale \u001b[31m(\u001b[0mA.j.p.) Taylor died.\n",
      "\n",
      "\n",
      "Sentence 20446, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mPace\u001b[0m bowler Ian Harvey claimed three for 81 for Victoria.\n",
      "\n",
      "\n",
      "Sentence 15514, token 16:\n",
      "Given label: O, predicted label according to provided pred_probs: PER\n",
      "----\n",
      "But one must not forget that the Osce only has limited powers there,\" said \u001b[31mCotti\u001b[0m, who is also the Swiss foreign minister.\"\n",
      "\n",
      "\n",
      "Sentence 7525, token 12:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince \u001b[31mSultan\u001b[0m in Jeddah, Saudi state television and the official Saudi Press Agency reported.\n",
      "\n",
      "\n",
      "Sentence 2288, token 0:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mSporting\u001b[0m his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada's reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.\n"
     ]
    }
   ],
   "source": [
    "display_issues(issues, tokens, pred_probs=pred_probs, labels=labels, \n",
    "               exclude=[(0, 1), (1, 0)], class_names=entities) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d04902",
   "metadata": {},
   "source": [
    "More than half of the potential label issues correspond to tokens that are incorrectly labeled. As shown above, some examples are ambigious and may require more thoughful handling. cleanlab has also discovered some edge cases such as tokens which are simply punctuations such as `/` and `(`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213b2b2",
   "metadata": {},
   "source": [
    "### Most common word-level token mislabels \n",
    "\n",
    "We may also wish to understand which tokens tend to be most commonly mislabeled throughout the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4a006bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:20.986051Z",
     "iopub.status.busy": "2022-10-03T18:52:20.985497Z",
     "iopub.status.idle": "2022-10-03T18:52:21.030363Z",
     "shell.execute_reply": "2022-10-03T18:52:21.029699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token '/' is potentially mislabeled 42 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `O` but predicted to actually be class `LOC` 36 times\n",
      "labeled as class `O` but predicted to actually be class `PER` 4 times\n",
      "labeled as class `O` but predicted to actually be class `ORG` 2 times\n",
      "\n",
      "Token 'Chicago' is potentially mislabeled 27 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 22 times\n",
      "labeled as class `LOC` but predicted to actually be class `ORG` 3 times\n",
      "labeled as class `MISC` but predicted to actually be class `ORG` 2 times\n",
      "\n",
      "Token 'U.s.' is potentially mislabeled 21 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `LOC` but predicted to actually be class `ORG` 8 times\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 6 times\n",
      "labeled as class `LOC` but predicted to actually be class `O` 3 times\n",
      "labeled as class `LOC` but predicted to actually be class `MISC` 2 times\n",
      "labeled as class `MISC` but predicted to actually be class `LOC` 1 times\n",
      "labeled as class `MISC` but predicted to actually be class `ORG` 1 times\n",
      "\n",
      "Token 'Digest' is potentially mislabeled 20 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `O` but predicted to actually be class `ORG` 20 times\n",
      "\n",
      "Token 'Press' is potentially mislabeled 20 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `O` but predicted to actually be class `ORG` 20 times\n",
      "\n",
      "Token 'New' is potentially mislabeled 17 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 13 times\n",
      "labeled as class `LOC` but predicted to actually be class `ORG` 2 times\n",
      "labeled as class `O` but predicted to actually be class `ORG` 1 times\n",
      "labeled as class `MISC` but predicted to actually be class `LOC` 1 times\n",
      "\n",
      "Token 'and' is potentially mislabeled 16 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `O` 7 times\n",
      "labeled as class `O` but predicted to actually be class `ORG` 5 times\n",
      "labeled as class `O` but predicted to actually be class `LOC` 3 times\n",
      "labeled as class `MISC` but predicted to actually be class `ORG` 1 times\n",
      "\n",
      "Token 'Philadelphia' is potentially mislabeled 15 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 14 times\n",
      "labeled as class `LOC` but predicted to actually be class `ORG` 1 times\n",
      "\n",
      "Token 'Usda' is potentially mislabeled 13 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 7 times\n",
      "labeled as class `ORG` but predicted to actually be class `PER` 5 times\n",
      "labeled as class `ORG` but predicted to actually be class `MISC` 1 times\n",
      "\n",
      "Token 'York' is potentially mislabeled 12 times throughout the dataset\n",
      "---------------------------------------------------------------------------------------\n",
      "labeled as class `ORG` but predicted to actually be class `LOC` 11 times\n",
      "labeled as class `LOC` but predicted to actually be class `ORG` 1 times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = common_label_issues(issues, tokens, \n",
    "                           labels=labels, \n",
    "                           pred_probs=pred_probs, \n",
    "                           class_names=entities, \n",
    "                           exclude=[(0, 1), (1, 0)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c417061",
   "metadata": {},
   "source": [
    "The printed information above is also stored in pd.DataFrame `info`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ef843",
   "metadata": {},
   "source": [
    "### Find issue sentences with particular word \n",
    "\n",
    "You can also only focus on the subset of potentially problematic sentences where a particular token may have been mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8f4e163",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:21.033946Z",
     "iopub.status.busy": "2022-10-03T18:52:21.033583Z",
     "iopub.status.idle": "2022-10-03T18:52:21.042563Z",
     "shell.execute_reply": "2022-10-03T18:52:21.042000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 471, token 8:\n",
      "Given label: LOC, predicted label according to provided pred_probs: ORG\n",
      "----\n",
      "Soccer - Keane Signs Four-year Contract With Manchester \u001b[31mUnited\u001b[0m.\n",
      "\n",
      "\n",
      "Sentence 19072, token 5:\n",
      "Given label: LOC, predicted label according to provided pred_probs: ORG\n",
      "----\n",
      "The Humane Society of the \u001b[31mUnited\u001b[0m States estimates that between 500,000 and one million bites are delivered by dogs each year, more than half of which are suffered by children.\n",
      "\n",
      "\n",
      "Sentence 19910, token 5:\n",
      "Given label: LOC, predicted label according to provided pred_probs: ORG\n",
      "----\n",
      "His father Clarence Woolmer represented \u001b[31mUnited\u001b[0m Province, now renamed Uttar Pradesh, in India's Ranji Trophy national championship and captained the state during 1949.\n",
      "\n",
      "\n",
      "Sentence 15658, token 0:\n",
      "Given label: ORG, predicted label according to provided pred_probs: LOC\n",
      "----\n",
      "\u001b[31mUnited\u001b[0m Nations 1996-08-29\n",
      "\n",
      "\n",
      "Sentence 19879, token 1:\n",
      "Given label: ORG, predicted label according to provided pred_probs: LOC\n",
      "----\n",
      "1. \u001b[31mUnited\u001b[0m States Iii (Brian Shimer, Randy Jones) one\n",
      "\n",
      "\n",
      "Sentence 19104, token 0:\n",
      "Given label: ORG, predicted label according to provided pred_probs: LOC\n",
      "----\n",
      "\u001b[31mUnited\u001b[0m Nations 1996-12-06\n"
     ]
    }
   ],
   "source": [
    "token_issues = filter_by_token('United', issues, tokens)\n",
    "\n",
    "display_issues(token_issues, tokens, pred_probs=pred_probs, labels=labels, \n",
    "               exclude=[(0, 1), (1, 0)], class_names=entities) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1759108b",
   "metadata": {},
   "source": [
    "###  Sentence label quality score \n",
    "\n",
    "For best reviewing label issues in a token classification dataset, you want to look at sentences one at a time. Here sentences more likely to contain a label error should be ranked earlier. Cleanlab can provide an overall label quality score for each sentence (ranging from 0 to 1) such that lower scores indicate sentences more likely to contain some mislabeled token. We can also obtain label quality scores for each individual token and decide which of these are label issues by thresholding them. This may be a superior approach if high precision (or high recall) is specifically preferred for your label error detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0b5179",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:21.045946Z",
     "iopub.status.busy": "2022-10-03T18:52:21.045598Z",
     "iopub.status.idle": "2022-10-03T18:52:25.274090Z",
     "shell.execute_reply": "2022-10-03T18:52:25.273421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 2907, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mLittle\u001b[0m change from today's weather expected.\n",
      "\n",
      "\n",
      "Sentence 19392, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mLet\u001b[0m's march together,\" Scalfaro, a northerner himself, said.\n",
      "\n",
      "\n",
      "Sentence 9962, token 4:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "3. Nastja Rysich (\u001b[31mgermany\u001b[0m) 3.75\n",
      "\n",
      "\n",
      "Sentence 8904, token 30:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The Spla has fought Khartoum's government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised \u001b[31mnorth\u001b[0m.\n",
      "\n",
      "\n",
      "Sentence 12918, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mMayor\u001b[0m Antonio Gonzalez Garcia, of the opposition Revolutionary Workers' Party, said in Wednesday's letter that army troops recently raided several local farms, stole cattle and raped women.\n",
      "\n",
      "\n",
      "Sentence 9256, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mSpring\u001b[0m Chg Hrw 12pct Chg White Chg\n",
      "\n",
      "\n",
      "Sentence 11855, token 20:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\" We have seen the photos but for the moment the palace has no comment,\" a spokeswoman for \u001b[31mPrince\u001b[0m Rainier told Reuters.\n",
      "\n",
      "\n",
      "Sentence 18392, token 4:\n",
      "Given label: O, predicted label according to provided pred_probs: LOC\n",
      "----\n",
      "Danila 28.5 16\u001b[31m/\u001b[0m12 Caribs/ up W224 Mobil.\n",
      "\n",
      "\n",
      "Sentence 19402, token 21:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next \u001b[31mWednesday\u001b[0m.\n",
      "\n",
      "\n",
      "Sentence 83, token 9:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "Listing London Denoms (K) 1-10-100 Sale Limits \u001b[31mUs\u001b[0m/ Uk/ Jp/ Fr\n",
      "\n",
      "\n",
      "Sentence 10331, token 3:\n",
      "Given label: O, predicted label according to provided pred_probs: ORG\n",
      "----\n",
      "Hapoel Haifa 3 \u001b[31mMaccabi\u001b[0m Tel Aviv 1\n",
      "\n",
      "\n",
      "Sentence 9430, token 10:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The revered Roman Catholic nun was admitted to the Calcutta \u001b[31mhospital\u001b[0m a week ago with high fever and severe vomiting.\n",
      "\n",
      "\n",
      "Sentence 6143, token 25:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council \u001b[31malliance\u001b[0m led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.\n",
      "\n",
      "\n",
      "Sentence 18367, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mCan\u001b[0m/ U.s. Dollar Exchange Rate: 1.3570\n",
      "\n",
      "\n",
      "Sentence 12049, token 0:\n",
      "Given label: LOC, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mBorn\u001b[0m in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.\n",
      "\n",
      "\n",
      "Sentence 16764, token 7:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "1990 - British historian Alan John Percivale \u001b[31m(\u001b[0mA.j.p.) Taylor died.\n",
      "\n",
      "\n",
      "Sentence 20446, token 0:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mPace\u001b[0m bowler Ian Harvey claimed three for 81 for Victoria.\n",
      "\n",
      "\n",
      "Sentence 15514, token 16:\n",
      "Given label: O, predicted label according to provided pred_probs: PER\n",
      "----\n",
      "But one must not forget that the Osce only has limited powers there,\" said \u001b[31mCotti\u001b[0m, who is also the Swiss foreign minister.\"\n",
      "\n",
      "\n",
      "Sentence 7525, token 12:\n",
      "Given label: PER, predicted label according to provided pred_probs: O\n",
      "----\n",
      "Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince \u001b[31mSultan\u001b[0m in Jeddah, Saudi state television and the official Saudi Press Agency reported.\n",
      "\n",
      "\n",
      "Sentence 2288, token 0:\n",
      "Given label: ORG, predicted label according to provided pred_probs: O\n",
      "----\n",
      "\u001b[31mSporting\u001b[0m his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada's reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.\n"
     ]
    }
   ],
   "source": [
    "sentence_scores, token_scores = get_label_quality_scores(labels, pred_probs)\n",
    "issues = issues_from_scores(sentence_scores, token_scores=token_scores) \n",
    "display_issues(issues, tokens, pred_probs=pred_probs, labels=labels, \n",
    "               exclude=[(0, 1), (1, 0)], class_names=entities) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a18795eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-03T18:52:25.277372Z",
     "iopub.status.busy": "2022-10-03T18:52:25.277031Z",
     "iopub.status.idle": "2022-10-03T18:52:25.283225Z",
     "shell.execute_reply": "2022-10-03T18:52:25.282632Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "highlighted_indices = [(2907, 0), (19392, 0), (9962, 4), (8904, 30), (19303, 0), \n",
    "                       (12918, 0), (9256, 0), (11855, 20), (18392, 4), (20426, 28), \n",
    "                       (19402, 21), (14744, 15), (19371, 0), (4645, 2), (83, 9), \n",
    "                       (10331, 3), (9430, 10), (6143, 25), (18367, 0), (12914, 3)] \n",
    "\n",
    "if not all(x in issues for x in highlighted_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from ranked_label_issues.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
