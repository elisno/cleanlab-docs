{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Issues in a Text Dataset with Datalab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this 5-minute quickstart tutorial, we use Datalab to detect various issues in an intent classification dataset composed of (text) customer service requests at an online bank. We consider a subset of the [Banking77-OOS Dataset](https://arxiv.org/abs/2106.04564) containing 1,000 customer service requests which are classified into 10 categories based on their intent (you can run this same code on any text classification dataset). Cleanlab automatically identifies bad examples in our dataset, including mislabeled data, out-of-scope examples (outliers), or otherwise ambiguous examples. Consider filtering or correcting such bad examplesÂ before you dive deep into modeling your data!\n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Use a pretrained transformer model to extract the text embeddings from the customer service requests\n",
    "\n",
    "- Train a simple Logistic Regression model on the text embeddings to compute out-of-sample predicted probabilities\n",
    "\n",
    "- Run cleanlab's `Datalab` audit with these predictions and embeddings in order to identify problems like: label issues, outliers, and near duplicates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "Already have (out-of-sample) `pred_probs` from a model trained on an existing set of labels? Maybe you have some numeric `features` as well? Run the code below to find any potential label errors in your dataset.\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```ipython3 \n",
    "from cleanlab import Datalab\n",
    "\n",
    "lab = Datalab(data=your_dataset, label_name=\"column_name_of_labels\")\n",
    "lab.find_issues(pred_probs=your_pred_probs, features=your_features)\n",
    "\n",
    "lab.report()\n",
    "lab.get_issues()\n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install required dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install sentence-transformers\n",
    "!pip install \"cleanlab[datalab]\"\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:08.364933Z",
     "iopub.status.busy": "2024-06-12T21:17:08.364516Z",
     "iopub.status.idle": "2024-06-12T21:17:11.054165Z",
     "shell.execute_reply": "2024-06-12T21:17:11.053546Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs.cleanlab.ai).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used:scikit-learn==1.2.0 sentence-transformers==2.2.2\n",
    "\n",
    "dependencies = [\"cleanlab\", \"sentence_transformers\", \"datasets\"]\n",
    "\n",
    "# Supress outputs that may appear if tensorflow happens to be improperly installed: \n",
    "import os \n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # disable parallelism to avoid deadlocks with huggingface\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install git+https://github.com/elisno/cleanlab.git@b0ca6e5ca84b14ac115c247b500b4f231df963a3\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    dependencies_test = [dependency.split('>')[0] if '>' in dependency \n",
    "                         else dependency.split('<')[0] if '<' in dependency \n",
    "                         else dependency.split('=')[0] for dependency in dependencies]\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies_test:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.057044Z",
     "iopub.status.busy": "2024-06-12T21:17:11.056738Z",
     "iopub.status.idle": "2024-06-12T21:17:11.060090Z",
     "shell.execute_reply": "2024-06-12T21:17:11.059608Z"
    }
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score, log_loss \n",
    "from sklearn.model_selection import cross_val_predict \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab import Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.062118Z",
     "iopub.status.busy": "2024-06-12T21:17:11.061715Z",
     "iopub.status.idle": "2024-06-12T21:17:11.064803Z",
     "shell.execute_reply": "2024-06-12T21:17:11.064265Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# This cell is hidden from docs.cleanlab.ai \n",
    "\n",
    "import random \n",
    "import numpy as np \n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None) \n",
    "\n",
    "SEED = 123456  # for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and format the text dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.066821Z",
     "iopub.status.busy": "2024-06-12T21:17:11.066489Z",
     "iopub.status.idle": "2024-06-12T21:17:11.088116Z",
     "shell.execute_reply": "2024-06-12T21:17:11.087481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i accidentally made a payment to a wrong account. what should i do?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i no longer want to transfer funds, can we cancel that transaction?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancel my transfer, please.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to revert this mornings transaction.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     text  \\\n",
       "0                                                                                                                     i accidentally made a payment to a wrong account. what should i do?   \n",
       "1                                                                                                                     i no longer want to transfer funds, can we cancel that transaction?   \n",
       "2                                                                                                                                                             cancel my transfer, please.   \n",
       "3                                                                                                                                             i want to revert this mornings transaction.   \n",
       "4  i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow   \n",
       "\n",
       "             label  \n",
       "0  cancel_transfer  \n",
       "1  cancel_transfer  \n",
       "2  cancel_transfer  \n",
       "3  cancel_transfer  \n",
       "4  cancel_transfer  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://s.cleanlab.ai/banking-intent-classification.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.090740Z",
     "iopub.status.busy": "2024-06-12T21:17:11.090201Z",
     "iopub.status.idle": "2024-06-12T21:17:11.094486Z",
     "shell.execute_reply": "2024-06-12T21:17:11.093935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 10 classes.\n",
      "Classes: {'supported_cards_and_currencies', 'beneficiary_not_allowed', 'lost_or_stolen_phone', 'getting_spare_card', 'visa_or_mastercard', 'card_about_to_expire', 'change_pin', 'apple_pay_or_google_pay', 'cancel_transfer', 'card_payment_fee_charged'}\n"
     ]
    }
   ],
   "source": [
    "raw_texts, labels = data[\"text\"].values, data[\"label\"].values\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "print(f\"This dataset has {num_classes} classes.\")\n",
    "print(f\"Classes: {set(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view the i-th example in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.096769Z",
     "iopub.status.busy": "2024-06-12T21:17:11.096406Z",
     "iopub.status.idle": "2024-06-12T21:17:11.099706Z",
     "shell.execute_reply": "2024-06-12T21:17:11.099185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Label: cancel_transfer\n",
      "Example Text: i no longer want to transfer funds, can we cancel that transaction?\n"
     ]
    }
   ],
   "source": [
    "i = 1  # change this to view other examples from the dataset\n",
    "print(f\"Example Label: {labels[i]}\")\n",
    "print(f\"Example Text: {raw_texts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as two numpy arrays:\n",
    "\n",
    "1. `raw_texts` stores the customer service requests utterances in text format\n",
    "2. `labels` stores the intent categories (labels) for each example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Bringing Your Own Data (BYOD)?\n",
    "\n",
    "You can easily replace the above with your own text dataset, and continue with the rest of the tutorial.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the text strings into vectors better suited as inputs for our ML models. \n",
    "\n",
    "We will use numeric representations from a pretrained Transformer model as embeddings of our text. The [Sentence Transformers](https://huggingface.co/docs/hub/sentence-transformers) library offers simple methods to compute these embeddings for text data. Here, we load the pretrained `electra-small-discriminator` model, and then run our data through network to extract a vector embeddingÂ of each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:11.101947Z",
     "iopub.status.busy": "2024-06-12T21:17:11.101591Z",
     "iopub.status.idle": "2024-06-12T21:17:15.222876Z",
     "shell.execute_reply": "2024-06-12T21:17:15.222270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/runner/.cache/torch/sentence_transformers/google_electra-small-discriminator. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "transformer = SentenceTransformer('google/electra-small-discriminator')\n",
    "text_embeddings = transformer.encode(raw_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our subsequent ML model will directly operate on elements of `text_embeddings` in order to classify the customer service requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a classification model and compute out-of-sample predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical way to leverage pretrained networks for a particular classification task is to add a linear output layer and fine-tune the network parameters on the new data. However this can be computationally intensive. Alternatively, we can freeze the pretrained weights of the network and only train the output layer without having to rely on GPU(s). Here we do this conveniently by fitting a scikit-learn linear model on top of the extracted embeddings.\n",
    "\n",
    "To identify label issues, cleanlab requires a probabilistic prediction from your model for each datapoint. However these predictions will be _overfit_ (and thus unreliable) for datapoints the model was previously trained on. cleanlab is intended to only be used with **out-of-sample** predicted class probabilities, i.e. on datapoints held-out from the model during the training.\n",
    "\n",
    "Here we obtain out-of-sample predicted class probabilities for every example in our dataset using a Logistic Regression model with cross-validation.\n",
    "Make sure that the columns of your `pred_probs` are properly ordered with respect to the ordering of classes, which for Datalab is: lexicographically sorted by class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:15.225794Z",
     "iopub.status.busy": "2024-06-12T21:17:15.225564Z",
     "iopub.status.idle": "2024-06-12T21:17:16.083967Z",
     "shell.execute_reply": "2024-06-12T21:17:16.083353Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=400)\n",
    "\n",
    "pred_probs = cross_val_predict(model, text_embeddings, labels, method=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use cleanlab to find issues in your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given feature embeddings and the (out-of-sample) predicted class probabilities obtained from any modelÂ you have, cleanlab can quickly help you identify low-quality examples in your dataset.\n",
    "\n",
    "Here, we use cleanlab's `Datalab` to find issues in our data. Datalab offers several ways of loading the data; weâll simply wrap the training features and noisy labels in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:16.086977Z",
     "iopub.status.busy": "2024-06-12T21:17:16.086574Z",
     "iopub.status.idle": "2024-06-12T21:17:16.089532Z",
     "shell.execute_reply": "2024-06-12T21:17:16.089043Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict = {\"texts\": raw_texts, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that is need to audit your data is to call `find_issues()`. We pass in the predicted probabilities and the feature embeddings obtained above, but you do not necessarily need to provide all of this information depending on which types of issues you are interested in. The more inputs you provide, the more types of issues `Datalab` can detect in your data. Using a better model to produce these inputs will ensure cleanlab more accurately estimates issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:16.091927Z",
     "iopub.status.busy": "2024-06-12T21:17:16.091522Z",
     "iopub.status.idle": "2024-06-12T21:17:17.647920Z",
     "shell.execute_reply": "2024-06-12T21:17:17.647241Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding outlier issues ...\n",
      "Fitting OOD estimator based on provided features ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 85 issues found in the dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.11.9/x64/lib/python3.11/site-packages/sklearn/neighbors/_base.py:246: EfficiencyWarning: Precomputed sparse input was not sorted by row values. Use the function sklearn.neighbors.sort_graph_by_row_values to sort the input by row values, with warn_when_not_sorted=False to remove this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data_dict, label_name=\"labels\")\n",
    "lab.find_issues(pred_probs=pred_probs, features=text_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the audit is complete, review the findings using the `report` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.652023Z",
     "iopub.status.busy": "2024-06-12T21:17:17.650874Z",
     "iopub.status.idle": "2024-06-12T21:17:17.675246Z",
     "shell.execute_reply": "2024-06-12T21:17:17.674732Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information: num_examples: 1000, num_classes: 10\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "    issue_type  num_issues\n",
      "         label          42\n",
      "       outlier          38\n",
      "near_duplicate           4\n",
      "       non_iid           1\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 42\n",
      "Overall dataset quality in terms of this issue: 0.9710\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score              given_label           predicted_label\n",
      "981            True     0.000005     card_about_to_expire  card_payment_fee_charged\n",
      "974            True     0.000146  beneficiary_not_allowed                change_pin\n",
      "982            True     0.000224  apple_pay_or_google_pay      card_about_to_expire\n",
      "971            True     0.000507  beneficiary_not_allowed                change_pin\n",
      "980            True     0.000960     card_about_to_expire  card_payment_fee_charged\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 38\n",
      "Overall dataset quality in terms of this issue: 0.3584\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_outlier_issue  outlier_score\n",
      "994              True       0.009642\n",
      "999              True       0.013067\n",
      "81               True       0.013841\n",
      "433              True       0.014722\n",
      "989              True       0.018224\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 4\n",
      "Overall dataset quality in terms of this issue: 0.6070\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "160                     True              0.095724               [148]                      0.006237\n",
      "148                     True              0.095724               [160]                      0.006237\n",
      "546                     True              0.099341               [514]                      0.006485\n",
      "514                     True              0.099341               [546]                      0.006485\n",
      "481                    False              0.123418                  []                      0.008165\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 1\n",
      "Overall dataset quality in terms of this issue: 0.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "313              True       0.564102\n",
      "13              False       0.572258\n",
      "28              False       0.574915\n",
      "31              False       0.575507\n",
      "40              False       0.575874\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "lab.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label issues\n",
    "\n",
    "The report indicates that cleanlab identified many label issues in our dataset. We can see which examples are flagged as likely mislabeled and the label quality score for each example using the `get_issues` method, specifying `label` as an argument to focus on label issues in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.678004Z",
     "iopub.status.busy": "2024-06-12T21:17:17.677604Z",
     "iopub.status.idle": "2024-06-12T21:17:17.687218Z",
     "shell.execute_reply": "2024-06-12T21:17:17.686733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_score</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.792090</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.257611</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.698710</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.182121</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.771619</td>\n",
       "      <td>cancel_transfer</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_score      given_label          predicted_label\n",
       "0           False     0.792090  cancel_transfer          cancel_transfer\n",
       "1           False     0.257611  cancel_transfer          cancel_transfer\n",
       "2           False     0.698710  cancel_transfer          cancel_transfer\n",
       "3           False     0.182121  cancel_transfer  apple_pay_or_google_pay\n",
       "4           False     0.771619  cancel_transfer          cancel_transfer"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issues = lab.get_issues(\"label\")\n",
    "label_issues.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method returns a dataframe containing a label quality score for each example. These numeric scores lie between 0 and 1, where lower scores indicate examples more likely to be mislabeled. The dataframe also contains a boolean column specifying whether or not each example is identified to have a label issue (indicating it is likely mislabeled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the subset of examples flagged with label issues, and also sort by label quality score to find the indices of the 5 most likely mislabeled examples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.689378Z",
     "iopub.status.busy": "2024-06-12T21:17:17.689069Z",
     "iopub.status.idle": "2024-06-12T21:17:17.693079Z",
     "shell.execute_reply": "2024-06-12T21:17:17.692542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanlab found 42 potential label errors in the dataset.\n",
      "Here are indices of the top 5 most likely errors: \n",
      " [981 974 982 971 980]\n"
     ]
    }
   ],
   "source": [
    "identified_label_issues = label_issues[label_issues[\"is_label_issue\"] == True]\n",
    "lowest_quality_labels = label_issues[\"label_score\"].argsort()[:5].to_numpy()\n",
    "\n",
    "print(\n",
    "    f\"cleanlab found {len(identified_label_issues)} potential label errors in the dataset.\\n\"\n",
    "    f\"Here are indices of the top 5 most likely errors: \\n {lowest_quality_labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review some of the most likely label errors. \n",
    "\n",
    "Here we display the top 5 examples identified as the most likely label errors in the dataset, together with their given (original) label and a suggested alternative label from cleanlab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.694992Z",
     "iopub.status.busy": "2024-06-12T21:17:17.694809Z",
     "iopub.status.idle": "2024-06-12T21:17:17.701346Z",
     "shell.execute_reply": "2024-06-12T21:17:17.700894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>given_label</th>\n",
       "      <th>suggested_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>i was charged for getting cash.</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>can i change my pin on holiday?</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>will i be sent a new card before mine expires?</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>please tell me how to change my pin.</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>why do i see extra charges for withdrawing my money?</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "981                       i was charged for getting cash.   \n",
       "974                       can i change my pin on holiday?   \n",
       "982        will i be sent a new card before mine expires?   \n",
       "971                  please tell me how to change my pin.   \n",
       "980  why do i see extra charges for withdrawing my money?   \n",
       "\n",
       "                 given_label           suggested_label  \n",
       "981     card_about_to_expire  card_payment_fee_charged  \n",
       "974  beneficiary_not_allowed                change_pin  \n",
       "982  apple_pay_or_google_pay      card_about_to_expire  \n",
       "971  beneficiary_not_allowed                change_pin  \n",
       "980     card_about_to_expire  card_payment_fee_charged  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_suggested_labels = pd.DataFrame(\n",
    "    {\"text\": raw_texts, \"given_label\": labels, \"suggested_label\": label_issues[\"predicted_label\"]}\n",
    ")\n",
    "data_with_suggested_labels.iloc[lowest_quality_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "These are very clear label errors that cleanlab has identified in this data! Note that the `given_label` does not correctly reflect the intent of these requests, whoever produced this dataset made many mistakes that are important to address before modeling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier issues\n",
    "\n",
    "According to the report, our dataset contains some outliers.\n",
    "We can see which examples are outliers (and a numeric quality score quantifying how typical each example appears to be) via `get_issues`. We sort the resulting DataFrame by cleanlab's outlier quality score to see the most severe outliers in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.703326Z",
     "iopub.status.busy": "2024-06-12T21:17:17.703013Z",
     "iopub.status.idle": "2024-06-12T21:17:17.709609Z",
     "shell.execute_reply": "2024-06-12T21:17:17.709097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_outlier_issue</th>\n",
       "      <th>outlier_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>True</td>\n",
       "      <td>0.009642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>True</td>\n",
       "      <td>0.013067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>True</td>\n",
       "      <td>0.013841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>True</td>\n",
       "      <td>0.014722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>True</td>\n",
       "      <td>0.018224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_outlier_issue  outlier_score\n",
       "994              True       0.009642\n",
       "999              True       0.013067\n",
       "81               True       0.013841\n",
       "433              True       0.014722\n",
       "989              True       0.018224"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_issues = lab.get_issues(\"outlier\")\n",
    "outlier_issues.sort_values(\"outlier_score\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.711641Z",
     "iopub.status.busy": "2024-06-12T21:17:17.711332Z",
     "iopub.status.idle": "2024-06-12T21:17:17.717106Z",
     "shell.execute_reply": "2024-06-12T21:17:17.716561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>(A AND NOT B) OR (C AND NOT D) OR (B AND NOT C AND D)</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>636C65616E6C616220697320617765736F6D6521</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>cancel transaction</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>phone is gone</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>&lt;p&gt;&lt;samp&gt;File not found.&lt;br&gt;Press F1 to continue&lt;/samp&gt;&lt;/p&gt;</td>\n",
       "      <td>supported_cards_and_currencies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            text  \\\n",
       "994        (A AND NOT B) OR (C AND NOT D) OR (B AND NOT C AND D)   \n",
       "999                     636C65616E6C616220697320617765736F6D6521   \n",
       "81                                            cancel transaction   \n",
       "433                                                phone is gone   \n",
       "989  <p><samp>File not found.<br>Press F1 to continue</samp></p>   \n",
       "\n",
       "                              label  \n",
       "994                      change_pin  \n",
       "999                 cancel_transfer  \n",
       "81                  cancel_transfer  \n",
       "433            lost_or_stolen_phone  \n",
       "989  supported_cards_and_currencies  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowest_quality_outliers = outlier_issues[\"outlier_score\"].argsort()[:5]\n",
    "\n",
    "data.iloc[lowest_quality_outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that cleanlab has identified entries in this dataset that do not appear to be proper customer requests. Outliers in this dataset appear to be out-of-scope customer requests and other nonsensical text which does not make sense for intent classification. Carefully consider whether such outliers may detrimentally affect your data modeling, and consider removing them from the dataset if so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Near-duplicate issues\n",
    "\n",
    "According to the report, our dataset contains some sets of nearly duplicated examples.\n",
    "We can see which examples are (nearly) duplicated (and a numeric quality score quantifying how dissimilar each example is from its nearest neighbor in the dataset) via `get_issues`. We sort the resulting DataFrame by cleanlab's near-duplicate quality score to see the text examples in our dataset that are most nearly duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.719102Z",
     "iopub.status.busy": "2024-06-12T21:17:17.718797Z",
     "iopub.status.idle": "2024-06-12T21:17:17.727397Z",
     "shell.execute_reply": "2024-06-12T21:17:17.726866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>True</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>[148]</td>\n",
       "      <td>0.006237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>True</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>[160]</td>\n",
       "      <td>0.006237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>True</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>[514]</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>True</td>\n",
       "      <td>0.099341</td>\n",
       "      <td>[546]</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>False</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.008165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "160                     True              0.095724               [148]   \n",
       "148                     True              0.095724               [160]   \n",
       "546                     True              0.099341               [514]   \n",
       "514                     True              0.099341               [546]   \n",
       "481                    False              0.123418                  []   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "160                      0.006237  \n",
       "148                      0.006237  \n",
       "546                      0.006485  \n",
       "514                      0.006485  \n",
       "481                      0.008165  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_issues = lab.get_issues(\"near_duplicate\")\n",
    "duplicate_issues.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show which examples cleanlab considers nearly duplicated (rows where `is_near_duplicate_issue == True`). Here, we see that example 160 and 148 are nearly duplicated, as are example 546 and 514.\n",
    "\n",
    "Let's view these examples to see how similar they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.729569Z",
     "iopub.status.busy": "2024-06-12T21:17:17.729170Z",
     "iopub.status.idle": "2024-06-12T21:17:17.734663Z",
     "shell.execute_reply": "2024-06-12T21:17:17.734150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>why was i charged an additional fee when paying with card?</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>why was i charged an extra fee when paying with card?</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           text  \\\n",
       "160  why was i charged an additional fee when paying with card?   \n",
       "148       why was i charged an extra fee when paying with card?   \n",
       "\n",
       "                        label  \n",
       "160  card_payment_fee_charged  \n",
       "148  card_payment_fee_charged  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[[160, 148]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.736591Z",
     "iopub.status.busy": "2024-06-12T21:17:17.736419Z",
     "iopub.status.idle": "2024-06-12T21:17:17.741967Z",
     "shell.execute_reply": "2024-06-12T21:17:17.741498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>do i have to go to the bank to change my pin?</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>do i have to go into the bank to change my pin?</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text       label\n",
       "546    do i have to go to the bank to change my pin?  change_pin\n",
       "514  do i have to go into the bank to change my pin?  change_pin"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[[546, 514]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that these two sets of request are indeed very similar to one another! Including near duplicates in a dataset may have unintended effects on models, and be wary about splitting them across training/test sets. Learn more about handling near duplicates in a dataset from [the FAQ](../faq.html#How-to-handle-near-duplicate-data-identified-by-cleanlab?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-IID issues (data drift)\n",
    "According to the report, our dataset does not appear to be Independent and Identically Distributed (IID).  The overall non-iid score for the dataset (displayed below) corresponds to the `p-value` of a statistical test for whether the ordering of samples in the dataset appears related to the similarity between their feature values.  A low `p-value` strongly suggests that the dataset violates the IID assumption, which is a key assumption required for conclusions (models) produced from the dataset to generalize to a larger population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.744141Z",
     "iopub.status.busy": "2024-06-12T21:17:17.743934Z",
     "iopub.status.idle": "2024-06-12T21:17:17.747864Z",
     "shell.execute_reply": "2024-06-12T21:17:17.747266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value = lab.get_info('non_iid')['p-value']\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, our dataset was flagged as non-IID because the rows happened to be sorted by class label in the original data. This may be benign if we remember to shuffle rows before model training and data splitting. But if you don't know why your data was flagged as non-IID, then you should be worried about potential data drift or unexpected interactions between data points (their values may not be statistically independent). Think carefully about what future test data may look like (and whether your data is representative of the population you care about). You should not shuffle your data before the non-IID test runs (will invalidate its conclusions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, cleanlab can automatically shortlist the most likely issues in your dataset to help you better curate your dataset for subsequent modeling. With this shortlist, you can decide whether to fix these label issues or remove nonsensical or duplicated examples from your dataset to obtain a higher-quality dataset for training your next ML model. cleanlab's issue detection can be run with outputs from *any* type of model you initially trained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Mode \n",
    "\n",
    "Cleanlab is most effective when you run this code with a good ML model. Try to produce the best ML model you can for your data (instead of the basic model from this tutorial). If you don't know the best ML model for your data, try [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/) which will automatically produce one for you. Super easy to use, [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/) isÂ no-code platform for data-centric AI that automatically: detects data issues (more types of issues than this cleanlab package), helps you quickly correct these data issues, confidently labels large subsets of an unlabeled dataset, and provides other smart metadata about each of your data points -- all powered by a system that automatically trains/deploys the best ML model for your data. [Try it for free!](https://cleanlab.ai/signup/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T21:17:17.749966Z",
     "iopub.status.busy": "2024-06-12T21:17:17.749787Z",
     "iopub.status.idle": "2024-06-12T21:17:17.755257Z",
     "shell.execute_reply": "2024-06-12T21:17:17.754821Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "label_issue_indices = [981, 974, 982]  # check these examples were found in label issues\n",
    "if not all(x in identified_label_issues.index for x in label_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_label_issues.\")\n",
    "    \n",
    "identified_outlier_issues = outlier_issues[outlier_issues[\"is_outlier_issue\"] == True]\n",
    "outlier_issue_indices = [994, 989, 999]  # check these examples were found in duplicates\n",
    "if not all(x in identified_outlier_issues.index for x in outlier_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_outlier_issues.\")\n",
    "\n",
    "identified_duplicate_issues = duplicate_issues[duplicate_issues[\"is_near_duplicate_issue\"] == True]\n",
    "duplicate_issue_indices = [160, 148, 546, 514]  # check these examples were found in duplicates\n",
    "if not all(x in identified_duplicate_issues.index for x in duplicate_issue_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from identified_duplicate_issues.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text x TensorFlow",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
