{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Noisy Labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Consider Using Datalab\n",
    "<br/>\n",
    "\n",
    "If you are interested in detecting a wide variety of issues in your text dataset, check out the [Datalab text tutorial](https://docs.cleanlab.ai/stable/tutorials/datalab/text.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this 5-minute quickstart tutorial, we use cleanlab to find potential label errors in an intent classification dataset composed of (text) customer service requests at an online bank. We consider a subset of the [Banking77-OOS Dataset](https://arxiv.org/abs/2106.04564) containing 1,000 customer service requests which can be classified into 10 categories corresponding to the intent of the request. cleanlab will shortlist examples that confuse our ML model the most; many of which are potential label errors, out-of-scope examples, or otherwise ambiguous examples. The `CleanLearning` class allows us to detect and filter out such bad data automatically, in order to train a more robust version of any ML model without having to change your existing modeling code! \n",
    "\n",
    "**Overview of what we'll do in this tutorial:**\n",
    "\n",
    "- Define a ML model that can be trained on our dataset (here we use Logistic Regression applied to text embeddings from a pretrained Transformer network, you can use any text classifier model).\n",
    "\n",
    "- Use `CleanLearning` to wrap this ML model and compute out-of-sample predicted class probabilites, which allow us to identify potential label errors in the dataset.\n",
    "\n",
    "- Train a more robust version of the same ML model after dropping the detected label errors using `CleanLearning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Quickstart\n",
    "<br/>\n",
    "    \n",
    "Already have an sklearn compatible `model`, `data` and given `labels`? Run the code below to train your `model` and get label issues using `CleanLearning`. \n",
    "    \n",
    "You can subsequently use the same `CleanLearning` object to train a more robust model (only trained on the clean data) by calling the `.fit()` method and passing in the `label_issues` found earlier.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.classification import CleanLearning\n",
    "\n",
    "cl = CleanLearning(model)\n",
    "label_issues = cl.find_label_issues(train_data, labels)  # identify mislabeled examples \n",
    "  \n",
    "cl.fit(train_data, labels, label_issues=label_issues)\n",
    "preds = cl.predict(test_data)  # predictions from a version of your model \n",
    "                               # trained on auto-cleaned data\n",
    "\n",
    "\n",
    "```\n",
    "    \n",
    "</div>\n",
    "    \n",
    "Is your model/data not compatible with `CleanLearning`? You can instead run cross-validation on your model to get out-of-sample `pred_probs`. Then run the code below to get label issue indices ranked by their inferred severity.\n",
    "\n",
    "\n",
    "<div  class=markdown markdown=\"1\" style=\"background:white;margin:16px\">  \n",
    "    \n",
    "```python\n",
    "\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "ranked_label_issues = find_label_issues(\n",
    "    labels,\n",
    "    pred_probs,\n",
    "    return_indices_ranked_by=\"self_confidence\",\n",
    ")\n",
    "    \n",
    "\n",
    "```\n",
    "    \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install required dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install sklearn sentence-transformers\n",
    "!pip install cleanlab\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:01.822837Z",
     "iopub.status.busy": "2024-02-27T10:08:01.822666Z",
     "iopub.status.idle": "2024-02-27T10:08:04.466593Z",
     "shell.execute_reply": "2024-02-27T10:08:04.466043Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs.cleanlab.ai).\n",
    "# If running on Colab, may want to use GPU (select: Runtime > Change runtime type > Hardware accelerator > GPU)\n",
    "# Package versions we used:scikit-learn==1.2.0 sentence-transformers==2.2.2\n",
    "\n",
    "dependencies = [\"cleanlab\", \"sentence_transformers\"]\n",
    "\n",
    "# Supress outputs that may appear if tensorflow happens to be improperly installed: \n",
    "import os \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # disable parallelism to avoid deadlocks with huggingface\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install git+https://github.com/elisno/cleanlab.git@e5ea09b4e09144c4027ee8b3bf56ec2f381b71ba\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    dependencies_test = [dependency.split('>')[0] if '>' in dependency \n",
    "                         else dependency.split('<')[0] if '<' in dependency \n",
    "                         else dependency.split('=')[0] for dependency in dependencies]\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies_test:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.469288Z",
     "iopub.status.busy": "2024-02-27T10:08:04.468970Z",
     "iopub.status.idle": "2024-02-27T10:08:04.472396Z",
     "shell.execute_reply": "2024-02-27T10:08:04.471958Z"
    }
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import pandas as pd \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from cleanlab.classification import CleanLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.474457Z",
     "iopub.status.busy": "2024-02-27T10:08:04.474120Z",
     "iopub.status.idle": "2024-02-27T10:08:04.477094Z",
     "shell.execute_reply": "2024-02-27T10:08:04.476658Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# This cell is hidden from docs.cleanlab.ai \n",
    "\n",
    "import random \n",
    "import numpy as np \n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None) \n",
    "\n",
    "SEED = 123456 # for reproducibility \n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and format the text dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.479131Z",
     "iopub.status.busy": "2024-02-27T10:08:04.478806Z",
     "iopub.status.idle": "2024-02-27T10:08:04.526894Z",
     "shell.execute_reply": "2024-02-27T10:08:04.526373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i accidentally made a payment to a wrong account. what should i do?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i no longer want to transfer funds, can we cancel that transaction?</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cancel my transfer, please.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i want to revert this mornings transaction.</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow</td>\n",
       "      <td>cancel_transfer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                     text  \\\n",
       "0                                                                                                                     i accidentally made a payment to a wrong account. what should i do?   \n",
       "1                                                                                                                     i no longer want to transfer funds, can we cancel that transaction?   \n",
       "2                                                                                                                                                             cancel my transfer, please.   \n",
       "3                                                                                                                                             i want to revert this mornings transaction.   \n",
       "4  i just realised i made the wrong payment yesterday. can you please change it to the right account? it's my rent payment and really really needs to be in the right account by tomorrow   \n",
       "\n",
       "             label  \n",
       "0  cancel_transfer  \n",
       "1  cancel_transfer  \n",
       "2  cancel_transfer  \n",
       "3  cancel_transfer  \n",
       "4  cancel_transfer  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://s.cleanlab.ai/banking-intent-classification.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.529078Z",
     "iopub.status.busy": "2024-02-27T10:08:04.528777Z",
     "iopub.status.idle": "2024-02-27T10:08:04.532330Z",
     "shell.execute_reply": "2024-02-27T10:08:04.531878Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_texts, raw_labels = data[\"text\"].values, data[\"label\"].values\n",
    "\n",
    "raw_train_texts, raw_test_texts, raw_train_labels, raw_test_labels = train_test_split(raw_texts, raw_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.534253Z",
     "iopub.status.busy": "2024-02-27T10:08:04.533949Z",
     "iopub.status.idle": "2024-02-27T10:08:04.537398Z",
     "shell.execute_reply": "2024-02-27T10:08:04.536939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 10 classes.\n",
      "Classes: {'apple_pay_or_google_pay', 'lost_or_stolen_phone', 'getting_spare_card', 'change_pin', 'visa_or_mastercard', 'beneficiary_not_allowed', 'card_payment_fee_charged', 'card_about_to_expire', 'cancel_transfer', 'supported_cards_and_currencies'}\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(set(raw_train_labels))\n",
    "\n",
    "print(f\"This dataset has {num_classes} classes.\")\n",
    "print(f\"Classes: {set(raw_train_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first example in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.539406Z",
     "iopub.status.busy": "2024-02-27T10:08:04.539083Z",
     "iopub.status.idle": "2024-02-27T10:08:04.542208Z",
     "shell.execute_reply": "2024-02-27T10:08:04.541763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Label: getting_spare_card\n",
      "Example Text: can i have another card in addition to my first one?\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(f\"Example Label: {raw_train_labels[i]}\")\n",
    "print(f\"Example Text: {raw_train_texts[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored as two numpy arrays for each the train and test set:\n",
    "\n",
    "1. `raw_train_texts` and `raw_test_texts` store the customer service requests utterances in text format\n",
    "2. `raw_train_labels` and `raw_test_labels` store the intent categories (labels) for each example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to perform label enconding on the labels, cleanlab's functions require the labels for each example to be an interger integer in 0, 1, â€¦, num_classes - 1. We will use sklearn's `LabelEncoder` to encode our labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.544055Z",
     "iopub.status.busy": "2024-02-27T10:08:04.543876Z",
     "iopub.status.idle": "2024-02-27T10:08:04.547432Z",
     "shell.execute_reply": "2024-02-27T10:08:04.546977Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(raw_train_labels)\n",
    "\n",
    "train_labels = encoder.transform(raw_train_labels)\n",
    "test_labels = encoder.transform(raw_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Bringing Your Own Data (BYOD)?\n",
    "\n",
    "You can easily replace the above with your own text dataset, and continue with the rest of the tutorial.\n",
    "\n",
    "Your classes (and entries of `train_labels` / `test_labels`) should be represented as integer indices 0, 1, ..., num_classes - 1.\n",
    "For example, if your dataset has 7 examples from 3 classes, `train_labels` might be: `np.array([2,0,0,1,2,0,1])`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we convert the text strings into vectors better suited as inputs for our ML model. \n",
    "\n",
    "We will use numeric representations from a pretrained Transformer model as embeddings of our text. The [Sentence Transformers](https://huggingface.co/docs/hub/sentence-transformers) library offers simple methods to compute these embeddings for text data. Here, we load the pretrained `electra-small-discriminator` model, and then run our data through network to extract a vector embedding of each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:04.549392Z",
     "iopub.status.busy": "2024-02-27T10:08:04.549138Z",
     "iopub.status.idle": "2024-02-27T10:08:08.459677Z",
     "shell.execute_reply": "2024-02-27T10:08:08.459034Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /home/runner/.cache/torch/sentence_transformers/google_electra-small-discriminator. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/hostedtoolcache/Python/3.11.8/x64/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "transformer = SentenceTransformer('google/electra-small-discriminator')\n",
    "\n",
    "train_texts = transformer.encode(raw_train_texts)\n",
    "test_texts = transformer.encode(raw_test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our subsequent ML model will directly operate on elements of `train_texts` and `test_texts` in order to classify the customer service requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a classification model and use cleanlab to find potential label errors\n",
    "\n",
    "<a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical way to leverage pretrained networks for a particular classification task is to add a linear output layer and fine-tune the network parameters on the new data. However this can be computationally intensive. Alternatively, we can freeze the pretrained weights of the network and only train the output layer without having to rely on GPU(s). Here we do this conveniently by fitting a scikit-learn linear model on top of the extracted embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:08.462304Z",
     "iopub.status.busy": "2024-02-27T10:08:08.462114Z",
     "iopub.status.idle": "2024-02-27T10:08:08.464931Z",
     "shell.execute_reply": "2024-02-27T10:08:08.464409Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the `CleanLearning` object with our Logistic Regression model and use `find_label_issues` to identify potential label errors.\n",
    "\n",
    "`CleanLearning` provides a wrapper class that can easily be applied to any scikit-learn compatible model, which can be used to find potential label issues and train a more robust model if the original data contains noisy labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:08.466947Z",
     "iopub.status.busy": "2024-02-27T10:08:08.466562Z",
     "iopub.status.idle": "2024-02-27T10:08:08.469298Z",
     "shell.execute_reply": "2024-02-27T10:08:08.468765Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_n_folds = 5  # for efficiency; values like 5 or 10 will generally work better\n",
    "\n",
    "cl = CleanLearning(model, cv_n_folds=cv_n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:08.471088Z",
     "iopub.status.busy": "2024-02-27T10:08:08.470908Z",
     "iopub.status.idle": "2024-02-27T10:08:10.728584Z",
     "shell.execute_reply": "2024-02-27T10:08:10.727976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_issues = cl.find_label_issues(X=train_texts, labels=train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_label_issues` method above will perform cross validation to compute out-of-sample predicted probabilites for each example, which is used to identify label issues.\n",
    "\n",
    "This method returns a dataframe containing a label quality score for each example. These numeric scores lie between 0 and 1, where  lower scores indicate examples more likely to be mislabeled. The dataframe also contains a boolean column specifying whether or not each example is identified to have a label issue (indicating it is likely mislabeled). Note that the given and predicted labels here are encoded as intergers as that was the format expected by `cleanlab`, we will inverse transform them later in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.731429Z",
     "iopub.status.busy": "2024-02-27T10:08:10.730822Z",
     "iopub.status.idle": "2024-02-27T10:08:10.738192Z",
     "shell.execute_reply": "2024-02-27T10:08:10.737782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_label_issue</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.858371</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.547274</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.826228</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.966008</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.792449</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_label_issue  label_quality  given_label  predicted_label\n",
       "0           False       0.858371            6                6\n",
       "1           False       0.547274            3                3\n",
       "2           False       0.826228            7                7\n",
       "3           False       0.966008            8                8\n",
       "4           False       0.792449            4                4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issues.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the subset of examples flagged with label issues, and also sort by label quality score to find the indices of the 10 most likely mislabeled examples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.740271Z",
     "iopub.status.busy": "2024-02-27T10:08:10.739942Z",
     "iopub.status.idle": "2024-02-27T10:08:10.743643Z",
     "shell.execute_reply": "2024-02-27T10:08:10.743172Z"
    }
   },
   "outputs": [],
   "source": [
    "identified_issues = label_issues[label_issues[\"is_label_issue\"] == True]\n",
    "lowest_quality_labels = label_issues[\"label_quality\"].argsort()[:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.745627Z",
     "iopub.status.busy": "2024-02-27T10:08:10.745323Z",
     "iopub.status.idle": "2024-02-27T10:08:10.748173Z",
     "shell.execute_reply": "2024-02-27T10:08:10.747681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanlab found 44 potential label errors in the dataset.\n",
      "Here are indices of the top 10 most likely errors: \n",
      " [646 390 628 121 702 863 456 135 337 735]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"cleanlab found {len(identified_issues)} potential label errors in the dataset.\\n\"\n",
    "    f\"Here are indices of the top 10 most likely errors: \\n {lowest_quality_labels}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review some of the most likely label errors. To help us inspect these datapoints, we define a method to print any example from the dataset, together with its given (original) label and the suggested alternative label from cleanlab.\n",
    "\n",
    "We then display some of the top-ranked label issues identified by cleanlab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.750203Z",
     "iopub.status.busy": "2024-02-27T10:08:10.749880Z",
     "iopub.status.idle": "2024-02-27T10:08:10.752830Z",
     "shell.execute_reply": "2024-02-27T10:08:10.752387Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_as_df(index):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"text\": raw_train_texts, \n",
    "            \"given_label\": raw_train_labels,\n",
    "            \"predicted_label\": encoder.inverse_transform(label_issues[\"predicted_label\"]),\n",
    "        },\n",
    "    ).iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.754686Z",
     "iopub.status.busy": "2024-02-27T10:08:10.754369Z",
     "iopub.status.idle": "2024-02-27T10:08:10.761809Z",
     "shell.execute_reply": "2024-02-27T10:08:10.761289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>given_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>i was charged for getting cash.</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "      <td>card_payment_fee_charged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>can i change my pin on holiday?</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>will i be sent a new card before mine expires?</td>\n",
       "      <td>apple_pay_or_google_pay</td>\n",
       "      <td>card_about_to_expire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Would you rather fight one horse-sized duck or 100 duck-sized horses?</td>\n",
       "      <td>lost_or_stolen_phone</td>\n",
       "      <td>getting_spare_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>please tell me how to change my pin.</td>\n",
       "      <td>beneficiary_not_allowed</td>\n",
       "      <td>change_pin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      text  \\\n",
       "646                                        i was charged for getting cash.   \n",
       "390                                        can i change my pin on holiday?   \n",
       "628                         will i be sent a new card before mine expires?   \n",
       "121  Would you rather fight one horse-sized duck or 100 duck-sized horses?   \n",
       "702                                   please tell me how to change my pin.   \n",
       "\n",
       "                 given_label           predicted_label  \n",
       "646     card_about_to_expire  card_payment_fee_charged  \n",
       "390  beneficiary_not_allowed                change_pin  \n",
       "628  apple_pay_or_google_pay      card_about_to_expire  \n",
       "121     lost_or_stolen_phone        getting_spare_card  \n",
       "702  beneficiary_not_allowed                change_pin  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_as_df(lowest_quality_labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are very clear label errors that cleanlab has identified in this data! Note that the `given_label` does not correctly reflect the intent of these requests, whoever produced this dataset made many mistakes that are important to address before modeling the data.\n",
    "\n",
    "cleanlab has shortlisted the most likely label errors to speed up your data cleaning process. With this list, you can decide whether to fix these label issues or remove ambiguous examples from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a more robust model from noisy labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the label issues manually may be time-consuming, but cleanlab can filter these noisy examples and train a model on the remaining clean data for you automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To establish a baseline, let's first train and evaluate our original Logistic Regression model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.763853Z",
     "iopub.status.busy": "2024-02-27T10:08:10.763568Z",
     "iopub.status.idle": "2024-02-27T10:08:10.990934Z",
     "shell.execute_reply": "2024-02-27T10:08:10.990443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Test accuracy of original model: 0.87\n"
     ]
    }
   ],
   "source": [
    "baseline_model = LogisticRegression(max_iter=400)  # note we first re-instantiate the model\n",
    "baseline_model.fit(X=train_texts, y=train_labels)\n",
    "\n",
    "preds = baseline_model.predict(test_texts)\n",
    "acc_og = accuracy_score(test_labels, preds)\n",
    "print(f\"\\n Test accuracy of original model: {acc_og}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a baseline, let's check if using `CleanLearning` improves our test accuracy.\n",
    "\n",
    "`CleanLearning` provides a wrapper that can be applied to any scikit-learn compatible model. The resulting model object can be used in the same manner, but it will now train more robustly if the data has noisy labels.\n",
    "\n",
    "We can use the same `CleanLearning` object defined above, and  pass the label issues we already computed into `.fit()` via the `label_issues` argument. This accelerates things; if we did not provide the label issues, then they would be recomputed via cross-validation. After that `CleanLearning` simply deletes the examples with label issues and retrains your model on the remaining data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:10.994390Z",
     "iopub.status.busy": "2024-02-27T10:08:10.993494Z",
     "iopub.status.idle": "2024-02-27T10:08:11.171328Z",
     "shell.execute_reply": "2024-02-27T10:08:11.170803Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of cleanlab's model: 0.89\n"
     ]
    }
   ],
   "source": [
    "cl.fit(X=train_texts, labels=train_labels, label_issues=cl.get_label_issues())\n",
    "\n",
    "pred_labels = cl.predict(test_texts)\n",
    "acc_cl = accuracy_score(test_labels, pred_labels)\n",
    "print(f\"Test accuracy of cleanlab's model: {acc_cl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test set accuracy slightly improved as a result of the data cleaning. Note that this will not always be the case, especially when we are evaluating on test data that are themselves noisy. The best practice is to run cleanlab to identify potential label issues and then manually review them, before blindly trusting any accuracy metrics. In particular, the most effort should be made to ensure high-quality test data, which is supposed to reflect the expected performance of our model during deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T10:08:11.173944Z",
     "iopub.status.busy": "2024-02-27T10:08:11.173573Z",
     "iopub.status.idle": "2024-02-27T10:08:11.177321Z",
     "shell.execute_reply": "2024-02-27T10:08:11.176852Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "highlighted_indices = [646, 390, 628, 702]  # check these examples were found in find_label_issues\n",
    "if not all(x in identified_issues.index for x in highlighted_indices):\n",
    "    raise Exception(\"Some highlighted examples are missing from ranked_label_issues.\")\n",
    "\n",
    "# Also check that cleanlab has improved prediction accuracy\n",
    "if acc_og >= acc_cl:\n",
    "    raise Exception(\"Cleanlab training failed to improve model accuracy.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Text x TensorFlow",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
