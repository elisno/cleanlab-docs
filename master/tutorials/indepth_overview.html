<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />

        <script async src="https://www.googletagmanager.com/gtag/js?id=G-EV8RVEFX82"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            
            gtag('config', 'G-EV8RVEFX82');
            
        </script>
    <meta property="og:title" content="The Workflows of Data-centric AI for Classification with Noisy Labels" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://docs.cleanlab.ai/master/tutorials/indepth_overview.html" />
<meta property="og:site_name" content="cleanlab" />
<meta property="og:description" content="In this tutorial, you will learn how to easily incorporate cleanlab into your ML development workflows to: Automatically find issues such as label errors, outliers and near duplicates lurking in yo..." />
<meta property="og:image" content="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/clos-preview-card.png" />
<meta property="og:image:alt" content="cleanlab" />
<meta name="description" content="In this tutorial, you will learn how to easily incorporate cleanlab into your ML development workflows to: Automatically find issues such as label errors, outliers and near duplicates lurking in yo..." />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Image Classification with PyTorch and Cleanlab" href="image.html" /><link rel="prev" title="Detecting Issues in Tabular Data (Numeric/Categorical columns) with Datalab" href="datalab/tabular.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/a4483476d449f2f05a4c7cde329e72358099cc07/cleanlab/cleanlab_favicon.svg"/><!-- Generated with Sphinx 7.1.2 and Furo 2023.09.10 -->
        <title>The Workflows of Data-centric AI for Classification with Noisy Labels - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=96bccb3e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a style="padding-bottom: 0px;" class="sidebar-brand" href="../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo" />
    </div>
    
    <span style="margin-bottom:0px" class="sidebar-brand-text">
        cleanlab
    </span>
    
</a>

<div class="centered">
    <a style="margin-top: 6px;" class="github-button" href="https://github.com/cleanlab/cleanlab" data-size="large" data-show-count="true"
    aria-label="Star cleanlab/cleanlab on GitHub">Star</a>
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="datalab/index.html">Datalab Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Datalab Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="datalab/datalab_quickstart.html">Detecting Common Data Issues with Datalab</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/datalab_advanced.html">Advanced Data Auditing with Datalab</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/text.html">Text Dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/tabular.html">Tabular Data (Numeric/Categorical)</a></li>
</ul>
</li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Workflows of Data-Centric AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="text.html">Text Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="tabular.html">Tabular Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio.html">Audio Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_health.html">Find Dataset-level Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="outliers.html">Identifying Outliers</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiannotator.html">Improving Consensus Labels for Multiannotator Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="multilabel_classification.html">Multi-Label Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="regression.html">Noisy Labels in Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="token_classification.html">Token Classification (text)</a></li>
<li class="toctree-l1"><a class="reference internal" href="segmentation.html">Image Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection.html">Object Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_probs_cross_val.html">Predicted Probabilities via Cross Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/datalab/index.html">datalab</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of datalab</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cleanlab/datalab/guide/index.html">Datalab guides</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of Datalab guides</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/guide/issue_type_description.html">Datalab Issue Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/guide/custom_issue_manager.html">Creating Your Own Issues Manager</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/datalab.html">datalab</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of internal</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/data_issues.html">data_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/issue_finder.html">issue_finder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/factory.html">factory</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/index.html">issue_manager</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of issue_manager</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/issue_manager.html">Base issue_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/label.html">label</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/outlier.html">outlier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/duplicate.html">duplicate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/noniid.html">noniid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/imbalance.html">imbalance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/underperforming_group.html">underperforming_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/null.html">null</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/data_valuation.html">data_valuation</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/regression/index.html">regression</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of regression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/regression/label.html">label</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/report.html">report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/task.html">task</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/count.html">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/dataset.html">dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/outlier.html">outlier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/multiannotator.html">multiannotator</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/multilabel_classification/index.html">multilabel_classification</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of multilabel_classification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/dataset.html">dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/regression/index.html">regression</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of regression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/regression/rank.html">regression.rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/regression/learn.html">regression.learn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/token_classification/index.html">token_classification</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of token_classification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/segmentation/index.html">segmentation</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of segmentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/object_detection/index.html">object_detection</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of object_detection</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/benchmarking/index.html">benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of benchmarking</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/benchmarking/noise_generation.html">noise_generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/models/index.html">models</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/models/keras.html">keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/models/fasttext.html">fasttext</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/experimental/index.html">experimental</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of experimental</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/label_issues_batched.html">label_issues_batched</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/mnist_pytorch.html">mnist_pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/coteaching.html">coteaching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/cifar_cnn.html">cifar_cnn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of internal</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/label_quality_utils.html">label_quality_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/multilabel_utils.html">multilabel_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/multilabel_scorer.html">multilabel_scorer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/outlier.html">outlier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/token_classification_utils.html">token_classification_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/validation.html">validation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/datalab/guide/index.html">Datalab issue types</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of Datalab issue types</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/guide/issue_type_description.html">Datalab Issue Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/guide/custom_issue_manager.html">Creating Your Own Issues Manager</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab/blob/master/CONTRIBUTING.md">How to contribute</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab Studio (Easy Mode)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://help.cleanlab.ai">Cleanlab Studio Docs</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/cleanlab-docs/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/cleanlab-docs/master/"
                >developer</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.5.0"
                class="reference internal"
                href="/cleanlab-docs/v2.5.0/"
                >v2.5.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.4.0"
                class="reference internal"
                href="/cleanlab-docs/v2.4.0/"
                >v2.4.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.3.1"
                class="reference internal"
                href="/cleanlab-docs/v2.3.1/"
                >v2.3.1</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.3.0"
                class="reference internal"
                href="/cleanlab-docs/v2.3.0/"
                >v2.3.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.2.0"
                class="reference internal"
                href="/cleanlab-docs/v2.2.0/"
                >v2.2.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.1.0"
                class="reference internal"
                href="/cleanlab-docs/v2.1.0/"
                >v2.1.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.0.0"
                class="reference internal"
                href="/cleanlab-docs/v2.0.0/"
                >v2.0.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v1.0.1"
                class="reference internal"
                href="/cleanlab-docs/v1.0.1/"
                >v1.0.1</a
            >
        </li>
        
    </ul>
</div>

<br>
<br>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number) && !path_arr.includes("stable")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">master</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 <style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }

    .output_area {
        max-height: 300px;
        overflow: auto;
    }

    .dataframe {
        background: #D7D7D7;
    }

    th {
        color:black;
    }
</style>

<script type="text/javascript">
    window.addEventListener('load', () => {
        const h1_element = document.getElementsByTagName("h1");
        h1_element[0].insertAdjacentHTML("afterend", `
        <p>
            <a style="background-color:white;color:black;padding:4px 12px;text-decoration:none;display:inline-block;border-radius:8px;box-shadow:0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 3px 10px 0 rgba(0, 0, 0, 0.19)" href="https://colab.research.google.com/github/elisno/cleanlab-docs/blob/master/master/tutorials/indepth_overview.ipynb" target="_blank">
            <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="" style="width:40px;height:40px;vertical-align:middle">
            <span style="vertical-align:middle">Run in Google Colab</span>
            </a>
        </p>
        `);
    })

</script><section id="The-Workflows-of-Data-centric-AI-for-Classification-with-Noisy-Labels">
<h1>The Workflows of Data-centric AI for Classification with Noisy Labels<a class="headerlink" href="#The-Workflows-of-Data-centric-AI-for-Classification-with-Noisy-Labels" title="Permalink to this heading">#</a></h1>
<p>In this tutorial, you will learn how to easily incorporate <a class="reference external" href="https://github.com/cleanlab/cleanlab">cleanlab</a> into your ML development workflows to:</p>
<ul class="simple">
<li><p>Automatically find issues such as label errors, outliers and near duplicates lurking in your classification data.</p></li>
<li><p>Score the label quality of every example in your dataset.</p></li>
<li><p>Train robust models in the presence of label issues.</p></li>
<li><p>Identify overlapping classes that you can merge to make the learning task less ambiguous.</p></li>
<li><p>Generate an overall label health score to track improvements in your labels as you clean your datasets over time.</p></li>
</ul>
<p>This tutorial provides an in-depth survey of many possible different ways that cleanlab can be utilized for Data-Centric AI. If you have a different use-case in mind that is not supported, please <a class="reference external" href="https://github.com/cleanlab/cleanlab/issues">tell us about it</a>! While this tutorial focuses on standard multi-class (and binary) classification datasets, cleanlab also supports other tasks including: <a class="reference external" href="multiannotator.html">data labeled by multiple annotators</a>, <a class="reference internal" href="../cleanlab/filter.html#cleanlab.filter.find_label_issues"><span class="std std-ref">multi-label
classification</span></a>, and <a class="reference external" href="token_classification.html">token classification of text</a>.</p>
<p><strong>cleanlab is grounded in theory and science</strong>. Learn more:</p>
<p><a class="reference external" href="https://cleanlab.ai/research">Research Publications</a> | <a class="reference external" href="https://labelerrors.com/">Label Errors found by cleanlab</a> | <a class="reference external" href="https://github.com/cleanlab/examples">Examples using cleanlab</a></p>
<section id="Install-dependencies-and-import-them">
<h2>Install dependencies and import them<a class="headerlink" href="#Install-dependencies-and-import-them" title="Permalink to this heading">#</a></h2>
<p>You can use pip to install all packages required for this tutorial as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>!pip install sklearn matplotlib
!pip install cleanlab[datalab]
# Make sure to install the version corresponding to this tutorial
# E.g. if viewing master branch documentation:
#     !pip install git+https://github.com/cleanlab/cleanlab.git
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cleanlab</span>
<span class="kn">from</span> <span class="nn">cleanlab</span> <span class="kn">import</span> <span class="n">Datalab</span>
<span class="kn">from</span> <span class="nn">cleanlab.classification</span> <span class="kn">import</span> <span class="n">CleanLearning</span>
<span class="kn">from</span> <span class="nn">cleanlab.benchmarking</span> <span class="kn">import</span> <span class="n">noise_generation</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>
<span class="kn">from</span> <span class="nn">numpy.random</span> <span class="kn">import</span> <span class="n">multivariate_normal</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</pre></div>
</div>
</div>
</section>
<section id="Create-the-data-(can-skip-these-details)">
<h2>Create the data (can skip these details)<a class="headerlink" href="#Create-the-data-(can-skip-these-details)" title="Permalink to this heading">#</a></h2>
<details><summary><p>See the code for data generation <strong>(click to expand)</strong></p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">def</span> <span class="nf">make_data</span><span class="p">(</span>
    <span class="n">means</span><span class="o">=</span><span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]],</span>
    <span class="n">covs</span><span class="o">=</span><span class="p">[</span>
        <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
        <span class="p">[[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>
    <span class="p">],</span>
    <span class="n">sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="n">avg_trace</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>  <span class="c1"># set to None for non-reproducible randomness</span>
<span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

    <span class="n">K</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>  <span class="c1"># number of classes</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_labels</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">means</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">covs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">test_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
                <span class="n">mean</span><span class="o">=</span><span class="n">means</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cov</span><span class="o">=</span><span class="n">covs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">idx</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])]))</span>
        <span class="n">test_labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">idx</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sizes</span><span class="p">[</span><span class="n">idx</span><span class="p">])]))</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

    <span class="c1"># Compute p(y=k) the prior distribution over true labels.</span>
    <span class="n">py_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

    <span class="n">noise_matrix_true</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noise_matrix_from_trace</span><span class="p">(</span>
        <span class="n">K</span><span class="p">,</span>
        <span class="n">trace</span><span class="o">=</span><span class="n">avg_trace</span> <span class="o">*</span> <span class="n">K</span><span class="p">,</span>
        <span class="n">py</span><span class="o">=</span><span class="n">py_true</span><span class="p">,</span>
        <span class="n">valid_noise_matrix</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Generate our noisy labels using the noise_marix.</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noisy_labels</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">noise_matrix_true</span><span class="p">)</span>
    <span class="n">s_test</span> <span class="o">=</span> <span class="n">noise_generation</span><span class="o">.</span><span class="n">generate_noisy_labels</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">noise_matrix_true</span><span class="p">)</span>
    <span class="n">ps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>  <span class="c1"># Prior distribution over noisy labels</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">X_train</span><span class="p">,</span>
        <span class="s2">&quot;true_labels&quot;</span><span class="p">:</span> <span class="n">y_train</span><span class="p">,</span>  <span class="c1"># You never get to see these perfect labels.</span>
        <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">s</span><span class="p">,</span>  <span class="c1"># Instead, you have these labels, which have some errors.</span>
        <span class="s2">&quot;test_data&quot;</span><span class="p">:</span> <span class="n">X_test</span><span class="p">,</span>
        <span class="s2">&quot;test_labels&quot;</span><span class="p">:</span> <span class="n">y_test</span><span class="p">,</span>  <span class="c1"># Perfect labels used for &quot;true&quot; measure of model&#39;s performance during deployment.</span>
        <span class="s2">&quot;noisy_test_labels&quot;</span><span class="p">:</span> <span class="n">s_test</span><span class="p">,</span>  <span class="c1"># With IID train/test split, you&#39;d have these labels, which also have some errors.</span>
        <span class="s2">&quot;ps&quot;</span><span class="p">:</span> <span class="n">ps</span><span class="p">,</span>
        <span class="s2">&quot;py_true&quot;</span><span class="p">:</span> <span class="n">py_true</span><span class="p">,</span>
        <span class="s2">&quot;noise_matrix_true&quot;</span><span class="p">:</span> <span class="n">noise_matrix_true</span><span class="p">,</span>
        <span class="s2">&quot;class_names&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;purple&quot;</span><span class="p">,</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="s2">&quot;seafoam green&quot;</span><span class="p">,</span> <span class="s2">&quot;yellow&quot;</span><span class="p">],</span>
    <span class="p">}</span>


<span class="n">data_dict</span> <span class="o">=</span> <span class="n">make_data</span><span class="p">()</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>  <span class="c1"># Map data_dict to variables in namespace</span>
    <span class="n">exec</span><span class="p">(</span><span class="n">key</span> <span class="o">+</span> <span class="s2">&quot;=val&quot;</span><span class="p">)</span>

<span class="c1"># Display dataset visually using matplotlib</span>
<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">circles</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
            <span class="s2">&quot;o&quot;</span><span class="p">,</span>
            <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
            <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span>
            <span class="n">markersize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
            <span class="n">markeredgewidth</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span>
        <span class="p">)</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</details><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">true_errors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">true_labels</span> <span class="o">!=</span> <span class="n">labels</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">true_errors</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;A realistic, messy dataset with 4 classes&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_8_0.png" src="../_images/tutorials_indepth_overview_8_0.png" />
</div>
</div>
<p>The figure above represents a toy dataset well use to demonstrate various cleanlab functionality. In this data, the features <em>X</em> are 2-dimensional and examples are colored according to their <em>given</em> label above.</p>
<p>Like <a class="reference external" href="https://labelerrors.com/">many real-world datasets</a>, the given label happens to be incorrect for some of the examples (<strong>circled in red</strong>) in this dataset!</p>
</section>
<section id="Workflow-1:-Use-Datalab-to-detect-many-types-of-issues">
<h2><strong>Workflow 1:</strong> Use Datalab to detect many types of issues<a class="headerlink" href="#Workflow-1:-Use-Datalab-to-detect-many-types-of-issues" title="Permalink to this heading">#</a></h2>
<p>Datalab offers an easy interface to detect all sorts of common real-world issue in your dataset. Internally it uses many data quality algorithms, and these methods can also be directly invoked  as demonstrated in some of the subsequent workflows here.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Datalab offers several ways of loading the data</span>
<span class="c1"># well simply wrap the training features and noisy labels in a dictionary.</span>
<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="n">data</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">labels</span><span class="p">}</span>

<span class="c1"># get out of sample predicted probabilities via cross-validation.</span>
<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>All that is need to audit your data is initalize a Datalab object with your dataset and call <code class="docutils literal notranslate"><span class="pre">find_issues()</span></code>.</p>
<p>Pass in the predicted probabilities and feature embeddings for your data and Datalab will do all the work! You do not necessarily need to provide all of this information depending on which types of issues you are interested in, but the more inputs you provide, the more types of issues <code class="docutils literal notranslate"><span class="pre">Datalab</span></code> can detect in your data. Using a better model to produce these inputs will ensure cleanlab more accurately estimates issues. Make sure that the columns of your <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> are properly ordered with
respect to the ordering of classes, which for Datalab is: lexicographically sorted by class name.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lab</span> <span class="o">=</span> <span class="n">Datalab</span><span class="p">(</span><span class="n">data_dict</span><span class="p">,</span> <span class="n">label_name</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">lab</span><span class="o">.</span><span class="n">find_issues</span><span class="p">(</span><span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Finding null issues ...
Finding label issues ...
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Finding outlier issues ...
Fitting OOD estimator based on provided features ...
Finding near_duplicate issues ...
Finding non_iid issues ...
Finding class_imbalance issues ...
Finding underperforming_group issues ...

Audit complete. 78 issues found in the dataset.
</pre></div></div>
</div>
<p>After the audit is complete, review the findings using the <code class="docutils literal notranslate"><span class="pre">report</span></code> method:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lab</span><span class="o">.</span><span class="n">report</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Here is a summary of the different kinds of issues found in the data:

    issue_type  num_issues
         label          64
       outlier           7
near_duplicate           6
       non_iid           1

Dataset Information: num_examples: 250, num_classes: 4


----------------------- label issues -----------------------

About this issue:
        Examples whose given label is estimated to be potentially incorrect
    (e.g. due to annotation error) are flagged as having label issues.


Number of examples with this issue: 64
Overall dataset quality in terms of this issue: 0.7560

Examples representing most severe instances of this issue:
     is_label_issue   label_score  given_label  predicted_label
99             True  5.637318e-08            1                0
8              True  3.896262e-07            1                0
64             True  3.548391e-05            1                0
107            True  7.923417e-05            3                1
10             True  9.375075e-05            2                1


---------------------- outlier issues ----------------------

About this issue:
        Examples that are very different from the rest of the dataset
    (i.e. potentially out-of-distribution or rare/anomalous instances).


Number of examples with this issue: 7
Overall dataset quality in terms of this issue: 0.3454

Examples representing most severe instances of this issue:
     is_outlier_issue  outlier_score
147              True       0.014051
10               True       0.020451
249              True       0.042594
132              True       0.043859
189              True       0.045954


------------------ near_duplicate issues -------------------

About this issue:
        A (near) duplicate issue refers to two or more examples in
    a dataset that are extremely similar to each other, relative
    to the rest of the dataset.  The examples flagged with this issue
    may be exactly duplicated, or lie atypically close together when
    represented as vectors (i.e. feature embeddings).


Number of examples with this issue: 6
Overall dataset quality in terms of this issue: 0.6120

Examples representing most severe instances of this issue:
     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor
3                       True              0.023714                [58]                      0.007136
58                      True              0.023714                 [3]                      0.007136
119                     True              0.107266               [103]                      0.033738
103                     True              0.107266               [119]                      0.033738
238                     True              0.119505               [236]                      0.037843


---------------------- non_iid issues ----------------------

About this issue:
        Whether the dataset exhibits statistically significant
    violations of the IID assumption like:
    changepoints or shift, drift, autocorrelation, etc.
    The specific violation considered is whether the
    examples are ordered such that almost adjacent examples
    tend to have more similar feature values.


Number of examples with this issue: 1
Overall dataset quality in terms of this issue: 0.0000

Examples representing most severe instances of this issue:
     is_non_iid_issue  non_iid_score
222              True       0.614915
122             False       0.624422
126             False       0.625965
119             False       0.626079
118             False       0.627675

Additional Information:
p-value: 0.0
</pre></div></div>
</div>
</section>
<section id="Workflow-2:-Use-CleanLearning-for-more-robust-Machine-Learning">
<h2><strong>Workflow 2:</strong> Use CleanLearning for more robust Machine Learning<a class="headerlink" href="#Workflow-2:-Use-CleanLearning-for-more-robust-Machine-Learning" title="Permalink to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># CleanLearning: Machine Learning with cleaned data (given messy, real-world data)</span>
<span class="n">cl</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Fit model to messy, real-world data, automatically training on cleaned data.</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># See the label quality for every example, which data has issues, and more.</span>
<span class="n">cl</span><span class="o">.</span><span class="n">get_label_issues</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>is_label_issue</th>
      <th>label_quality</th>
      <th>given_label</th>
      <th>predicted_label</th>
      <th>sample_weight</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>0.695223</td>
      <td>0</td>
      <td>0</td>
      <td>1.323529</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>0.523015</td>
      <td>0</td>
      <td>0</td>
      <td>1.323529</td>
    </tr>
    <tr>
      <th>2</th>
      <td>True</td>
      <td>0.013720</td>
      <td>3</td>
      <td>0</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>0.675727</td>
      <td>0</td>
      <td>0</td>
      <td>1.323529</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>0.646521</td>
      <td>0</td>
      <td>0</td>
      <td>1.323529</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<section id="Clean-Learning-=-Machine-Learning-with-cleaned-data">
<h3>Clean Learning = Machine Learning with cleaned data<a class="headerlink" href="#Clean-Learning-=-Machine-Learning-with-cleaned-data" title="Permalink to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For comparison, this is how you would have trained your model normally (without Cleanlab)</span>
<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy using yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="w"> </span><span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># But CleanLearning can do anything yourFavoriteModel can do, but enhanced.</span>
<span class="c1"># For example, CleanLearning gives you predictions (just like yourFavoriteModel)</span>
<span class="c1"># but the magic is that CleanLearning was trained as if your data did not have label errors.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">cl</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="w"> </span><span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Accuracy using yourFavoriteModel: 83%
Accuracy using yourFavoriteModel (+ CleanLearning): 86%
</pre></div></div>
</div>
<p>Note! <em>Accuracy</em> refers to the accuracy with respect to the <em>true</em> error-free labels of a test set., i.e. what we actually care about in practice because thats what real-world model performance is based on. If you dont have a clean test set, you can use cleanlab to make one :)</p>
</section>
</section>
<section id="Workflow-3:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code">
<h2><strong>Workflow 3:</strong> Use CleanLearning to find_label_issues in one line of code<a class="headerlink" href="#Workflow-3:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code" title="Permalink to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># One line of code. Literally.</span>
<span class="n">issues</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="n">issues</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>is_label_issue</th>
      <th>label_quality</th>
      <th>given_label</th>
      <th>predicted_label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>False</td>
      <td>0.695223</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>False</td>
      <td>0.523015</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>True</td>
      <td>0.013720</td>
      <td>3</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>False</td>
      <td>0.675727</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>False</td>
      <td>0.646521</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<section id="Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">
<h3>Visualize the twenty examples with lowest label quality to see if Cleanlab works.<a class="headerlink" href="#Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works." title="Permalink to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lowest_quality_labels</span> <span class="o">=</span> <span class="n">issues</span><span class="p">[</span><span class="s2">&quot;label_quality&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[:</span><span class="mi">20</span><span class="p">]</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">lowest_quality_labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;The 20 lowest label quality examples&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_25_0.png" src="../_images/tutorials_indepth_overview_25_0.png" />
</div>
</div>
<p>Above, the top 20 label issues circled in red are found automatically using cleanlab (no true labels given).</p>
<p>If youve already computed the label issues using <code class="docutils literal notranslate"><span class="pre">CleanLearning</span></code>, you can pass them into <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and it will train <strong>much</strong> faster (skips label-issue identification step).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CleanLearning can train faster if issues are provided at fitting time.</span>
<span class="n">cl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">label_issues</span><span class="o">=</span><span class="n">issues</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>CleanLearning(clf=LogisticRegression(random_state=0),
              find_label_issues_kwargs={&#x27;confident_joint&#x27;: array([[68,  0,  8,  8],
       [ 5, 46,  3,  0],
       [15,  3, 31, 14],
       [ 2,  1, 12, 34]]),
                                        &#x27;min_examples_per_class&#x27;: 10},
              seed=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" ><label for="sk-estimator-id-1" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;CleanLearning<span class="sk-estimator-doc-link ">i<span>Not fitted</span></span></label><div class="sk-toggleable__content "><pre>CleanLearning(clf=LogisticRegression(random_state=0),
              find_label_issues_kwargs={&#x27;confident_joint&#x27;: array([[68,  0,  8,  8],
       [ 5, 46,  3,  0],
       [15,  3, 31, 14],
       [ 2,  1, 12, 34]]),
                                        &#x27;min_examples_per_class&#x27;: 10},
              seed=0)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label  sk-toggleable__label-arrow ">clf: LogisticRegression</label><div class="sk-toggleable__content "><pre>LogisticRegression(random_state=0)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;LogisticRegression<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html">?<span>Documentation for LogisticRegression</span></a></label><div class="sk-toggleable__content "><pre>LogisticRegression(random_state=0)</pre></div> </div></div></div></div></div></div></div></div></div></div>
</div>
</section>
</section>
<section id="Workflow-4:-Use-cleanlab-to-find-dataset-level-and-class-level-issues">
<h2><strong>Workflow 4:</strong> Use cleanlab to find dataset-level and class-level issues<a class="headerlink" href="#Workflow-4:-Use-cleanlab-to-find-dataset-level-and-class-level-issues" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Did you notice that the yellow and seafoam green class above are overlapping?</p></li>
<li><p>How can a model ever know (or learn) whats ground truth inside the yellow distribution?</p></li>
<li><p>If these two classes were merged, the model can learn more accurately from 3 classes (versus 4).</p></li>
</ul>
<p>cleanlab automatically finds data-set level issues like this, in one line of code. Check this out!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cleanlab</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">find_overlapping_classes</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">confident_joint</span><span class="o">=</span><span class="n">cl</span><span class="o">.</span><span class="n">confident_joint</span><span class="p">,</span>  <span class="c1"># cleanlab uses the confident_joint internally to quantify label noise (see cleanlab.count.compute_confident_joint)</span>
    <span class="n">class_names</span><span class="o">=</span><span class="n">class_names</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Class Name A</th>
      <th>Class Name B</th>
      <th>Class Index A</th>
      <th>Class Index B</th>
      <th>Num Overlapping Examples</th>
      <th>Joint Probability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>seafoam green</td>
      <td>yellow</td>
      <td>2</td>
      <td>3</td>
      <td>26</td>
      <td>0.104</td>
    </tr>
    <tr>
      <th>1</th>
      <td>purple</td>
      <td>seafoam green</td>
      <td>0</td>
      <td>2</td>
      <td>23</td>
      <td>0.092</td>
    </tr>
    <tr>
      <th>2</th>
      <td>purple</td>
      <td>yellow</td>
      <td>0</td>
      <td>3</td>
      <td>10</td>
      <td>0.040</td>
    </tr>
    <tr>
      <th>3</th>
      <td>blue</td>
      <td>seafoam green</td>
      <td>1</td>
      <td>2</td>
      <td>6</td>
      <td>0.024</td>
    </tr>
    <tr>
      <th>4</th>
      <td>purple</td>
      <td>blue</td>
      <td>0</td>
      <td>1</td>
      <td>5</td>
      <td>0.020</td>
    </tr>
    <tr>
      <th>5</th>
      <td>blue</td>
      <td>yellow</td>
      <td>1</td>
      <td>3</td>
      <td>1</td>
      <td>0.004</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Do the results surprise you? Did you expect the purple and seafoam green to also have so much overlap?</p>
<p>There are two things being happening here:</p>
<ol class="arabic simple">
<li><p><strong>Distribution Overlap</strong>: The green distribution has huge variance and overlaps with other distributions.</p>
<ul class="simple">
<li><p>Cleanlab handles this for you: read the theory behind cleanlab for overlapping classes here: <a class="reference external" href="https://arxiv.org/abs/1705.01936">https://arxiv.org/abs/1705.01936</a></p></li>
</ul>
</li>
<li><p><strong>Label Issues</strong>: A ton of examples (which actually belong to the purple class) have been mislabeled as green in our dataset.</p></li>
</ol>
<section id="Now,-let's-see-what-happens-if-we-merge-classes-%22seafoam-green%22-and-%22yellow%22">
<h3>Now, lets see what happens if we merge classes seafoam green and yellow<a class="headerlink" href="#Now,-let's-see-what-happens-if-we-merge-classes-%22seafoam-green%22-and-%22yellow%22" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The top two classes found automatically by <code class="docutils literal notranslate"><span class="pre">cleanlab.dataset.find_overlapping_classes()</span></code></p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yourFavoriteModel1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Original classes] Accuracy of yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="w"> </span><span class="n">test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">merged_labels</span><span class="p">,</span> <span class="n">merged_test_labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">labels</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_labels</span><span class="p">)</span>

<span class="c1"># Merge classes: map all yellow-labeled examples to seafoam green</span>
<span class="n">merged_labels</span><span class="p">[</span><span class="n">merged_labels</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">merged_test_labels</span><span class="p">[</span><span class="n">merged_test_labels</span> <span class="o">==</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Re-run our comparison. Re-run your model on the newly labeled dataset.</span>
<span class="n">yourFavoriteModel2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">merged_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Modified classes] Accuracy of yourFavoriteModel: </span><span class="si">{</span><span class="n">yourFavoriteModel2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="w"> </span><span class="n">merged_test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Re-run CleanLearning as well.</span>
<span class="n">yourFavoriteModel3</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">cl3</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">cl3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">merged_labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Modified classes] Accuracy of yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">cl3</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span><span class="w"> </span><span class="n">merged_test_labels</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[Original classes] Accuracy of yourFavoriteModel: 83%
[Modified classes] Accuracy of yourFavoriteModel: 94%
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[Modified classes] Accuracy of yourFavoriteModel (+ CleanLearning): 96%
</pre></div></div>
</div>
<p>While on one hand thats a huge improvement, its important to remember that choosing among three classes is an easier task than choosing among four classes, so its not fair to directly compare these numbers.</p>
<p>Instead, the big takeaway is if you get to choose your classes, combining overlapping classes can make the learning task easier for your model. But if you have lots of classes, how do you know which ones to merge?? Thats when you use <code class="docutils literal notranslate"><span class="pre">cleanlab.dataset.find_overlapping_classes</span></code>.</p>
</section>
</section>
<section id="Workflow-5:-Clean-your-test-set-too-if-you're-doing-ML-with-noisy-labels!">
<h2><strong>Workflow 5:</strong> Clean your test set too if youre doing ML with noisy labels!<a class="headerlink" href="#Workflow-5:-Clean-your-test-set-too-if-you're-doing-ML-with-noisy-labels!" title="Permalink to this heading">#</a></h2>
<p>If your test and training data were randomly split (IID), then be aware that your test labels are likely noisy too! It is thus important to fix label issues in them before we can trust measures like test accuracy.</p>
<ul class="simple">
<li><p>More about what can go wrong if you dont use a clean test set <a class="reference external" href="https://arxiv.org/abs/2103.14749">in this paper</a>.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Fit your model on noisily labeled train data</span>
<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Get predicted probabilities for test data (these are out-of-sample)</span>
<span class="n">my_test_pred_probs</span> <span class="o">=</span> <span class="n">yourFavoriteModel</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>
<span class="n">my_test_preds</span> <span class="o">=</span> <span class="n">my_test_pred_probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># predicted labels</span>

<span class="c1"># Find label issues in the test data</span>
<span class="n">issues_test</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">noisy_test_labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">my_test_pred_probs</span><span class="p">)</span>

<span class="c1"># You should inspect issues_test and fix issues to ensure high-quality test data labels.</span>
<span class="n">corrected_test_labels</span> <span class="o">=</span> <span class="n">test_labels</span>  <span class="c1"># Here we&#39;ll pretend you have done this perfectly :)</span>

<span class="c1"># Fit more robust version of model on noisily labeled training data</span>
<span class="n">cl</span> <span class="o">=</span> <span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">cl_test_preds</span> <span class="o">=</span> <span class="n">cl</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Noisy Test Accuracy (on given test labels) using yourFavoriteModel: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">noisy_test_labels</span><span class="p">,</span><span class="w"> </span><span class="n">my_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Noisy Test Accuracy (on given test labels) using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">noisy_test_labels</span><span class="p">,</span><span class="w"> </span><span class="n">cl_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual Test Accuracy (on corrected test labels) using yourFavoriteModel: </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">corrected_test_labels</span><span class="p">,</span><span class="w"> </span><span class="n">my_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Actual Test Accuracy (on corrected test labels) using yourFavoriteModel (+ CleanLearning): </span><span class="si">{</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">corrected_test_labels</span><span class="p">,</span><span class="w"> </span><span class="n">cl_test_preds</span><span class="p">)</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 Noisy Test Accuracy (on given test labels) using yourFavoriteModel: 69%
 Noisy Test Accuracy (on given test labels) using yourFavoriteModel (+ CleanLearning): 71%
Actual Test Accuracy (on corrected test labels) using yourFavoriteModel: 83%
Actual Test Accuracy (on corrected test labels) using yourFavoriteModel (+ CleanLearning): 86%
</pre></div></div>
</div>
</section>
<section id="Workflow-6:-One-score-to-rule-them-all----use-cleanlab's-overall-dataset-health-score">
<h2><strong>Workflow 6:</strong> One score to rule them all  use cleanlabs overall dataset health score<a class="headerlink" href="#Workflow-6:-One-score-to-rule-them-all----use-cleanlab's-overall-dataset-health-score" title="Permalink to this heading">#</a></h2>
<p>This score can be fairly compared across datasets or across versions of a dataset to track overall dataset quality (a.k.a. <em>dataset health</em>) over time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># One line of code.</span>
<span class="n">health</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">overall_label_health_score</span><span class="p">(</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">confident_joint</span><span class="o">=</span><span class="n">cl</span><span class="o">.</span><span class="n">confident_joint</span>
    <span class="c1"># cleanlab uses the confident_joint internally to quantify label noise (see cleanlab.count.compute_confident_joint)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 * Overall, about 28% (71 of the 250) labels in your dataset have potential issues.
 ** The overall label health score for this dataset is: 0.72.
</pre></div></div>
</div>
<section id="How-accurate-is-this-dataset-health-score?">
<h3>How accurate is this dataset health score?<a class="headerlink" href="#How-accurate-is-this-dataset-health-score?" title="Permalink to this heading">#</a></h3>
<p>Because we know the true labels (we created this toy dataset), we can compare with ground truth.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_acc</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">labels</span> <span class="o">!=</span> <span class="n">true_labels</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Percentage of label issues guessed by cleanlab </span><span class="si">{</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">health</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Percentage of (ground truth) label errors): </span><span class="si">{</span><span class="n">label_acc</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">offset</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">label_acc</span><span class="p">)</span> <span class="o">-</span> <span class="n">health</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Question: cleanlab seems to be overestimating.&quot;</span>
    <span class="sa">f</span><span class="s2">&quot; How do we account for this </span><span class="si">{</span><span class="n">offset</span><span class="si">:</span><span class="s2">.0%</span><span class="si">}</span><span class="s2"> difference?&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;Answer: Data points that fall in between two overlapping distributions are often &quot;</span>
    <span class="s2">&quot;impossible to label and are counted as issues.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Percentage of label issues guessed by cleanlab 28%
Percentage of (ground truth) label errors): 20%

Question: cleanlab seems to be overestimating. How do we account for this 8% difference?
Answer: Data points that fall in between two overlapping distributions are often impossible to label and are counted as issues.
</pre></div></div>
</div>
</section>
</section>
<section id="Workflow(s)-7:-Use-count,-rank,-filter-modules-directly">
<h2><strong>Workflow(s) 7:</strong> Use count, rank, filter modules directly<a class="headerlink" href="#Workflow(s)-7:-Use-count,-rank,-filter-modules-directly" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Using these modules directly is intended for more experienced cleanlab users. But once you understand how they work, you can create numerous powerful workflows.</p></li>
<li><p>For these workflows, you <strong>always</strong> need two things:</p>
<ol class="arabic simple">
<li><p>Out-of-sample predicted probabilities (e.g. computed via cross-validation)</p></li>
<li><p>Labels (can contain label errors and various issues)</p></li>
</ol>
</li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_cv_predicted_probabilities</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pred_probs is a </span><span class="si">{</span><span class="n">pred_probs</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> matrix of predicted probabilities&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
pred_probs is a (250, 4) matrix of predicted probabilities
</pre></div></div>
</div>
<section id="Workflow-7.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-...)">
<h3><strong>Workflow 7.1 (count)</strong>: Fully characterize label noise (noise matrix, joint, prior of true labels, )<a class="headerlink" href="#Workflow-7.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-...)" title="Permalink to this heading">#</a></h3>
<p>Now that we have <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code>, advanced users can compute everything in <code class="docutils literal notranslate"><span class="pre">cleanlab.count</span></code>.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">py:</span> <span class="pre">prob(true_label=k)</span></code></p>
<ul>
<li><p>For all classes K, this is the distribution over the actual true labels (which cleanlab can estimate for you even though you dont have the true labels).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">noise_matrix:</span> <span class="pre">p(noisy|true)</span></code></p>
<ul>
<li><p>This describes how errors were introduced into your labels. Its a conditional probability matrix with the probability of flipping from the true class to every other class for the given label.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_noise_matrix:</span> <span class="pre">p(true|noisy)</span></code></p>
<ul>
<li><p>This tells you the probability, for every class, that the true label is actually a different class.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">confident_joint</span></code></p>
<ul>
<li><p>This is an unnormalized (count-based) estimate of the number of examples in our dataset with each possible (true label, given label) pairing.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">joint:</span> <span class="pre">p(true</span> <span class="pre">label,</span> <span class="pre">noisy</span> <span class="pre">label)</span></code></p>
<ul>
<li><p>The joint distribution of noisy (given) and true labels is the most useful of all these statistics. From it, you can compute every other statistic listed above. One entry from this matrix can be interpreted as: The proportion of examples in our dataset whose true label is <em>i</em> and given label is <em>j</em>.</p></li>
</ul>
</li>
</ul>
<p>These five tools fully characterize class-conditional label noise in a dataset.</p>
<section id="Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:">
<h4>Use cleanlab to estimate and visualize the joint distribution of label noise and noise matrix of label flipping rates:<a class="headerlink" href="#Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:" title="Permalink to this heading">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span>
    <span class="n">py</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="p">,</span> <span class="n">inverse_noise_matrix</span><span class="p">,</span> <span class="n">confident_joint</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_py_and_noise_matrices_from_probabilities</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>

<span class="c1"># Note: you can also combine the above two lines of code into a single line of code like this</span>
<span class="p">(</span>
    <span class="n">py</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="p">,</span> <span class="n">inverse_noise_matrix</span><span class="p">,</span> <span class="n">confident_joint</span><span class="p">,</span> <span class="n">pred_probs</span>
<span class="p">)</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_py_noise_matrices_and_cv_pred_proba</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">clf</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>

<span class="c1"># Get the joint distribution of noisy and true labels from the confident joint</span>
<span class="c1"># This is the most powerful statistic in machine learning with noisy labels.</span>
<span class="n">joint</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">estimate_joint</span><span class="p">(</span>
    <span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">,</span> <span class="n">confident_joint</span><span class="o">=</span><span class="n">confident_joint</span>
<span class="p">)</span>

<span class="c1"># Pretty print the joint distribution and noise matrix</span>
<span class="n">cleanlab</span><span class="o">.</span><span class="n">internal</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">print_joint_matrix</span><span class="p">(</span><span class="n">joint</span><span class="p">)</span>
<span class="n">cleanlab</span><span class="o">.</span><span class="n">internal</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">print_noise_matrix</span><span class="p">(</span><span class="n">noise_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

 Joint Label Noise Distribution Matrix P(given_label, true_label) of shape (4, 4)
 p(s,y) y=0     y=1     y=2     y=3
        ---     ---     ---     ---
s=0 |   0.27    0.0     0.03    0.03
s=1 |   0.02    0.18    0.01    0.0
s=2 |   0.06    0.01    0.12    0.06
s=3 |   0.01    0.0     0.05    0.14
        Trace(matrix) = 0.72


 Noise Matrix (aka Noisy Channel) P(given_label|true_label) of shape (4, 4)
 p(s|y) y=0     y=1     y=2     y=3
        ---     ---     ---     ---
s=0 |   0.76    0.0     0.15    0.14
s=1 |   0.06    0.92    0.06    0.0
s=2 |   0.17    0.06    0.57    0.25
s=3 |   0.02    0.02    0.22    0.61
        Trace(matrix) = 2.86

</pre></div></div>
</div>
<p>In some applications, you may have a priori knowledge regarding some of these quantities. In this case, you can pass them directly into cleanlab which may be able to leverage this information to better identify label issues.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cl3</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">CleanLearning</span><span class="p">(</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">cl3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">noise_matrix</span><span class="o">=</span><span class="n">noise_matrix_true</span><span class="p">)</span>  <span class="c1"># CleanLearning with a prioiri known noise_matrix</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Workflow-7.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code">
<h3><strong>Workflow 7.2 (filter):</strong> Find label issues for any dataset and any model in one line of code<a class="headerlink" href="#Workflow-7.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code" title="Permalink to this heading">#</a></h3>
<p>Features of <code class="docutils literal notranslate"><span class="pre">cleanlab.filter.find_label_issues</span></code>:</p>
<ul class="simple">
<li><p>Versatility  Choose from several <a class="reference external" href="https://arxiv.org/abs/1911.00068">state-of-the-art</a> label-issue detection algorithms using <code class="docutils literal notranslate"><span class="pre">filter_by=</span></code>.</p></li>
<li><p>Works with any model by using predicted probabilities (no model needed).</p></li>
<li><p>One line of code :)</p></li>
</ul>
<p>Remember <code class="docutils literal notranslate"><span class="pre">CleanLearning.find_label_issues</span></code>? It uses this method internally.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get out of sample predicted probabilities via cross-validation.</span>
<span class="c1"># Here we demonstrate the use of sklearn cross_val_predict as another option to get cross-validated predicted probabilities</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>

<span class="c1"># Find label issues</span>
<span class="n">label_issues_indices</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span>
    <span class="n">filter_by</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="c1"># 5 available filter_by options</span>
    <span class="n">return_indices_ranked_by</span><span class="o">=</span><span class="s2">&quot;self_confidence&quot;</span><span class="p">,</span>  <span class="c1"># 3 available label quality scoring options for rank ordering</span>
    <span class="n">rank_by_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;adjust_pred_probs&quot;</span><span class="p">:</span> <span class="kc">True</span>  <span class="c1"># adjust predicted probabilities (see docstring for more details)</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="c1"># Return dataset indices of examples with label issues</span>
<span class="n">label_issues_indices</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 99,   8,  64,  45,  83, 213, 212, 218, 152, 197, 196, 170, 167,
       214, 164, 198,  21, 191, 107,  16,  51,  63,   2, 175,  10, 121,
       117,  24,  95,  82,  76,  26,  90,  25,  62,  22,  92,  49,  97,
       206,  68, 115,   7,  48,  43, 193, 184, 249, 194, 186, 201, 174,
       188, 163, 150, 190, 169, 151, 168,  54])
</pre></div></div>
</div>
<section id="Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">
<h4>Again, we can visualize the twenty examples with lowest label quality to see if Cleanlab works.<a class="headerlink" href="#Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works." title="Permalink to this heading">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">label_issues_indices</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Top 20 label issues found by cleanlab.filter.find_label_issues()&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_49_0.png" src="../_images/tutorials_indepth_overview_49_0.png" />
</div>
</div>
</section>
</section>
<section id="Workflow-7.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter.">
<h3>Workflow 7.2 supports lots of methods to <code class="docutils literal notranslate"><span class="pre">find_label_issues()</span></code> via the <code class="docutils literal notranslate"><span class="pre">filter_by</span></code> parameter.<a class="headerlink" href="#Workflow-7.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter." title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Here, we evaluate precision/recall/f1/accuracy of detecting true label issues for each method.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">f1_score</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">yourFavoriteModel</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Get cross-validated predicted probabilities</span>
<span class="c1"># Here we demonstrate the use of sklearn cross_val_predict as another option to get cross-validated predicted probabilities</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">yourFavoriteModel</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>

<span class="c1"># Ground truth label issues to use for evaluating different filter_by options</span>
<span class="n">true_label_issues</span> <span class="o">=</span> <span class="p">(</span><span class="n">true_labels</span> <span class="o">!=</span> <span class="n">labels</span><span class="p">)</span>

<span class="c1"># Find label issues with different filter_by options</span>
<span class="n">filter_by_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;prune_by_noise_rate&quot;</span><span class="p">,</span>
    <span class="s2">&quot;prune_by_class&quot;</span><span class="p">,</span>
    <span class="s2">&quot;both&quot;</span><span class="p">,</span>
    <span class="s2">&quot;confident_learning&quot;</span><span class="p">,</span>
    <span class="s2">&quot;predicted_neq_given&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">filter_by</span> <span class="ow">in</span> <span class="n">filter_by_list</span><span class="p">:</span>

    <span class="c1"># Find label issues</span>
    <span class="n">label_issues</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">filter</span><span class="o">.</span><span class="n">find_label_issues</span><span class="p">(</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span>
        <span class="n">filter_by</span><span class="o">=</span><span class="n">filter_by</span>
    <span class="p">)</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">true_label_issues</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">)</span>

    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;filter_by algorithm&quot;</span><span class="p">:</span> <span class="n">filter_by</span><span class="p">,</span>
        <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span>
        <span class="s2">&quot;recall&quot;</span><span class="p">:</span> <span class="n">recall</span><span class="p">,</span>
        <span class="s2">&quot;f1&quot;</span><span class="p">:</span> <span class="n">f1</span><span class="p">,</span>
        <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">acc</span>
    <span class="p">}</span>

    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="c1"># summary of results</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;f1&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filter_by algorithm</th>
      <th>precision</th>
      <th>recall</th>
      <th>f1</th>
      <th>accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>prune_by_noise_rate</td>
      <td>0.718750</td>
      <td>0.92</td>
      <td>0.807018</td>
      <td>0.912</td>
    </tr>
    <tr>
      <th>2</th>
      <td>both</td>
      <td>0.733333</td>
      <td>0.88</td>
      <td>0.800000</td>
      <td>0.912</td>
    </tr>
    <tr>
      <th>3</th>
      <td>confident_learning</td>
      <td>0.721311</td>
      <td>0.88</td>
      <td>0.792793</td>
      <td>0.908</td>
    </tr>
    <tr>
      <th>1</th>
      <td>prune_by_class</td>
      <td>0.676923</td>
      <td>0.88</td>
      <td>0.765217</td>
      <td>0.892</td>
    </tr>
    <tr>
      <th>4</th>
      <td>predicted_neq_given</td>
      <td>0.567901</td>
      <td>0.92</td>
      <td>0.702290</td>
      <td>0.844</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</section>
<section id="Workflow-7.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold.">
<h3><strong>Workflow 7.3 (rank):</strong> Automatically rank every example by a unique label quality score. Find errors using <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code> as a threshold.<a class="headerlink" href="#Workflow-7.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold." title="Permalink to this heading">#</a></h3>
<p>cleanlab can analyze every label in a dataset and provide a numerical score gauging its overall quality. Low-quality labels indicate examples that should be more closely inspected, perhaps because their given label is incorrect, or simply because they represent an ambiguous edge-case thats worth a second look.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estimate the number of label issues</span>
<span class="n">label_issues_count</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">count</span><span class="o">.</span><span class="n">num_label_issues</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span>
<span class="p">)</span>

<span class="c1"># Get label quality scores</span>
<span class="n">label_quality_scores</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
    <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;self_confidence&quot;</span>
<span class="p">)</span>

<span class="c1"># Rank-order by label quality scores and get the top estimated number of label issues</span>
<span class="n">label_issues_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">label_quality_scores</span><span class="p">)[:</span><span class="n">label_issues_count</span><span class="p">]</span>

<span class="n">label_issues_indices</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
array([ 99,   8,  64, 107,  10,  16,  51,  63, 121, 213, 212, 218, 117,
         2, 152, 197, 196, 170,  45,  24, 167,  83,  95,  82,  76,  26,
        90, 214, 164,  25,  62,  22, 198,  92,  21, 191,  49,  97,  68,
       115,   7,  48,  43, 193, 184, 194, 186, 174, 188, 163, 155, 150,
       190, 169, 156, 151, 168,  54, 172, 176, 157])
</pre></div></div>
</div>
<section id="Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works.">
<h4>Again, we can visualize the label issues found to see if Cleanlab works.<a class="headerlink" href="#Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works." title="Permalink to this heading">#</a></h4>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">circles</span><span class="o">=</span><span class="n">label_issues_indices</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Top 20 label issues using cleanlab.rank with cleanlab.count.num_label_issues()&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/tutorials_indepth_overview_55_0.png" src="../_images/tutorials_indepth_overview_55_0.png" />
</div>
</div>
</section>
<section id="Not-sure-when-to-use-Workflow-7.2-or-7.3-to-find-label-issues?">
<h4>Not sure when to use Workflow 7.2 or 7.3 to find label issues?<a class="headerlink" href="#Not-sure-when-to-use-Workflow-7.2-or-7.3-to-find-label-issues?" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><p>Workflow 7.2 is the easiest to use as its just one line of code.</p></li>
<li><p>Workflow 7.3 is modular and extensible. As we add more label and data quality scoring functions in <code class="docutils literal notranslate"><span class="pre">cleanlab.rank</span></code>, Workflow 7.3 will always work.</p></li>
<li><p>Workflow 7.3 is also for users who have a custom way to rank their data by label quality, and they just need to know what the cut-off is, found via <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code>.</p></li>
</ul>
</section>
</section>
</section>
<section id="Workflow-8:-Ensembling-label-quality-scores-from-multiple-predictors">
<h2><strong>Workflow 8:</strong> Ensembling label quality scores from multiple predictors<a class="headerlink" href="#Workflow-8:-Ensembling-label-quality-scores-from-multiple-predictors" title="Permalink to this heading">#</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">RandomForestClassifier</span>

<span class="c1"># 3 models in ensemble</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l2&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span>
<span class="p">)</span>

<span class="c1"># Get cross-validated predicted probabilities from each model</span>
<span class="n">cv_pred_probs_1</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model1</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>
<span class="n">cv_pred_probs_2</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model2</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>
<span class="n">cv_pred_probs_3</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">model3</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span>
<span class="p">)</span>

<span class="c1"># List of predicted probabilities from each model</span>
<span class="n">pred_probs_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">cv_pred_probs_1</span><span class="p">,</span> <span class="n">cv_pred_probs_2</span><span class="p">,</span> <span class="n">cv_pred_probs_3</span><span class="p">]</span>

<span class="c1"># Get ensemble label quality scores</span>
<span class="n">label_quality_scores_best</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_ensemble_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs_list</span><span class="o">=</span><span class="n">pred_probs_list</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># Alternative approach: create single ensemble predictor and get its pred_probs</span>
<span class="n">cv_pred_probs_ensemble</span> <span class="o">=</span> <span class="p">(</span><span class="n">cv_pred_probs_1</span> <span class="o">+</span> <span class="n">cv_pred_probs_2</span> <span class="o">+</span> <span class="n">cv_pred_probs_3</span><span class="p">)</span><span class="o">/</span><span class="mi">3</span>  <span class="c1"># uniform aggregation of predictions</span>

<span class="c1"># Use this single set of pred_probs to find label issues</span>
<span class="n">label_quality_scores_better</span> <span class="o">=</span> <span class="n">cleanlab</span><span class="o">.</span><span class="n">rank</span><span class="o">.</span><span class="n">get_label_quality_scores</span><span class="p">(</span>
    <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">cv_pred_probs_ensemble</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>While ensembling different models label quality scores (<code class="docutils literal notranslate"><span class="pre">label_quality_scores_best</span></code>) will often be superior to getting label quality scores from a single ensemble predictor (<code class="docutils literal notranslate"><span class="pre">label_quality_scores_better</span></code>), both approaches produce significantly better label quality scores than just using the predictions from a single model.</p>
</section>
</section>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          <a class="next-page" href="image.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Image Classification with PyTorch and Cleanlab</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="datalab/tabular.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Detecting Issues in Tabular Data(Numeric/Categorical columns) with Datalab</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">The Workflows of Data-centric AI for Classification with Noisy Labels</a><ul>
<li><a class="reference internal" href="#Install-dependencies-and-import-them">Install dependencies and import them</a></li>
<li><a class="reference internal" href="#Create-the-data-(can-skip-these-details)">Create the data (can skip these details)</a></li>
<li><a class="reference internal" href="#Workflow-1:-Use-Datalab-to-detect-many-types-of-issues"><strong>Workflow 1:</strong> Use Datalab to detect many types of issues</a></li>
<li><a class="reference internal" href="#Workflow-2:-Use-CleanLearning-for-more-robust-Machine-Learning"><strong>Workflow 2:</strong> Use CleanLearning for more robust Machine Learning</a><ul>
<li><a class="reference internal" href="#Clean-Learning-=-Machine-Learning-with-cleaned-data">Clean Learning = Machine Learning with cleaned data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-3:-Use-CleanLearning-to-find_label_issues-in-one-line-of-code"><strong>Workflow 3:</strong> Use CleanLearning to find_label_issues in one line of code</a><ul>
<li><a class="reference internal" href="#Visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">Visualize the twenty examples with lowest label quality to see if Cleanlab works.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-4:-Use-cleanlab-to-find-dataset-level-and-class-level-issues"><strong>Workflow 4:</strong> Use cleanlab to find dataset-level and class-level issues</a><ul>
<li><a class="reference internal" href="#Now,-let's-see-what-happens-if-we-merge-classes-%22seafoam-green%22-and-%22yellow%22">Now, lets see what happens if we merge classes seafoam green and yellow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-5:-Clean-your-test-set-too-if-you're-doing-ML-with-noisy-labels!"><strong>Workflow 5:</strong> Clean your test set too if youre doing ML with noisy labels!</a></li>
<li><a class="reference internal" href="#Workflow-6:-One-score-to-rule-them-all----use-cleanlab's-overall-dataset-health-score"><strong>Workflow 6:</strong> One score to rule them all  use cleanlabs overall dataset health score</a><ul>
<li><a class="reference internal" href="#How-accurate-is-this-dataset-health-score?">How accurate is this dataset health score?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow(s)-7:-Use-count,-rank,-filter-modules-directly"><strong>Workflow(s) 7:</strong> Use count, rank, filter modules directly</a><ul>
<li><a class="reference internal" href="#Workflow-7.1-(count):-Fully-characterize-label-noise-(noise-matrix,-joint,-prior-of-true-labels,-...)"><strong>Workflow 7.1 (count)</strong>: Fully characterize label noise (noise matrix, joint, prior of true labels, )</a><ul>
<li><a class="reference internal" href="#Use-cleanlab-to-estimate-and-visualize-the-joint-distribution-of-label-noise-and-noise-matrix-of-label-flipping-rates:">Use cleanlab to estimate and visualize the joint distribution of label noise and noise matrix of label flipping rates:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-7.2-(filter):-Find-label-issues-for-any-dataset-and-any-model-in-one-line-of-code"><strong>Workflow 7.2 (filter):</strong> Find label issues for any dataset and any model in one line of code</a><ul>
<li><a class="reference internal" href="#Again,-we-can-visualize-the-twenty-examples-with-lowest-label-quality-to-see-if-Cleanlab-works.">Again, we can visualize the twenty examples with lowest label quality to see if Cleanlab works.</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-7.2-supports-lots-of-methods-to-find_label_issues()-via-the-filter_by-parameter.">Workflow 7.2 supports lots of methods to <code class="docutils literal notranslate"><span class="pre">find_label_issues()</span></code> via the <code class="docutils literal notranslate"><span class="pre">filter_by</span></code> parameter.</a></li>
<li><a class="reference internal" href="#Workflow-7.3-(rank):-Automatically-rank-every-example-by-a-unique-label-quality-score.-Find-errors-using-cleanlab.count.num_label_issues-as-a-threshold."><strong>Workflow 7.3 (rank):</strong> Automatically rank every example by a unique label quality score. Find errors using <code class="docutils literal notranslate"><span class="pre">cleanlab.count.num_label_issues</span></code> as a threshold.</a><ul>
<li><a class="reference internal" href="#Again,-we-can-visualize-the-label-issues-found-to-see-if-Cleanlab-works.">Again, we can visualize the label issues found to see if Cleanlab works.</a></li>
<li><a class="reference internal" href="#Not-sure-when-to-use-Workflow-7.2-or-7.3-to-find-label-issues?">Not sure when to use Workflow 7.2 or 7.3 to find label issues?</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#Workflow-8:-Ensembling-label-quality-scores-from-multiple-predictors"><strong>Workflow 8:</strong> Ensembling label quality scores from multiple predictors</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=2b91c5f0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=30646c52"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>