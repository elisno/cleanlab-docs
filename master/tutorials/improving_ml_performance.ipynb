{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f361b775-0fb3-4f09-89b9-6672775382bb",
   "metadata": {},
   "source": [
    "# Improving ML Performance via Data Curation with Train vs Test Splits\n",
    "\n",
    "In typical Machine Learning projects, we split our dataset into **training** data for fitting models and **test** data to evaluate model performance. For noisy real-world datasets, detecting/correcting errors in the training data is important to train robust models, but it's less recognized that the test set can also be noisy.\n",
    "For accurate model evaluation, it is vital to **find and fix issues in the test data** as well. Some evaluation metrics are particularly sensitive to outliers and noisy labels.\n",
    "This tutorial demonstrates a way to use cleanlab (via `Datalab`) to curate both your training and test data, ensuring **robust model training** and **reliable performance evaluation**.\n",
    "We recommend first completing some Datalab tutorials before diving into this more complex subject.\n",
    "\n",
    "Here's how we recommend handling noisy training and test data (this tutorial walks through these steps):\n",
    "\n",
    "1. [Preprocess](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d) your training and test data to be suitable for ML. Use cleanlab to check for fundamental train/test setup problems in the merged dataset like train/test leakage or drift.\n",
    "2. Fit your ML model to your noisy training data and get its predictions/embeddings for your test data. Use these model outputs with cleanlab to detect issues in your **test** data.\n",
    "3. Manually review/correct cleanlab-detected issues in your test data. **We caution against blindly automated correction of test data**. Changes to your test set should be carefully verified to ensure they will lead to more accurate model evaluation. We also caution against comparing the performance of different ML models across different versions of your test data; performance comparions between models should be based on the same test data.\n",
    "4. Cross-validate a new copy of your ML model on your training data, and then use it with cleanlab to detect issues in the **training** dataset. Do not include test data in any part of this step to avoid leaking test set information into the training data curation.\n",
    "5. You can try **automated techniques** to curate your training data based on cleanlab results, train models on the curated training data, and evaluate them on the cleaned test data.\n",
    "\n",
    "Consider this tutorial as a blueprint for using cleanlab in diverse ML projects spanning various data modalities. The same ideas apply if you substitute *test* data with *validation* data above. In a final advanced section of this tutorial, we show how training data edits can be parameterized in terms of cleanlab's detected issues, such that hyperparameter optimization can identify the optimal combination of data edits for training an effective ML model.\n",
    "\n",
    "**Note**: This tutorial trains an XGBoost model on a tabular dataset, but the same approach applies to *any* ML model and data modality.\n",
    "\n",
    "\n",
    "### Why did you make this tutorial?\n",
    "\n",
    "**TLDR:** Reliable ML requires both reliable training and reliable evaluation. This tutorial shows you how to achieve both using cleanlab.\n",
    "\n",
    "**Longer answer:** Many users wish to use cleanlab to improve their ML model by improving their data, but make subtle mistakes. This multi-step tutorial shows one way to do this properly.\n",
    "Some users curate (e.g. fix label issues in) their training data, train ML model, and evaluate it on test data. But they see no improvement in test-set accuracy, because they have introduced *distribution-shift* by altering their training data. If the test data also has issues, they must also be fixed for a faithful model evaluation.\n",
    "Other users therefore curate their test data too, but some blindly auto-fix their test data, which is dangerous! This cleanlab package is based on ML and thus inevitably imperfect. Issues that cleanlab detected in test data should **not** be blindly auto-fixed -- this risks making model evaluation wrong.\n",
    "Instead we recommend the multi-step workflow above, where less algorithmic/automated correction is applied to test data than to training data (focus your manual efforts on curating test rather than training data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72907260",
   "metadata": {},
   "source": [
    "## 1. Install dependencies\n",
    "\n",
    "`Datalab` has additional dependencies that are not included in the standard installation of cleanlab.\n",
    "You can use `pip` to install all packages required for this tutorial as follows:\n",
    "\n",
    "```ipython3\n",
    "!pip install xgboost\n",
    "!pip install \"cleanlab[datalab]\"\n",
    "# Make sure to install the version corresponding to this tutorial\n",
    "# E.g. if viewing master branch documentation:\n",
    "#     !pip install git+https://github.com/cleanlab/cleanlab.git\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d638465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:13.161302Z",
     "iopub.status.busy": "2025-02-27T14:47:13.160895Z",
     "iopub.status.idle": "2025-02-27T14:47:14.436782Z",
     "shell.execute_reply": "2025-02-27T14:47:14.436117Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Package installation (hidden on docs website).\n",
    "dependencies = [\"cleanlab\", \"xgboost\", \"datasets\"]\n",
    "\n",
    "if \"google.colab\" in str(get_ipython()):  # Check if it's running in Google Colab\n",
    "    %pip install git+https://github.com/elisno/cleanlab.git@d083bb5cb45534444fa4f8f9826e9835e4711da7\n",
    "    cmd = ' '.join([dep for dep in dependencies if dep != \"cleanlab\"])\n",
    "    %pip install $cmd\n",
    "else:\n",
    "    dependencies_test = [dependency.split('>')[0] if '>' in dependency \n",
    "                         else dependency.split('<')[0] if '<' in dependency \n",
    "                         else dependency.split('=')[0] for dependency in dependencies]\n",
    "    missing_dependencies = []\n",
    "    for dependency in dependencies_test:\n",
    "        try:\n",
    "            __import__(dependency)\n",
    "        except ImportError:\n",
    "            missing_dependencies.append(dependency)\n",
    "\n",
    "    if len(missing_dependencies) > 0:\n",
    "        print(\"Missing required dependencies:\")\n",
    "        print(*missing_dependencies, sep=\", \")\n",
    "        print(\"\\nPlease install them before running the rest of this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bbf715-47c6-44ea-b15e-89800e62ee04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:14.439044Z",
     "iopub.status.busy": "2025-02-27T14:47:14.438750Z",
     "iopub.status.idle": "2025-02-27T14:47:14.442632Z",
     "shell.execute_reply": "2025-02-27T14:47:14.442081Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import cleanlab\n",
    "from cleanlab import Datalab\n",
    "\n",
    "SEED = 123456  # for reproducibility\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bbadc-547a-4bb0-8bcf-033c6890ce5e",
   "metadata": {},
   "source": [
    "## 2. Preprocess the data \n",
    "\n",
    "This tutorial considers a classification task with structured/tabular data. The ML task is to predict each student's final grade in a course (class label) based on various numeric/categorical features about them (exam scores and notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c58f8015-d051-411c-9e03-5659cf3ad956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:14.444363Z",
     "iopub.status.busy": "2025-02-27T14:47:14.444028Z",
     "iopub.status.idle": "2025-02-27T14:47:15.162918Z",
     "shell.execute_reply": "2025-02-27T14:47:15.162341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stud_ID</th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>018bff</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>great participation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>076d92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>cheated on exam, gets 0pts</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c80059</td>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e38f8a</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d57e1a</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>great final presentation +10</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stud_ID  exam_1  exam_2  exam_3                         notes  \\\n",
       "0  018bff    94.0    41.0    91.0       great participation +10   \n",
       "1  076d92     0.0    79.0    65.0    cheated on exam, gets 0pts   \n",
       "2  c80059    86.0    89.0    85.0  great final presentation +10   \n",
       "3  e38f8a    50.0    67.0    94.0  great final presentation +10   \n",
       "4  d57e1a    92.0    79.0    98.0  great final presentation +10   \n",
       "\n",
       "  noisy_letter_grade  \n",
       "0                  B  \n",
       "1                  F  \n",
       "2                  F  \n",
       "3                  B  \n",
       "4                  A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_train_data.csv\"\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_test_data.csv\"\n",
    ")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39cd525-7a09-4d8e-811e-44ac1072f438",
   "metadata": {},
   "source": [
    "Before training a ML model, we [preprocess](https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d) our dataset. The type of preprocessing that is best will depend on what ML model you use. This tutorial will demonstrate an XGBoost model, so we'll process the **notes** and **noisy_letter_grade** columns into categorical columns for this model (each category encoded as an integer). You can alternatively use [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/), which will automatically produce a high-accuracy ML model for your raw data, without you having to worry about any ML modeling or data preprocessing work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5f50e6-d125-4e61-b63e-4004f0c9099a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.164636Z",
     "iopub.status.busy": "2025-02-27T14:47:15.164449Z",
     "iopub.status.idle": "2025-02-27T14:47:15.170710Z",
     "shell.execute_reply": "2025-02-27T14:47:15.170121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create label encoders for the categorical columns\n",
    "grade_le = preprocessing.LabelEncoder()\n",
    "notes_le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Process the feature columns\n",
    "train_features = df_train.drop([\"stud_ID\", \"noisy_letter_grade\"], axis=1).copy()\n",
    "train_features[\"notes\"] = notes_le.fit_transform(train_features[\"notes\"])\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "# Process the label column\n",
    "train_labels = pd.DataFrame(grade_le.fit_transform(df_train[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])\n",
    "\n",
    "# Keep separate copies of these training features and labels for later use\n",
    "train_features_v2 = train_features.copy()\n",
    "train_labels_v2 = train_labels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cd820-7565-4314-9dda-808cbe7c638f",
   "metadata": {},
   "source": [
    "We first solely preprocessed the training data to avoid information leakage (using test data information that would not be available at prediction time). Here's how the preprocessed training features look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a36c21e9-1c32-4df9-bd87-fffeb8c2175f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.172788Z",
     "iopub.status.busy": "2025-02-27T14:47:15.172321Z",
     "iopub.status.idle": "2025-02-27T14:47:15.179320Z",
     "shell.execute_reply": "2025-02-27T14:47:15.178863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   exam_1  exam_2  exam_3 notes\n",
       "0    94.0    41.0    91.0     2\n",
       "1     0.0    79.0    65.0     0\n",
       "2    86.0    89.0    85.0     1\n",
       "3    50.0    67.0    94.0     1\n",
       "4    92.0    79.0    98.0     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bda",
   "metadata": {},
   "source": [
    "We apply the same preprocessing to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f856a3a-8aae-4836-b146-9ab68d8d1c7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.180846Z",
     "iopub.status.busy": "2025-02-27T14:47:15.180625Z",
     "iopub.status.idle": "2025-02-27T14:47:15.185511Z",
     "shell.execute_reply": "2025-02-27T14:47:15.184955Z"
    }
   },
   "outputs": [],
   "source": [
    "test_features = df_test.drop(\n",
    "    [\"stud_ID\", \"noisy_letter_grade\"], axis=1\n",
    ").copy()\n",
    "test_features[\"notes\"] = notes_le.transform(test_features[\"notes\"])\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(\"category\")\n",
    "\n",
    "test_labels = pd.DataFrame(grade_le.transform(df_test[\"noisy_letter_grade\"].copy()), columns=[\"noisy_letter_grade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da7bf-07b6-4a49-b7be-994713688bdd",
   "metadata": {},
   "source": [
    "We then appropriately format the datasets for the ML model used in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46275634-da56-4e58-9061-8108be2b585d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.187260Z",
     "iopub.status.busy": "2025-02-27T14:47:15.186939Z",
     "iopub.status.idle": "2025-02-27T14:47:15.192984Z",
     "shell.execute_reply": "2025-02-27T14:47:15.192380Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype('object')\n",
    "test_labels = test_labels.astype('object')\n",
    "\n",
    "train_features[\"notes\"] = train_features[\"notes\"].astype(int)\n",
    "test_features[\"notes\"] = test_features[\"notes\"].astype(int)\n",
    "\n",
    "preprocessed_train_data = pd.concat([train_features, train_labels], axis=1)\n",
    "preprocessed_train_data[\"stud_ID\"] = df_train[\"stud_ID\"]\n",
    "\n",
    "preprocessed_test_data = pd.concat([test_features, test_labels], axis=1)\n",
    "preprocessed_test_data[\"stud_ID\"] = df_test[\"stud_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f2d8d0-c5ac-4e46-9ab0-aee52adaae0d",
   "metadata": {},
   "source": [
    "## 3. Check for fundamental problems in the train/test setup\n",
    "\n",
    "Before training any ML model, we can quickly check for fundamental issues in our setup with cleanlab. To audit all of our data at once, we merge the training and test sets into one dataset, from which we construct a `Datalab` object. Datalab automatically detects many types of common issues in a dataset, but requires a trained ML model for a comprehensive audit. We haven't trained any model yet, so here we instruct Datalab to only check for specific data issues: near duplicates, and whether the data appears non-IID (violations of the IID assumption include: data drift or lack of statistical independence between data points).\n",
    "\n",
    "Datalab can detect many additional types of data issues, depending on what inputs it is given. Below we provide `features = features_df` as the sole input to `Datalab.find_issues()`, which solely contains numerical values here. If you have heterogenoues/complex data types (eg. text or images), you could instead provide vector feature representations (eg. pretrained model embeddings) of your data as the `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769c4c5e-a7ff-4e02-bee5-2b2e676aec14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.194817Z",
     "iopub.status.busy": "2025-02-27T14:47:15.194637Z",
     "iopub.status.idle": "2025-02-27T14:47:15.198790Z",
     "shell.execute_reply": "2025-02-27T14:47:15.198354Z"
    }
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([preprocessed_train_data, preprocessed_test_data], axis=0).reset_index(drop=True)\n",
    "features_df = full_df.drop([\"noisy_letter_grade\", \"stud_ID\"], axis=1)  # can instead use model embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ac47c3d-9e87-45b7-9064-bfa45578872e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.200285Z",
     "iopub.status.busy": "2025-02-27T14:47:15.200116Z",
     "iopub.status.idle": "2025-02-27T14:47:15.265812Z",
     "shell.execute_reply": "2025-02-27T14:47:15.265185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "\n",
      "Audit complete. 100 issues found in the dataset.\n",
      "Dataset Information: num_examples: 749, num_classes: 5\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "    issue_type    score  num_issues\n",
      "near_duplicate 0.583745         100\n",
      "       non_iid 0.291382           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 100\n",
      "Overall dataset quality in terms of this issue: 0.5837\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "748                     True                   0.0               [604]                           0.0\n",
      "510                     True                   0.0               [227]                           0.0\n",
      "71                      True                   0.0               [719]                           0.0\n",
      "65                      True                   0.0          [690, 444]                           0.0\n",
      "547                     True                   0.0               [647]                           0.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.2914\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "611             False       0.687869\n",
      "610             False       0.687883\n",
      "612             False       0.688146\n",
      "609             False       0.688189\n",
      "613             False       0.688713\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.2913818469137725\n"
     ]
    }
   ],
   "source": [
    "lab = Datalab(data=full_df, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "lab.find_issues(features=features_df.to_numpy(), issue_types={\"near_duplicate\": {}, \"non_iid\": {}})\n",
    "lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46ce6-29e7-4aa5-9e27-37e9e3c7107a",
   "metadata": {},
   "source": [
    "cleanlab does not find significant evidence that our data is non-[IID](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables), which is good. Otherwise, we'd need to further consider where our data came from and whether conclusions/predictions from this dataset can really generalize to our population of interest.\n",
    "\n",
    "But cleanlab did detect many near duplicates in the dataset. We see some exact duplicates between our training and test data, which may indicate data leakage!  Since we didn't expect these duplicates in our dataset, let's drop the extra duplicated copies of test data points found in our training set from this training set. This helps ensure that our model evaluations reflect generalization capabilities.\n",
    "Here's how we can review the near duplicates detected via Datalab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cef169e-d15b-4d18-9cb7-8ea589557e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.267859Z",
     "iopub.status.busy": "2025-02-27T14:47:15.267644Z",
     "iopub.status.idle": "2025-02-27T14:47:15.278574Z",
     "shell.execute_reply": "2025-02-27T14:47:15.278052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[604]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[227]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[719]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[690, 444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[647]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "748                     True                   0.0               [604]   \n",
       "510                     True                   0.0               [227]   \n",
       "71                      True                   0.0               [719]   \n",
       "65                      True                   0.0          [690, 444]   \n",
       "547                     True                   0.0               [647]   \n",
       "\n",
       "     distance_to_nearest_neighbor  \n",
       "748                           0.0  \n",
       "510                           0.0  \n",
       "71                            0.0  \n",
       "65                            0.0  \n",
       "547                           0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_duplicate_results = lab.get_issues(\"near_duplicate\")\n",
    "full_duplicate_results.sort_values(\"near_duplicate_score\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900691f-ee72-43e5-b0c5-90fa0a703594",
   "metadata": {},
   "source": [
    "To distinguish between near vs. exact duplicates, we can filter where the `distance_to_nearest_neighbor` column has value = 0.\n",
    "We specifically filter for exact duplicates between our training and test set in order to drop the extra copies of such data points from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b68e0418-86cf-431f-9107-2dd0a310ca42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.280730Z",
     "iopub.status.busy": "2025-02-27T14:47:15.280350Z",
     "iopub.status.idle": "2025-02-27T14:47:15.301210Z",
     "shell.execute_reply": "2025-02-27T14:47:15.300650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_near_duplicate_issue</th>\n",
       "      <th>near_duplicate_score</th>\n",
       "      <th>near_duplicate_sets</th>\n",
       "      <th>distance_to_nearest_neighbor</th>\n",
       "      <th>nd_set_has_index_over_training_cutoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[627]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[678]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[690, 444]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[719]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[709]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[615]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[620]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[704]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[688]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[672]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[647]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[696]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[748]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[723]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  \\\n",
       "33                      True                   0.0               [627]   \n",
       "53                      True                   0.0               [678]   \n",
       "65                      True                   0.0          [690, 444]   \n",
       "71                      True                   0.0               [719]   \n",
       "82                      True                   0.0               [709]   \n",
       "100                     True                   0.0               [615]   \n",
       "292                     True                   0.0               [620]   \n",
       "420                     True                   0.0               [704]   \n",
       "431                     True                   0.0               [688]   \n",
       "459                     True                   0.0               [672]   \n",
       "547                     True                   0.0               [647]   \n",
       "564                     True                   0.0               [696]   \n",
       "604                     True                   0.0               [748]   \n",
       "605                     True                   0.0               [723]   \n",
       "\n",
       "     distance_to_nearest_neighbor  nd_set_has_index_over_training_cutoff  \n",
       "33                            0.0                                   True  \n",
       "53                            0.0                                   True  \n",
       "65                            0.0                                   True  \n",
       "71                            0.0                                   True  \n",
       "82                            0.0                                   True  \n",
       "100                           0.0                                   True  \n",
       "292                           0.0                                   True  \n",
       "420                           0.0                                   True  \n",
       "431                           0.0                                   True  \n",
       "459                           0.0                                   True  \n",
       "547                           0.0                                   True  \n",
       "564                           0.0                                   True  \n",
       "604                           0.0                                   True  \n",
       "605                           0.0                                   True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_cutoff = len(preprocessed_train_data) - 1  # last index of training data in the merged dataset\n",
    "\n",
    "# Create column to list which duplicate sets include some test data:\n",
    "full_duplicate_results['nd_set_has_index_over_training_cutoff'] = full_duplicate_results['near_duplicate_sets'].apply(lambda x: any(i > train_idx_cutoff for i in x))\n",
    "\n",
    "exact_duplicates = full_duplicate_results.query('is_near_duplicate_issue == True and near_duplicate_score == 0.0 and nd_set_has_index_over_training_cutoff == True').sort_values(\"near_duplicate_score\")\n",
    "exact_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9bd131-429f-48af-b4fc-ed8b907950b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.303307Z",
     "iopub.status.busy": "2025-02-27T14:47:15.302941Z",
     "iopub.status.idle": "2025-02-27T14:47:15.307067Z",
     "shell.execute_reply": "2025-02-27T14:47:15.306584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([33, 53, 65, 71, 82, 100, 292, 420, 431, 459, 547, 564, 604, 605], dtype='int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_duplicates_indices = exact_duplicates.index\n",
    "exact_duplicates_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b10842-0ad2-4441-a8a4-a424d9c14557",
   "metadata": {},
   "source": [
    "Below we remove the exact duplicates that occur between our training and test sets from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e72320ec-7792-4347-b2fb-630f2519127c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.309045Z",
     "iopub.status.busy": "2025-02-27T14:47:15.308669Z",
     "iopub.status.idle": "2025-02-27T14:47:15.312874Z",
     "shell.execute_reply": "2025-02-27T14:47:15.312366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33, 53, 65, 71, 82, 100, 292, 420, 431, 459, 547, 564, 604, 605]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_of_duplicates_to_drop = [idx for idx in exact_duplicates_indices if idx <= train_idx_cutoff]\n",
    "indices_of_duplicates_to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f56824-c706-4448-9581-a07ea0cd9041",
   "metadata": {},
   "source": [
    "Here are the examples we'll drop from our *training* data, since they are exact duplicates of *test* examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8520ba4a-3ad6-408a-b377-3f47c32d745a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.314846Z",
     "iopub.status.busy": "2025-02-27T14:47:15.314462Z",
     "iopub.status.idle": "2025-02-27T14:47:15.326240Z",
     "shell.execute_reply": "2025-02-27T14:47:15.325815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exam_1</th>\n",
       "      <th>exam_2</th>\n",
       "      <th>exam_3</th>\n",
       "      <th>notes</th>\n",
       "      <th>noisy_letter_grade</th>\n",
       "      <th>stud_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>83.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4a3f75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>d030b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>93.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>ddd0ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8e6d24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>78.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>464aab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>ee3387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>79.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>61e807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>99.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>71d7b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>90.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83e31f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>70.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>edeb53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>cd52b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>84.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>454e51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>87.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>042686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>96.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12a73f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     exam_1  exam_2  exam_3  notes noisy_letter_grade stud_ID\n",
       "33     83.0    92.0    80.0      3                  2  4a3f75\n",
       "53     91.0     0.0    94.0      0                  3  d030b5\n",
       "65     93.0    73.0    82.0      5                  1  ddd0ba\n",
       "71     90.0    95.0    75.0      1                  0  8e6d24\n",
       "82     78.0    81.0    74.0      4                  3  464aab\n",
       "100    80.0    96.0    83.0      4                  2  ee3387\n",
       "292    79.0    62.0    82.0      5                  2  61e807\n",
       "420    99.0    53.0    76.0      5                  2  71d7b9\n",
       "431    90.0    92.0    88.0      2                  0  83e31f\n",
       "459    70.0    63.0    95.0      2                  1  edeb53\n",
       "547    68.0    93.0    73.0      5                  2  cd52b5\n",
       "564    84.0    92.0    86.0      5                  1  454e51\n",
       "604    87.0    74.0    95.0      3                  2  042686\n",
       "605    96.0    83.0    73.0      1                  0  12a73f"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.iloc[indices_of_duplicates_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c002665-c48b-4f04-91f7-ad112a49efc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.327930Z",
     "iopub.status.busy": "2025-02-27T14:47:15.327639Z",
     "iopub.status.idle": "2025-02-27T14:47:15.331622Z",
     "shell.execute_reply": "2025-02-27T14:47:15.331189Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True)\n",
    "train_features = train_features.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(indices_of_duplicates_to_drop, axis=0).reset_index(drop=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553d5b2-1ba9-4dca-8110-eda6a8e11281",
   "metadata": {},
   "source": [
    "## 4. Train model with original (noisy) training data\n",
    "\n",
    "After handling fundamental issues in our training/test setup, let's fit our ML model to the training data. Here we use XGBoost as an example, but the same ideas of this tutorial apply to any other ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36319f39-f563-4f63-913f-821373180350",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.333195Z",
     "iopub.status.busy": "2025-02-27T14:47:15.333029Z",
     "iopub.status.idle": "2025-02-27T14:47:15.447213Z",
     "shell.execute_reply": "2025-02-27T14:47:15.446590Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train_labels[\"noisy_letter_grade\"]\n",
    "clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214e30b-4c82-4295-a3b0-68493904836b",
   "metadata": {},
   "source": [
    "### Compute out-of-sample predicted probabilities for the test data from this baseline model\n",
    "\n",
    "Make sure that the columns of your predicted class probabilities are properly ordered with respect to the ordering of classes, which for Datalab is: lexicographically sorted by class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "044c0eb1-299a-4851-b1bf-268d5bce56c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.449389Z",
     "iopub.status.busy": "2025-02-27T14:47:15.448954Z",
     "iopub.status.idle": "2025-02-27T14:47:15.455261Z",
     "shell.execute_reply": "2025-02-27T14:47:15.454723Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred_probs = clf.predict_proba(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7e3406-845a-42ff-87d5-a104837234c4",
   "metadata": {},
   "source": [
    "## 5. Check for issues in test data and manually address them\n",
    "\n",
    "While we could evaluate our model's accuracy using the predictions above, this will be unreliable if the test data have issues. Based on the given labels, model predictions, and feature representations, Datalab can automatically detect issues lurking in our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c43df278-abfe-40e5-9d48-2df3efea9379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:15.457303Z",
     "iopub.status.busy": "2025-02-27T14:47:15.456790Z",
     "iopub.status.idle": "2025-02-27T14:47:17.501987Z",
     "shell.execute_reply": "2025-02-27T14:47:17.501311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding outlier issues ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 30 issues found in the dataset.\n",
      "Dataset Information: num_examples: 134, num_classes: 5\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.798507          25\n",
      "              outlier 0.370259           5\n",
      "                 null 1.000000           0\n",
      "       near_duplicate 0.625352           0\n",
      "              non_iid 0.524042           0\n",
      "      class_imbalance 0.097015           0\n",
      "underperforming_group 1.000000           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 25\n",
      "Overall dataset quality in terms of this issue: 0.7985\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score given_label predicted_label\n",
      "70             True     0.000537           F               A\n",
      "90            False     0.000903           F               C\n",
      "79            False     0.001743           F               C\n",
      "106            True     0.001853           F               A\n",
      "46             True     0.002121           F               A\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 5\n",
      "Overall dataset quality in terms of this issue: 0.3703\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_outlier_issue  outlier_score\n",
      "63              True   4.752463e-99\n",
      "89              True   3.784418e-09\n",
      "40              True   5.477741e-06\n",
      "57              True   1.134230e-05\n",
      "32              True   7.153555e-03\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_null_issue  null_score\n",
      "0           False         1.0\n",
      "97          False         1.0\n",
      "96          False         1.0\n",
      "95          False         1.0\n",
      "94          False         1.0\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.6254\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor\n",
      "43                    False              0.143272                  []                      0.000016\n",
      "93                    False              0.143272                  []                      0.000016\n",
      "20                    False              0.146501                  []                      0.000016\n",
      "83                    False              0.146501                  []                      0.000016\n",
      "75                    False              0.161431                  []                      0.000018\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.5240\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "12              False       0.765240\n",
      "35              False       0.771221\n",
      "28              False       0.801589\n",
      "7               False       0.801652\n",
      "112             False       0.810735\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.5240417899434826\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.0970\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_class_imbalance_issue  class_imbalance_score given_label\n",
      "88                     False               0.097015           F\n",
      "70                     False               0.097015           F\n",
      "2                      False               0.097015           F\n",
      "71                     False               0.097015           F\n",
      "46                     False               0.097015           F\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a cluster of similar examples\n",
      "    (i.e. a slice) in the dataset for which the ML model predictions\n",
      "    are particularly poor (loss evaluation over this subpopulation is high).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "    is_underperforming_group_issue  underperforming_group_score\n",
      "0                            False                          1.0\n",
      "97                           False                          1.0\n",
      "96                           False                          1.0\n",
      "95                           False                          1.0\n",
      "94                           False                          1.0\n"
     ]
    }
   ],
   "source": [
    "test_lab = Datalab(data=df_test, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "test_features_array = test_features.to_numpy()  # could alternatively be model embeddings\n",
    "test_lab.find_issues(features=test_features_array, pred_probs=test_pred_probs)\n",
    "test_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0c82c6-43df-4b4a-b8ad-0d5884ab068a",
   "metadata": {},
   "source": [
    "Datalab automatically audits our dataset for various common issues. The report above indicates many label issues in our data.\n",
    "\n",
    "We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the `get_issues()` method. To review the most likely label errors, we sort our data by the `label_score` (a lower score represents that the label is less likely to be correct)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77c7f776-54b3-45b5-9207-715d6d2e90c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:17.504537Z",
     "iopub.status.busy": "2025-02-27T14:47:17.503926Z",
     "iopub.status.idle": "2025-02-27T14:47:17.517282Z",
     "shell.execute_reply": "2025-02-27T14:47:17.516770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    stud_ID  exam_1  exam_2  exam_3                           notes  \\\n",
      "70   2bd759    93.0    79.0    97.0         great participation +10   \n",
      "106  34ccdd    90.0   100.0    89.0         great participation +10   \n",
      "46   bb3bab    97.0    88.0    74.0         great participation +10   \n",
      "103  bf1b14    66.0    83.0    96.0                             NaN   \n",
      "97   4787de    73.0    84.0    68.0         great participation +10   \n",
      "92   865cbd    95.0    87.0    82.0     missed class frequently -10   \n",
      "72   32d53f    71.0    78.0    80.0    great final presentation +10   \n",
      "22   5b2f76    99.0    86.0    95.0     missed class frequently -10   \n",
      "3    28f8b4    67.0    82.0    98.0                             NaN   \n",
      "69   df814d    78.0    85.0    84.0                             NaN   \n",
      "45   f17261    95.0    88.0    69.0                             NaN   \n",
      "98   1db3ff    95.0    81.0    76.0                             NaN   \n",
      "109  ded944    86.0    85.0    89.0                             NaN   \n",
      "124  343dd3    67.0    87.0    95.0  missed homework frequently -10   \n",
      "20   8d904d    73.0    73.0    76.0     missed class frequently -10   \n",
      "83   e4f0d5    86.0    85.0    89.0  missed homework frequently -10   \n",
      "120  d6d208    97.0    97.0    92.0  missed homework frequently -10   \n",
      "29   76c083    91.0    92.0    74.0                             NaN   \n",
      "63   d030b5    91.0     0.0    94.0      cheated on exam, gets 0pts   \n",
      "23   695f96    96.0    69.0    92.0                             NaN   \n",
      "84   745c23    89.0    95.0    72.0                             NaN   \n",
      "10   13b36e    98.0    92.0    96.0                             NaN   \n",
      "89   71d7b9    99.0    53.0    76.0                             NaN   \n",
      "127  5ba892    98.0    97.0    93.0                             NaN   \n",
      "43   9f0216    94.0    79.0    89.0                             NaN   \n",
      "\n",
      "    noisy_letter_grade  is_label_issue  label_score given_label  \\\n",
      "70                   F            True     0.000537           F   \n",
      "106                  F            True     0.001853           F   \n",
      "46                   F            True     0.002121           F   \n",
      "103                  D            True     0.003628           D   \n",
      "97                   D            True     0.004006           D   \n",
      "92                   A            True     0.004031           A   \n",
      "72                   D            True     0.007930           D   \n",
      "22                   B            True     0.013226           B   \n",
      "3                    D            True     0.015255           D   \n",
      "69                   B            True     0.017692           B   \n",
      "45                   D            True     0.019767           D   \n",
      "98                   B            True     0.036197           B   \n",
      "109                  D            True     0.054746           D   \n",
      "124                  C            True     0.055110           C   \n",
      "20                   D            True     0.062675           D   \n",
      "83                   C            True     0.112695           C   \n",
      "120                  B            True     0.121059           B   \n",
      "29                   B            True     0.171280           B   \n",
      "63                   D            True     0.181689           D   \n",
      "23                   B            True     0.208001           B   \n",
      "84                   B            True     0.275028           B   \n",
      "10                   A            True     0.346032           A   \n",
      "89                   C            True     0.396350           C   \n",
      "127                  A            True     0.401493           A   \n",
      "43                   B            True     0.474349           B   \n",
      "\n",
      "    predicted_label  \n",
      "70                A  \n",
      "106               A  \n",
      "46                A  \n",
      "103               F  \n",
      "97                B  \n",
      "92                C  \n",
      "72                A  \n",
      "22                A  \n",
      "3                 B  \n",
      "69                D  \n",
      "45                B  \n",
      "98                D  \n",
      "109               B  \n",
      "124               B  \n",
      "20                B  \n",
      "83                A  \n",
      "120               A  \n",
      "29                D  \n",
      "63                B  \n",
      "23                D  \n",
      "84                D  \n",
      "10                F  \n",
      "89                D  \n",
      "127               F  \n",
      "43                D  \n"
     ]
    }
   ],
   "source": [
    "test_label_issue_results = test_lab.get_issues(\"label\")\n",
    "test_label_issues_ordered = df_test.join(test_label_issue_results)\n",
    "test_label_issues_ordered = test_label_issues_ordered[test_label_issue_results[\"is_label_issue\"] == True].sort_values(\"label_score\")\n",
    "\n",
    "print(test_label_issues_ordered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c4c6c-ce5b-4863-9675-471ff7596229",
   "metadata": {},
   "source": [
    "The dataframe above shows the original label (`given_label`) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative `predicted_label` for each example. These examples have likely been labeled incorrectly and should be carefully re-examined. After manually inspecting our label issues above, we can add the indices for the label issues we want to remove from our data to our previously defined list. \n",
    "\n",
    "Remember to inspect and **manually** handle issues detected in your test data and to **avoid** handling them automatically. Otherwise you risk misleading model evaluations!\n",
    "\n",
    "In this case, we manually found that the first 11 label issues with lowest `label_score` correspond to real label errors. We'll drop those data points from our test set, in order to curate a cleaner test set. Here we solely address mislabeled data for brevity, but you can similarly address other issues detected in your test data to ensure the most reliable model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e218d04-0729-4f42-b264-51c73601ebe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:17.519298Z",
     "iopub.status.busy": "2025-02-27T14:47:17.518911Z",
     "iopub.status.idle": "2025-02-27T14:47:17.521923Z",
     "shell.execute_reply": "2025-02-27T14:47:17.521398Z"
    }
   },
   "outputs": [],
   "source": [
    "indices_to_drop_from_test_data = test_label_issues_ordered.index[:11]  # found by manually inspecting test_label_issues_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e2bdb41-321e-4929-aa01-1f60948b9e8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:17.523834Z",
     "iopub.status.busy": "2025-02-27T14:47:17.523453Z",
     "iopub.status.idle": "2025-02-27T14:47:17.527982Z",
     "shell.execute_reply": "2025-02-27T14:47:17.527479Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_cleaned = df_test.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)\n",
    "test_features = test_features.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)\n",
    "test_labels = test_labels.drop(indices_to_drop_from_test_data, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9aba3f-1413-4a04-a74d-eb2febaf6763",
   "metadata": {},
   "source": [
    "### Use clean test data to evaluate the performance of model trained on noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce2d89f-e832-448d-bfac-9941da15c895",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:17.530016Z",
     "iopub.status.busy": "2025-02-27T14:47:17.529696Z",
     "iopub.status.idle": "2025-02-27T14:47:17.566661Z",
     "shell.execute_reply": "2025-02-27T14:47:17.566120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to noisy training data, measured on clean test data: 78.0%\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(test_features)\n",
    "acc_original = accuracy_score(test_labels.astype(int), preds.astype(int))\n",
    "print(\n",
    "    f\"Accuracy of model fit to noisy training data, measured on clean test data: {round(acc_original*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045f5e46-8985-4a7c-bc6f-9f7be509b787",
   "metadata": {},
   "source": [
    "Although curating clean test data does not directly help train a better ML model, more reliable model evaluation can improve your overall ML project. For instance, clean test data enables better informed decisions regarding when to deploy a model and better model/hyperparameter selection. \n",
    "While manually curating data can be tedious, [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/) offers data correction interfaces to streamline this work.\n",
    "\n",
    "\n",
    "## 6. Check for issues in training data and algorithmically correct them\n",
    "\n",
    "To run Datalab on our training set, we first compute out-of-sample predicted probabilities for our training data (via cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f437756-112e-4531-84fc-6ceadd0c9ef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:17.569745Z",
     "iopub.status.busy": "2025-02-27T14:47:17.569009Z",
     "iopub.status.idle": "2025-02-27T14:47:18.137330Z",
     "shell.execute_reply": "2025-02-27T14:47:18.136776Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "num_crossval_folds = 5\n",
    "pred_probs = cross_val_predict(\n",
    "    clf,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    cv=num_crossval_folds,\n",
    "    method=\"predict_proba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323134e9-8339-4847-9a1d-455ca0a6f449",
   "metadata": {},
   "source": [
    "Based on these ML model outputs, we similarly run Datalab to detect issues in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "707625f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.140580Z",
     "iopub.status.busy": "2025-02-27T14:47:18.139850Z",
     "iopub.status.idle": "2025-02-27T14:47:18.282588Z",
     "shell.execute_reply": "2025-02-27T14:47:18.281953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding null issues ...\n",
      "Finding label issues ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding outlier issues ...\n",
      "Finding near_duplicate issues ...\n",
      "Finding non_iid issues ...\n",
      "Finding class_imbalance issues ...\n",
      "Finding underperforming_group issues ...\n",
      "\n",
      "Audit complete. 318 issues found in the dataset.\n",
      "Dataset Information: num_examples: 601, num_classes: 5\n",
      "\n",
      "Here is a summary of various issues found in your data:\n",
      "\n",
      "           issue_type    score  num_issues\n",
      "                label 0.740433         175\n",
      "              outlier 0.344154          72\n",
      "       near_duplicate 0.588290          71\n",
      "                 null 1.000000           0\n",
      "              non_iid 0.437267           0\n",
      "      class_imbalance 0.146423           0\n",
      "underperforming_group 0.977223           0\n",
      "\n",
      "(Note: A lower score indicates a more severe issue across all examples in the dataset.)\n",
      "\n",
      "Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html\n",
      "See which examples in your dataset exhibit each issue via: `datalab.get_issues(<ISSUE_NAME>)`\n",
      "\n",
      "Data indices corresponding to top examples of each issue are shown below.\n",
      "\n",
      "\n",
      "----------------------- label issues -----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples whose given label is estimated to be potentially incorrect\n",
      "    (e.g. due to annotation error) are flagged as having label issues.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 175\n",
      "Overall dataset quality in terms of this issue: 0.7404\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_label_issue  label_score given_label predicted_label\n",
      "162            True     0.000072           F               A\n",
      "348            True     0.000161           B               D\n",
      "232            True     0.000256           F               B\n",
      "205            True     0.000458           F               A\n",
      "400            True     0.000738           C               D\n",
      "\n",
      "\n",
      "---------------------- outlier issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples that are very different from the rest of the dataset \n",
      "    (i.e. potentially out-of-distribution or rare/anomalous instances).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 72\n",
      "Overall dataset quality in terms of this issue: 0.3442\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_outlier_issue  outlier_score\n",
      "588              True   2.358961e-46\n",
      "336              True   2.490911e-36\n",
      "269              True   3.122475e-28\n",
      "321              True   5.374139e-22\n",
      "311              True   1.358617e-17\n",
      "\n",
      "\n",
      "------------------ near_duplicate issues -------------------\n",
      "\n",
      "About this issue:\n",
      "\tA (near) duplicate issue refers to two or more examples in\n",
      "    a dataset that are extremely similar to each other, relative\n",
      "    to the rest of the dataset.  The examples flagged with this issue\n",
      "    may be exactly duplicated, or lie atypically close together when\n",
      "    represented as vectors (i.e. feature embeddings).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 71\n",
      "Overall dataset quality in terms of this issue: 0.5883\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_near_duplicate_issue  near_duplicate_score                       near_duplicate_sets  distance_to_nearest_neighbor\n",
      "600                     True                   0.0  [592, 593, 594, 595, 596, 597, 598, 599]                  0.000000e+00\n",
      "221                     True                   0.0                                     [500]                  0.000000e+00\n",
      "222                     True                   0.0                                [315, 332]                  7.791060e-09\n",
      "243                     True                   0.0                                     [540]                  2.379106e-09\n",
      "599                     True                   0.0  [592, 593, 594, 595, 596, 597, 598, 600]                  0.000000e+00\n",
      "\n",
      "\n",
      "----------------------- null issues ------------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).\n",
      "        \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 1.0000\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_null_issue  null_score\n",
      "0            False         1.0\n",
      "396          False         1.0\n",
      "397          False         1.0\n",
      "398          False         1.0\n",
      "399          False         1.0\n",
      "\n",
      "\n",
      "---------------------- non_iid issues ----------------------\n",
      "\n",
      "About this issue:\n",
      "\tWhether the dataset exhibits statistically significant\n",
      "    violations of the IID assumption like:\n",
      "    changepoints or shift, drift, autocorrelation, etc.\n",
      "    The specific violation considered is whether the\n",
      "    examples are ordered such that almost adjacent examples\n",
      "    tend to have more similar feature values.\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.4373\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_non_iid_issue  non_iid_score\n",
      "165             False       0.550374\n",
      "598             False       0.627357\n",
      "599             False       0.627496\n",
      "597             False       0.627502\n",
      "600             False       0.627919\n",
      "\n",
      "Additional Information: \n",
      "p-value: 0.43726734378061227\n",
      "\n",
      "\n",
      "------------------ class_imbalance issues ------------------\n",
      "\n",
      "About this issue:\n",
      "\tExamples belonging to the most under-represented class in the dataset.\n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.1464\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_class_imbalance_issue  class_imbalance_score given_label\n",
      "321                     False               0.146423           F\n",
      "112                     False               0.146423           F\n",
      "506                     False               0.146423           F\n",
      "393                     False               0.146423           F\n",
      "508                     False               0.146423           F\n",
      "\n",
      "Additional Information: \n",
      "Rarest Class: NA\n",
      "\n",
      "\n",
      "--------------- underperforming_group issues ---------------\n",
      "\n",
      "About this issue:\n",
      "\tAn underperforming group refers to a cluster of similar examples\n",
      "    (i.e. a slice) in the dataset for which the ML model predictions\n",
      "    are particularly poor (loss evaluation over this subpopulation is high).\n",
      "    \n",
      "\n",
      "Number of examples with this issue: 0\n",
      "Overall dataset quality in terms of this issue: 0.9772\n",
      "\n",
      "Examples representing most severe instances of this issue:\n",
      "     is_underperforming_group_issue  underperforming_group_score\n",
      "0                             False                     0.977223\n",
      "402                           False                     0.977223\n",
      "401                           False                     0.977223\n",
      "400                           False                     0.977223\n",
      "399                           False                     0.977223\n"
     ]
    }
   ],
   "source": [
    "train_features_array = train_features.to_numpy()  # could alternatively be model embeddings\n",
    "\n",
    "train_lab = Datalab(data=df_train, label_name=\"noisy_letter_grade\", task=\"classification\")\n",
    "train_lab.find_issues(features=train_features_array, pred_probs=pred_probs)\n",
    "train_lab.report(show_summary_score=True, show_all_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e46f20",
   "metadata": {},
   "source": [
    "Now instead of manually inspecting the detected issues in our training data, we will **automatically filter** all data points out of the training set that cleanlab has flagged as being likely mislabeled, outliers, or near duplicates. Unlike the test data which cannot be blindly auto-curated because we must ensure reliable model evaluation, the training data can be more aggressively modified as long as we're able to faithfully evaluate the resulting fitted model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25afe46c-a521-483c-b168-728c76d970dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.285717Z",
     "iopub.status.busy": "2025-02-27T14:47:18.284897Z",
     "iopub.status.idle": "2025-02-27T14:47:18.293557Z",
     "shell.execute_reply": "2025-02-27T14:47:18.293032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  2,   7,  12,  21,  23,  25,  26,  29,  32,  33,\n",
       "       ...\n",
       "       566, 568, 571, 572, 574, 576, 578, 585, 587, 590],\n",
       "      dtype='int64', length=175)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_issue_results = train_lab.get_issues(\"label\")\n",
    "label_issues_idx = label_issue_results[label_issue_results[\"is_label_issue\"] == True].index\n",
    "label_issues_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6efcf06f-cc40-4964-87df-5204d3b1b9d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.296553Z",
     "iopub.status.busy": "2025-02-27T14:47:18.295793Z",
     "iopub.status.idle": "2025-02-27T14:47:18.303566Z",
     "shell.execute_reply": "2025-02-27T14:47:18.303053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 19,  29,  41,  43,  71,  83,  85,  88, 101, 106, 117, 122, 146, 155,\n",
       "       156, 173, 187, 196, 221, 222, 224, 243, 252, 272, 277, 279, 288, 292,\n",
       "       300, 315, 329, 332, 342, 352, 363, 365, 366, 384, 388, 393, 394, 397,\n",
       "       404, 431, 436, 474, 480, 494, 500, 506, 508, 515, 516, 536, 537, 539,\n",
       "       540, 542, 559, 575, 576, 582, 592, 593, 594, 595, 596, 597, 598, 599,\n",
       "       600],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_duplicates = train_lab.get_issues(\"near_duplicate\")\n",
    "near_duplicates_idx = near_duplicates[near_duplicates[\"is_near_duplicate_issue\"] == True].index\n",
    "near_duplicates_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bc87d72-bbd5-4ed2-bc38-2218862ddfbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.306577Z",
     "iopub.status.busy": "2025-02-27T14:47:18.305813Z",
     "iopub.status.idle": "2025-02-27T14:47:18.312876Z",
     "shell.execute_reply": "2025-02-27T14:47:18.312340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  0,   1,   3,   7,  26,  46,  52,  77,  89,  99, 101, 131, 132, 143,\n",
       "       153, 155, 159, 163, 193, 194, 195, 199, 208, 212, 240, 241, 242, 247,\n",
       "       256, 269, 287, 295, 299, 307, 311, 313, 321, 330, 336, 337, 340, 350,\n",
       "       361, 378, 379, 388, 392, 419, 432, 444, 476, 479, 484, 485, 489, 492,\n",
       "       504, 510, 511, 522, 523, 535, 543, 546, 547, 567, 571, 578, 579, 585,\n",
       "       588, 591],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = train_lab.get_issues(\"outlier\")\n",
    "outliers_idx = outliers[outliers[\"is_outlier_issue\"] == True].index\n",
    "outliers_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c70be3e-0ba2-4e3e-8c50-359d402ca1fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.315790Z",
     "iopub.status.busy": "2025-02-27T14:47:18.315019Z",
     "iopub.status.idle": "2025-02-27T14:47:18.320707Z",
     "shell.execute_reply": "2025-02-27T14:47:18.320204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_drop = list(set(list(label_issues_idx) + list(near_duplicates_idx) + list(outliers_idx)))\n",
    "len(idx_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08080458-0cd7-447d-80e6-384cb8d31eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.322648Z",
     "iopub.status.busy": "2025-02-27T14:47:18.322465Z",
     "iopub.status.idle": "2025-02-27T14:47:18.327052Z",
     "shell.execute_reply": "2025-02-27T14:47:18.326634Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_curated = df_train.drop(idx_to_drop, axis=0).reset_index(drop=True)\n",
    "train_features = train_features.drop(idx_to_drop, axis=0).reset_index(drop=True)\n",
    "train_labels = train_labels.drop(idx_to_drop, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8560d6-70e3-4cee-944e-49f047b9fff4",
   "metadata": {},
   "source": [
    "## 7. Train model on cleaned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "009bb215-4d26-47da-a230-d0ccf4122629",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.329002Z",
     "iopub.status.busy": "2025-02-27T14:47:18.328635Z",
     "iopub.status.idle": "2025-02-27T14:47:18.410677Z",
     "shell.execute_reply": "2025-02-27T14:47:18.410045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_clf = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "clean_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe23e39-fe7b-4145-af55-c7fc1f245850",
   "metadata": {},
   "source": [
    "**In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook.\n",
    "On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0f83f8-07e6-4702-a39e-94336268bfef",
   "metadata": {},
   "source": [
    "### Use clean test data to evaluate the performance of model trained on cleaned training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcaeda51-9b24-4c04-889d-7e63563594fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.413206Z",
     "iopub.status.busy": "2025-02-27T14:47:18.412349Z",
     "iopub.status.idle": "2025-02-27T14:47:18.422176Z",
     "shell.execute_reply": "2025-02-27T14:47:18.421677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to clean training data, measured on clean test data: 78.9%\n"
     ]
    }
   ],
   "source": [
    "clean_preds = clean_clf.predict(test_features)\n",
    "acc_clean = accuracy_score(test_labels.astype(int), clean_preds.astype(int))\n",
    "print(\n",
    "    f\"Accuracy of model fit to clean training data, measured on clean test data: {round(acc_clean*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b367cd66",
   "metadata": {},
   "source": [
    "Although this simple data filtering may not be the maximally effective training set curation (particularly if the initial ML model was poor-quality and hence the detected issues are inaccurate), we can at least faithfully assess its effect using our clean test data. In this case, we do see the resulting ML model has improved, even with this simple training data filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2624388-ad39-4c88-88c3-51a224ad549a",
   "metadata": {},
   "source": [
    "## 8. Identifying better training data curation strategies via hyperparameter optimization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8e3fe-b15f-41e0-87dd-0efb786f2920",
   "metadata": {},
   "source": [
    "Thus far, we've seen how to detect issues in the training and test data to improve model training and evaluation.\n",
    "While we should manually curate the test data to ensure faithful evaluation, we are free to algorithmically curate the training data. Since the simple filtering strategy above is not necessarily optimal, here we consider how to identify a better algorithmic curation strategy. Note however that the **best strategy** will be a hybrid of automated and manual data corrections, as you can efficiently do via the data correction interface in [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/).\n",
    "\n",
    "\n",
    "Above we made basic training data edits to improve test performance, where each one of these data edits can be quantitatively parameterized (eg. what fraction of each issue to filter from the dataset). We can use (hyper)parameter-tuning techniques to automatically search for combinations of training data edits that result in particularly accurate models. Here we apply this hyperparameter optimization to maximize test set performance for brevity, but in practice you should use a separate *validation* set (which you can curate similarly to the test data in this tutorial, in order to ensure reliable model evaluations).\n",
    "\n",
    "We define a dict to parameterize our dataset changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d92d78d-e4a8-4322-bf38-f5a5dae3bf17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.424268Z",
     "iopub.status.busy": "2025-02-27T14:47:18.423730Z",
     "iopub.status.idle": "2025-02-27T14:47:18.426626Z",
     "shell.execute_reply": "2025-02-27T14:47:18.426222Z"
    }
   },
   "outputs": [],
   "source": [
    "default_edit_params = {\n",
    "        \"drop_label_issue\": 0.5,\n",
    "        \"drop_outlier\": 0.5,\n",
    "        \"drop_near_duplicate\": 0.2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcc027-7e51-4583-ab6d-9fc73f847c90",
   "metadata": {},
   "source": [
    "These example values translate into the following training data edits:\n",
    "\n",
    "- `drop_label_issue`: We filter the top 50% of the datapoints flagged with label issues (with most severe label score).\n",
    "- `drop_outlier`: We filter the top 50% most severe outliers based on outlier score (amongst the set of flagged outliers).\n",
    "- `drop_near_duplicate`: We drop **extra copies** of the top 20% of near duplicates (based on near duplicate score). Amongst each set of near duplicates, we keep the data point that has highest self-confidence score for its given label.\n",
    "\n",
    "We will search over various values for these parameters, fit a model to each corresponding training dataset edited based on the parameter values, and see which combination of values yields the best model.\n",
    "\n",
    "**Note:** Datalab detects other issue types that could also be considered in this algorithmic data curation.\n",
    "\n",
    "To more easily apply candidate training data edits, we first sort our data points flagged with each issue type based on the corresponding severity score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "941ab2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.428296Z",
     "iopub.status.busy": "2025-02-27T14:47:18.427848Z",
     "iopub.status.idle": "2025-02-27T14:47:18.437438Z",
     "shell.execute_reply": "2025-02-27T14:47:18.436922Z"
    }
   },
   "outputs": [],
   "source": [
    "label_issues = train_lab.get_issues(\"label\").query(\"is_label_issue\").sort_values(\"label_score\")\n",
    "near_duplicates = train_lab.get_issues(\"near_duplicate\").query(\"is_near_duplicate_issue\").sort_values(\"near_duplicate_score\")\n",
    "outliers = train_lab.get_issues(\"outlier\").query(\"is_outlier_issue\").sort_values(\"outlier_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc7e66",
   "metadata": {},
   "source": [
    "We introduce a `edit_data` function to implement candidate training data edits, fit a model to the edited training set, and evaluate it on our cleaned test data (can skip these details)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc581de-71db-4622-8cfd-ce8a10609bf9",
   "metadata": {},
   "source": [
    "<details><summary>See the implementation of `edit_data` **(click to expand)**</summary>\n",
    "    \n",
    "```python\n",
    "# Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "def edit_data(train_features, train_labels, label_issues, near_duplicates, outliers, \n",
    "              drop_label_issue, drop_near_duplicate, drop_outlier):\n",
    "    \"\"\"\n",
    "    Edits the training data by dropping a specified percentage of data points identified as label issues,\n",
    "    near duplicates, and outliers based on the full datasets provided for each issue type.\n",
    "\n",
    "    Args:\n",
    "        train_features (pd.DataFrame): DataFrame containing the training features.\n",
    "        train_labels (pd.Series): Series containing the training labels.\n",
    "        label_issues (pd.DataFrame): DataFrame containing data points with label issues.\n",
    "        near_duplicates (pd.DataFrame): DataFrame containing data points identified as near duplicates.\n",
    "        outliers (pd.DataFrame): DataFrame containing data points identified as outliers.\n",
    "        drop_label_issue (float): Percentage of label issue data points to drop.\n",
    "        drop_near_duplicate (float): Percentage of near duplicate data points to drop.\n",
    "        drop_outlier (float): Percentage of outlier data points to drop.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned training features.\n",
    "        pd.Series: The cleaned training labels.\n",
    "    \"\"\"\n",
    "    # Extract indices for each type of issue\n",
    "    label_issues_idx = label_issues.index.tolist()\n",
    "    near_duplicates_idx = near_duplicates.index.tolist()\n",
    "    outliers_idx = outliers.index.tolist()\n",
    "\n",
    "    # Calculate the number of each type of data point to drop except near duplicates, which requires separate logic\n",
    "    num_label_issues_to_drop = int(len(label_issues_idx) * drop_label_issue)\n",
    "    num_outliers_to_drop = int(len(outliers_idx) * drop_outlier)\n",
    "\n",
    "    # Calculate number of near duplicates to drop\n",
    "    # Assuming the 'near_duplicate_sets' are lists of indices (integers) of near duplicates\n",
    "    clusters = []\n",
    "    for i in near_duplicates_idx:\n",
    "        # Create a set for each cluster, add the current index to its near duplicate set\n",
    "        cluster = set(near_duplicates.at[i, 'near_duplicate_sets'])\n",
    "        cluster.add(i)\n",
    "        clusters.append(cluster)\n",
    "\n",
    "    # Deduplicate clusters by converting the list of sets to a set of frozensets\n",
    "    unique_clusters = set(frozenset(cluster) for cluster in clusters)\n",
    "\n",
    "    # If you need the unique clusters back in list of lists format:\n",
    "    unique_clusters_list = [list(cluster) for cluster in unique_clusters]\n",
    "\n",
    "    near_duplicates_idx_to_drop = []\n",
    "\n",
    "    for cluster in unique_clusters_list:\n",
    "        # Calculate the number of rows to drop, ensuring at least one datapoint remains\n",
    "        n_drop = max(math.ceil(len(cluster) * drop_near_duplicate), 1)  # Drop at least k% or 1 row\n",
    "        if len(cluster) > n_drop:  # Ensure we keep at least one datapoint\n",
    "            # Randomly select datapoints to drop\n",
    "            drops = random.sample(cluster, n_drop)\n",
    "        else:\n",
    "            # If the cluster is too small, adjust the number to keep at least one datapoint\n",
    "            drops = random.sample(cluster, len(cluster) - 1)  # Keep at least one\n",
    "        near_duplicates_idx_to_drop.extend(drops)\n",
    "\n",
    "    # Determine the specific indices to drop\n",
    "    label_issues_idx_to_drop = label_issues_idx[:num_label_issues_to_drop]\n",
    "    outliers_idx_to_drop = outliers_idx[:num_outliers_to_drop]\n",
    "\n",
    "    # Combine the indices to drop\n",
    "    idx_to_drop = list(set(label_issues_idx_to_drop + near_duplicates_idx_to_drop + outliers_idx_to_drop))\n",
    "\n",
    "    # Drop the rows from the training data\n",
    "    train_features_cleaned = train_features.drop(idx_to_drop).reset_index(drop=True)\n",
    "    train_labels_cleaned = train_labels.drop(idx_to_drop).reset_index(drop=True)\n",
    "\n",
    "    return train_features_cleaned, train_labels_cleaned\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50666fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.439651Z",
     "iopub.status.busy": "2025-02-27T14:47:18.439260Z",
     "iopub.status.idle": "2025-02-27T14:47:18.446002Z",
     "shell.execute_reply": "2025-02-27T14:47:18.445527Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "def edit_data(train_features, train_labels, label_issues, near_duplicates, outliers, drop_label_issue, drop_near_duplicate, drop_outlier):\n",
    "    \"\"\"\n",
    "    Edits the training data by dropping a specified percentage of data points identified as label issues,\n",
    "    near duplicates, and outliers based on the full datasets provided for each issue type.\n",
    "    \n",
    "    Args:\n",
    "        train_features (pd.DataFrame): DataFrame containing the training features.\n",
    "        train_labels (pd.Series): Series containing the training labels.\n",
    "        label_issues (pd.DataFrame): DataFrame containing data points with label issues.\n",
    "        near_duplicates (pd.DataFrame): DataFrame containing data points identified as near duplicates.\n",
    "        outliers (pd.DataFrame): DataFrame containing data points identified as outliers.\n",
    "        drop_label_issue (float): Percentage of label issue data points to drop.\n",
    "        drop_near_duplicate (float): Percentage of near duplicate data points to drop.\n",
    "        drop_outlier (float): Percentage of outlier data points to drop.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned training features.\n",
    "        pd.Series: The cleaned training labels.\n",
    "    \"\"\"\n",
    "    # Extract indices for each type of issue\n",
    "    label_issues_idx = label_issues.index.tolist()\n",
    "    near_duplicates_idx = near_duplicates.index.tolist()\n",
    "    outliers_idx = outliers.index.tolist()\n",
    "    \n",
    "    # Calculate the number of each type of data point to drop except near duplicates, which requires separate logic\n",
    "    num_label_issues_to_drop = int(len(label_issues_idx) * drop_label_issue)\n",
    "    num_outliers_to_drop = int(len(outliers_idx) * drop_outlier)\n",
    "\n",
    "    # Calculate number of near duplicates to drop\n",
    "    # Assuming the 'near_duplicate_sets' are lists of indices (integers) of near duplicates\n",
    "    clusters = []\n",
    "    for i in near_duplicates_idx:\n",
    "        # Create a set for each cluster, add the current index to its near duplicate set\n",
    "        cluster = set(near_duplicates.at[i, 'near_duplicate_sets'])\n",
    "        cluster.add(i)\n",
    "        clusters.append(cluster)\n",
    "    \n",
    "    # Deduplicate clusters by converting the list of sets to a set of frozensets\n",
    "    unique_clusters = set(frozenset(cluster) for cluster in clusters)\n",
    "    \n",
    "    # If you need the unique clusters back in list of lists format:\n",
    "    unique_clusters_list = [list(cluster) for cluster in unique_clusters]\n",
    "    \n",
    "    near_duplicates_idx_to_drop = []\n",
    "    \n",
    "    for cluster in unique_clusters_list:\n",
    "        # Calculate the number of rows to drop, ensuring at least one datapoint remains\n",
    "        n_drop = max(math.ceil(len(cluster) * drop_near_duplicate), 1)  # Drop at least k% or 1 row\n",
    "        if len(cluster) > n_drop:  # Ensure we keep at least one datapoint\n",
    "            # Randomly select datapoints to drop\n",
    "            drops = random.sample(cluster, n_drop)\n",
    "        else:\n",
    "            # If the cluster is too small, adjust the number to keep at least one datapoint\n",
    "            drops = random.sample(cluster, len(cluster) - 1)  # Keep at least one\n",
    "        near_duplicates_idx_to_drop.extend(drops)\n",
    "    \n",
    "    # Determine the specific indices to drop\n",
    "    label_issues_idx_to_drop = label_issues_idx[:num_label_issues_to_drop]\n",
    "    outliers_idx_to_drop = outliers_idx[:num_outliers_to_drop]\n",
    "    \n",
    "    # Combine the indices to drop\n",
    "    idx_to_drop = list(set(label_issues_idx_to_drop + near_duplicates_idx_to_drop + outliers_idx_to_drop))\n",
    "    \n",
    "    # Drop the rows from the training data\n",
    "    train_features_cleaned = train_features.drop(idx_to_drop).reset_index(drop=True)\n",
    "    train_labels_cleaned = train_labels.drop(idx_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    return train_features_cleaned, train_labels_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5aa2883-d20d-481f-a012-fcc7ff8e3e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.447812Z",
     "iopub.status.busy": "2025-02-27T14:47:18.447472Z",
     "iopub.status.idle": "2025-02-27T14:47:18.450743Z",
     "shell.execute_reply": "2025-02-27T14:47:18.450288Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# List of possible values for each data edit parameter to search over (finer grid will yield better results but longer runtimes)\n",
    "param_grid = {\n",
    "    'drop_label_issue': [0.2, 0.5, 0.7, 1.0],\n",
    "    'drop_near_duplicate': [0.0, 0.2, 0.5],\n",
    "    'drop_outlier': [0.2, 0.5, 0.7],\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "param_combinations = list(product(param_grid['drop_label_issue'], param_grid['drop_near_duplicate'], param_grid['drop_outlier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ce1c0ada-88b1-4654-b43f-3c0b59002979",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:18.452454Z",
     "iopub.status.busy": "2025-02-27T14:47:18.452126Z",
     "iopub.status.idle": "2025-02-27T14:47:22.641156Z",
     "shell.execute_reply": "2025-02-27T14:47:22.640547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found in search: {'drop_label_issue': 0.5, 'drop_near_duplicate': 0.0, 'drop_outlier': 0.7}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for drop_label_issue, drop_near_duplicate, drop_outlier in param_combinations:\n",
    "    # Preprocess the data for the current combination of parameters\n",
    "    train_features_preprocessed, train_labels_preprocessed = edit_data(\n",
    "        train_features_v2, train_labels_v2, label_issues, near_duplicates, outliers,\n",
    "        drop_label_issue, drop_near_duplicate, drop_outlier)\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    model = XGBClassifier(tree_method=\"hist\", enable_categorical=True, random_state=SEED)\n",
    "    model.fit(train_features_preprocessed, train_labels_preprocessed)\n",
    "    predictions = model.predict(test_features)\n",
    "    accuracy = accuracy_score(test_labels.astype(int), predictions.astype(int))\n",
    "    \n",
    "    # Update the best score and parameters if the current model is better\n",
    "    if accuracy > best_score:\n",
    "        best_score = accuracy\n",
    "        best_params = {'drop_label_issue': drop_label_issue, 'drop_near_duplicate': drop_near_duplicate, 'drop_outlier': drop_outlier}\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best parameters found in search: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f572acf-31c3-4874-9100-451796e35b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:22.644251Z",
     "iopub.status.busy": "2025-02-27T14:47:22.643488Z",
     "iopub.status.idle": "2025-02-27T14:47:22.647530Z",
     "shell.execute_reply": "2025-02-27T14:47:22.646926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model fit to optimally cleaned training data, measured on clean test data: 82.1%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Accuracy of model fit to optimally cleaned training data, measured on clean test data: {round(best_score*100,1)}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc306eff-f3b7-4098-9f7e-3d17d1d0016a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This tutorial demonstrated how you can properly use cleanlab to improve your own ML model. When dealing with noisy data, you should **first manually curate your test data to ensure reliable model evaluation**. After that, you can **algorithmically curate your training data**. We demonstrated a simple hyperparameter tuning technique to identify effective training data edits that produce an accurate model. As well as how cleanlab can help catch fundamental problems in the overall train/test setup like duplicates/leakage and data drift.\n",
    "\n",
    "Note that we never evaluated different models with different test set versions (which does **not** yield meaningful comparisons). We curated the test data to be as high-quality as possible and then based all model evaluations on this fixed version of the test data.\n",
    "\n",
    "For brevity, this tutorial focused mostly around label issues and data pruning strategies. For classification tasks where you already have high-quality test data and solely want to handle label errors in your training data: cleanlab's `CleanLearning` class offers an *alternative* convenience method to **train a robust ML model**. You can achieve **better results** by considering additional data issues beyond label errors and curation strategies like fixing incorrect values -- this is all streamlined via the intelligent data correction interface of [Cleanlab Studio](https://cleanlab.ai/blog/data-centric-ai/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a025a88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-27T14:47:22.649547Z",
     "iopub.status.busy": "2025-02-27T14:47:22.649174Z",
     "iopub.status.idle": "2025-02-27T14:47:22.651960Z",
     "shell.execute_reply": "2025-02-27T14:47:22.651499Z"
    },
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# Note: This cell is only for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.\n",
    "\n",
    "assert(acc_clean*100 - acc_original*100 >= 0.8)\n",
    "assert(best_score*100 - acc_clean*100 >= 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
