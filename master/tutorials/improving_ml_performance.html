<!doctype html>
<html class="no-js" lang="en" data-content_root="">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />

        <script async src="https://www.googletagmanager.com/gtag/js?id=G-EV8RVEFX82"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            
            gtag('config', 'G-EV8RVEFX82');
            
        </script>
    <meta property="og:title" content="Improving ML Performance via Data Curation with Train vs Test Splits" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://docs.cleanlab.ai/master/tutorials/improving_ml_performance.html" />
<meta property="og:site_name" content="cleanlab" />
<meta property="og:description" content="In typical Machine Learning projects, we split our dataset into training data for fitting models and test data to evaluate model performance. For noisy real-world datasets, detecting/correcting err..." />
<meta property="og:image" content="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/clos-preview-card.png" />
<meta property="og:image:alt" content="cleanlab" />
<meta name="description" content="In typical Machine Learning projects, we split our dataset into training data for fitting models and test data to evaluate model performance. For noisy real-world datasets, detecting/correcting err..." />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="CleanLearning Tutorials" href="clean_learning/index.html" /><link rel="prev" title="Miscellaneous workflows with Datalab" href="datalab/workflows.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/a4483476d449f2f05a4c7cde329e72358099cc07/cleanlab/cleanlab_favicon.svg"/><!-- Generated with Sphinx 7.1.2 and Furo 2023.09.10 -->
        <title>Improving ML Performance via Data Curation with Train vs Test Splits - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=135e06be" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css?v=a5c4661c" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css?v=91adb8b6" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom.css?v=96bccb3e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a style="padding-bottom: 0px;" class="sidebar-brand" href="../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo" />
    </div>
    
    <span style="margin-bottom:0px" class="sidebar-brand-text">
        cleanlab
    </span>
    
</a>

<div class="centered">
    <a style="margin-top: 6px;" class="github-button" href="https://github.com/cleanlab/cleanlab" data-size="large" data-show-count="true"
    aria-label="Star cleanlab/cleanlab on GitHub">Star</a>
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1 has-children"><a class="reference internal" href="datalab/index.html">Datalab Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of Datalab Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="datalab/datalab_quickstart.html">Detecting Common Data Issues with Datalab</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/datalab_advanced.html">Advanced Data Auditing with Datalab</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/text.html">Text Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/tabular.html">Tabular Data (Numeric/Categorical)</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/image.html">Image Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/audio.html">Audio Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/guide/issue_type_description.html">Guide to Datalab Issue Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="datalab/workflows.html">Miscellaneous workflows with Datalab</a></li>
</ul>
</li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Improving ML Performance</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="clean_learning/index.html">CleanLearning Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of CleanLearning Tutorials</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="clean_learning/text.html">Text Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="clean_learning/tabular.html">Tabular Classification (Numeric/Categorical)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="indepth_overview.html">Workflows of Data-Centric AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_health.html">Analyze Dataset-level Issues</a></li>
<li class="toctree-l1"><a class="reference internal" href="outliers.html">Outlier Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiannotator.html">Improving Consensus Labels for Multiannotator Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="multilabel_classification.html">Multi-Label Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="regression.html">Noisy Labels in Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="token_classification.html">Token Classification (text)</a></li>
<li class="toctree-l1"><a class="reference internal" href="segmentation.html">Image Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="object_detection.html">Object Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_probs_cross_val.html">Predicted Probabilities via Cross Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/datalab/index.html">datalab</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of datalab</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cleanlab/datalab/guide/index.html">Datalab guides</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of Datalab guides</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/guide/issue_type_description.html">Datalab Issue Types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/guide/custom_issue_manager.html">Creating Your Own Issues Manager</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/datalab.html">datalab</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle navigation of internal</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/data.html">data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/data_issues.html">data_issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/issue_finder.html">issue_finder</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/factory.html">factory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/model_outputs.html">model_outputs</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/index.html">issue_manager</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle navigation of issue_manager</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/issue_manager.html">Base issue_manager module</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/label.html">label</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/outlier.html">outlier</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/duplicate.html">duplicate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/noniid.html">noniid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/imbalance.html">imbalance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/underperforming_group.html">underperforming_group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/null.html">null</a></li>
<li class="toctree-l4"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/data_valuation.html">data_valuation</a></li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/regression/index.html">regression</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle navigation of regression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/regression/label.html">label</a></li>
</ul>
</li>
<li class="toctree-l4 has-children"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/multilabel/index.html">multilabel</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle navigation of multilabel</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l5"><a class="reference internal" href="../cleanlab/datalab/internal/issue_manager/multilabel/label.html">label</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/report.html">report</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/datalab/internal/task.html">task</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/count.html">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/dataset.html">dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/outlier.html">outlier</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/multiannotator.html">multiannotator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/data_valuation.html">data_valuation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/multilabel_classification/index.html">multilabel_classification</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle navigation of multilabel_classification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/multilabel_classification/dataset.html">dataset</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/regression/index.html">regression</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle navigation of regression</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/regression/rank.html">regression.rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/regression/learn.html">regression.learn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/token_classification/index.html">token_classification</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle navigation of token_classification</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/token_classification/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/segmentation/index.html">segmentation</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle navigation of segmentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/segmentation/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/object_detection/index.html">object_detection</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle navigation of object_detection</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/rank.html">rank</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/filter.html">filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/object_detection/summary.html">summary</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/benchmarking/index.html">benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle navigation of benchmarking</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/benchmarking/noise_generation.html">noise_generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/models/index.html">models</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle navigation of models</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/models/keras.html">keras</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/experimental/index.html">experimental</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle navigation of experimental</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/label_issues_batched.html">label_issues_batched</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/span_classification.html">span_classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/mnist_pytorch.html">mnist_pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/coteaching.html">coteaching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/cifar_cnn.html">cifar_cnn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle navigation of internal</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/label_quality_utils.html">label_quality_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/multilabel_utils.html">multilabel_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/multilabel_scorer.html">multilabel_scorer</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../cleanlab/internal/neighbor/index.html">neighbor</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle navigation of neighbor</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/internal/neighbor/knn_graph.html">knn_graph</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/internal/neighbor/metric.html">metric</a></li>
<li class="toctree-l3"><a class="reference internal" href="../cleanlab/internal/neighbor/search.html">search</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/outlier.html">outlier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/token_classification_utils.html">token_classification_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/validation.html">validation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/datalab/guide/index.html">Datalab issue types</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle navigation of Datalab issue types</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/guide/issue_type_description.html">Datalab Issue Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/datalab/guide/custom_issue_manager.html">Creating Your Own Issues Manager</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab/blob/master/CONTRIBUTING.md">How to contribute</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/conda-forge/cleanlab">Conda</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai/slack">Community Discussions</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai/blog/">Blog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/@CleanlabAI/playlists">Videos</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab Studio (Easy Mode)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://help.cleanlab.ai">Cleanlab Studio Docs</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/cleanlab-docs/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/cleanlab-docs/master/"
                >developer</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.6"
                class="reference internal"
                href="/cleanlab-docs/v2.6.6/"
                >v2.6.6</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.5"
                class="reference internal"
                href="/cleanlab-docs/v2.6.5/"
                >v2.6.5</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.4"
                class="reference internal"
                href="/cleanlab-docs/v2.6.4/"
                >v2.6.4</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.3"
                class="reference internal"
                href="/cleanlab-docs/v2.6.3/"
                >v2.6.3</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.2"
                class="reference internal"
                href="/cleanlab-docs/v2.6.2/"
                >v2.6.2</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.1"
                class="reference internal"
                href="/cleanlab-docs/v2.6.1/"
                >v2.6.1</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.6.0"
                class="reference internal"
                href="/cleanlab-docs/v2.6.0/"
                >v2.6.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.5.0"
                class="reference internal"
                href="/cleanlab-docs/v2.5.0/"
                >v2.5.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.4.0"
                class="reference internal"
                href="/cleanlab-docs/v2.4.0/"
                >v2.4.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.3.1"
                class="reference internal"
                href="/cleanlab-docs/v2.3.1/"
                >v2.3.1</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.3.0"
                class="reference internal"
                href="/cleanlab-docs/v2.3.0/"
                >v2.3.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.2.0"
                class="reference internal"
                href="/cleanlab-docs/v2.2.0/"
                >v2.2.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.1.0"
                class="reference internal"
                href="/cleanlab-docs/v2.1.0/"
                >v2.1.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v2.0.0"
                class="reference internal"
                href="/cleanlab-docs/v2.0.0/"
                >v2.0.0</a
            >
        </li>
        
        <li class="toctree-l1">
            <a
                id="v1.0.1"
                class="reference internal"
                href="/cleanlab-docs/v1.0.1/"
                >v1.0.1</a
            >
        </li>
        
    </ul>
</div>

<br>
<br>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/cleanlab-docs/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number) && !path_arr.includes("stable")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">master</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/cleanlab-docs/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 <style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }

    .output_area {
        max-height: 300px;
        overflow: auto;
    }

    .dataframe {
        background: #D7D7D7;
    }

    th {
        color:black;
    }
</style>

<script type="text/javascript">
    window.addEventListener('load', () => {
        const h1_element = document.getElementsByTagName("h1");
        h1_element[0].insertAdjacentHTML("afterend", `
        <p>
            <a style="background-color:white;color:black;padding:4px 12px;text-decoration:none;display:inline-block;border-radius:8px;box-shadow:0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 3px 10px 0 rgba(0, 0, 0, 0.19)" href="https://colab.research.google.com/github/elisno/cleanlab-docs/blob/master/master/tutorials/improving_ml_performance.ipynb" target="_blank">
            <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="" style="width:40px;height:40px;vertical-align:middle">
            <span style="vertical-align:middle">Run in Google Colab</span>
            </a>
        </p>
        `);
    })

</script><section id="Improving-ML-Performance-via-Data-Curation-with-Train-vs-Test-Splits">
<h1>Improving ML Performance via Data Curation with Train vs Test Splits<a class="headerlink" href="#Improving-ML-Performance-via-Data-Curation-with-Train-vs-Test-Splits" title="Permalink to this heading">#</a></h1>
<p>In typical Machine Learning projects, we split our dataset into <strong>training</strong> data for fitting models and <strong>test</strong> data to evaluate model performance. For noisy real-world datasets, detecting/correcting errors in the training data is important to train robust models, but it’s less recognized that the test set can also be noisy. For accurate model evaluation, it is vital to <strong>find and fix issues in the test data</strong> as well. Some evaluation metrics are particularly sensitive to outliers and noisy
labels. This tutorial demonstrates a way to use cleanlab (via <code class="docutils literal notranslate"><span class="pre">Datalab</span></code>) to curate both your training and test data, ensuring <strong>robust model training</strong> and <strong>reliable performance evaluation</strong>. We recommend first completing some Datalab tutorials before diving into this more complex subject.</p>
<p>Here’s how we recommend handling noisy training and test data (this tutorial walks through these steps):</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d">Preprocess</a> your training and test data to be suitable for ML. Use cleanlab to check for fundamental train/test setup problems in the merged dataset like train/test leakage or drift.</p></li>
<li><p>Fit your ML model to your noisy training data and get its predictions/embeddings for your test data. Use these model outputs with cleanlab to detect issues in your <strong>test</strong> data.</p></li>
<li><p>Manually review/correct cleanlab-detected issues in your test data. <strong>We caution against blindly automated correction of test data</strong>. Changes to your test set should be carefully verified to ensure they will lead to more accurate model evaluation. We also caution against comparing the performance of different ML models across different versions of your test data; performance comparions between models should be based on the same test data.</p></li>
<li><p>Cross-validate a new copy of your ML model on your training data, and then use it with cleanlab to detect issues in the <strong>training</strong> dataset. Do not include test data in any part of this step to avoid leaking test set information into the training data curation.</p></li>
<li><p>You can try <strong>automated techniques</strong> to curate your training data based on cleanlab results, train models on the curated training data, and evaluate them on the cleaned test data.</p></li>
</ol>
<p>Consider this tutorial as a blueprint for using cleanlab in diverse ML projects spanning various data modalities. The same ideas apply if you substitute <em>test</em> data with <em>validation</em> data above. In a final advanced section of this tutorial, we show how training data edits can be parameterized in terms of cleanlab’s detected issues, such that hyperparameter optimization can identify the optimal combination of data edits for training an effective ML model.</p>
<p><strong>Note</strong>: This tutorial trains an XGBoost model on a tabular dataset, but the same approach applies to <em>any</em> ML model and data modality.</p>
<section id="Why-did-you-make-this-tutorial?">
<h2>Why did you make this tutorial?<a class="headerlink" href="#Why-did-you-make-this-tutorial?" title="Permalink to this heading">#</a></h2>
<p><strong>TLDR:</strong> Reliable ML requires both reliable training and reliable evaluation. This tutorial shows you how to achieve both using cleanlab.</p>
<p><strong>Longer answer:</strong> Many users wish to use cleanlab to improve their ML model by improving their data, but make subtle mistakes. This multi-step tutorial shows one way to do this properly. Some users curate (e.g. fix label issues in) their training data, train ML model, and evaluate it on test data. But they see no improvement in test-set accuracy, because they have introduced <em>distribution-shift</em> by altering their training data. If the test data also has issues, they must also be fixed for a
faithful model evaluation. Other users therefore curate their test data too, but some blindly auto-fix their test data, which is dangerous! This cleanlab package is based on ML and thus inevitably imperfect. Issues that cleanlab detected in test data should <strong>not</strong> be blindly auto-fixed – this risks making model evaluation wrong. Instead we recommend the multi-step workflow above, where less algorithmic/automated correction is applied to test data than to training data (focus your manual
efforts on curating test rather than training data).</p>
<section id="1.-Install-dependencies">
<h3>1. Install dependencies<a class="headerlink" href="#1.-Install-dependencies" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">Datalab</span></code> has additional dependencies that are not included in the standard installation of cleanlab. You can use <code class="docutils literal notranslate"><span class="pre">pip</span></code> to install all packages required for this tutorial as follows:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>xgboost
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span><span class="s2">&quot;cleanlab[datalab]&quot;</span>
<span class="c1"># Make sure to install the version corresponding to this tutorial</span>
<span class="c1"># E.g. if viewing master branch documentation:</span>
<span class="c1">#     !pip install git+https://github.com/cleanlab/cleanlab.git</span>
</pre></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">cleanlab</span>
<span class="kn">from</span> <span class="nn">cleanlab</span> <span class="kn">import</span> <span class="n">Datalab</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="mi">123456</span>  <span class="c1"># for reproducibility</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="2.-Preprocess-the-data">
<h3>2. Preprocess the data<a class="headerlink" href="#2.-Preprocess-the-data" title="Permalink to this heading">#</a></h3>
<p>This tutorial considers a classification task with structured/tabular data. The ML task is to predict each student’s final grade in a course (class label) based on various numeric/categorical features about them (exam scores and notes).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_train_data.csv&quot;</span>
<span class="p">)</span>

<span class="n">df_test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s2">&quot;https://cleanlab-public.s3.amazonaws.com/Datasets/student-grades/clos_test_data.csv&quot;</span>
<span class="p">)</span>

<span class="n">df_train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>stud_ID</th>
      <th>exam_1</th>
      <th>exam_2</th>
      <th>exam_3</th>
      <th>notes</th>
      <th>noisy_letter_grade</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>018bff</td>
      <td>94.0</td>
      <td>41.0</td>
      <td>91.0</td>
      <td>great participation +10</td>
      <td>B</td>
    </tr>
    <tr>
      <th>1</th>
      <td>076d92</td>
      <td>0.0</td>
      <td>79.0</td>
      <td>65.0</td>
      <td>cheated on exam, gets 0pts</td>
      <td>F</td>
    </tr>
    <tr>
      <th>2</th>
      <td>c80059</td>
      <td>86.0</td>
      <td>89.0</td>
      <td>85.0</td>
      <td>great final presentation +10</td>
      <td>F</td>
    </tr>
    <tr>
      <th>3</th>
      <td>e38f8a</td>
      <td>50.0</td>
      <td>67.0</td>
      <td>94.0</td>
      <td>great final presentation +10</td>
      <td>B</td>
    </tr>
    <tr>
      <th>4</th>
      <td>d57e1a</td>
      <td>92.0</td>
      <td>79.0</td>
      <td>98.0</td>
      <td>great final presentation +10</td>
      <td>A</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Before training a ML model, we <a class="reference external" href="https://towardsdatascience.com/introduction-to-data-preprocessing-in-machine-learning-a9fa83a5dc9d">preprocess</a> our dataset. The type of preprocessing that is best will depend on what ML model you use. This tutorial will demonstrate an XGBoost model, so we’ll process the <strong>notes</strong> and <strong>noisy_letter_grade</strong> columns into categorical columns for this model (each category encoded as an integer). You can alternatively use <a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab
Studio</a>, which will automatically produce a high-accuracy ML model for your raw data, without you having to worry about any ML modeling or data preprocessing work.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create label encoders for the categorical columns</span>
<span class="n">grade_le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">notes_le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>

<span class="c1"># Process the feature columns</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">,</span> <span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">notes_le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">])</span>
<span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span>

<span class="c1"># Process the label column</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grade_le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">])</span>

<span class="c1"># Keep separate copies of these training features and labels for later use</span>
<span class="n">train_features_v2</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">train_labels_v2</span> <span class="o">=</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>We first solely preprocessed the training data to avoid information leakage (using test data information that would not be available at prediction time). Here’s how the preprocessed training features look:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_features</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exam_1</th>
      <th>exam_2</th>
      <th>exam_3</th>
      <th>notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>94.0</td>
      <td>41.0</td>
      <td>91.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>79.0</td>
      <td>65.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>86.0</td>
      <td>89.0</td>
      <td>85.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>50.0</td>
      <td>67.0</td>
      <td>94.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>92.0</td>
      <td>79.0</td>
      <td>98.0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We apply the same preprocessing to the test data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_features</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">,</span> <span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">notes_le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">])</span>
<span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;category&quot;</span><span class="p">)</span>

<span class="n">test_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grade_le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<p>We then appropriately format the datasets for the ML model used in this tutorial.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>

<span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_features</span><span class="p">[</span><span class="s2">&quot;notes&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">preprocessed_train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">preprocessed_train_data</span><span class="p">[</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">]</span>

<span class="n">preprocessed_test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">test_features</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">preprocessed_test_data</span><span class="p">[</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_test</span><span class="p">[</span><span class="s2">&quot;stud_ID&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</section>
<section id="3.-Check-for-fundamental-problems-in-the-train/test-setup">
<h3>3. Check for fundamental problems in the train/test setup<a class="headerlink" href="#3.-Check-for-fundamental-problems-in-the-train/test-setup" title="Permalink to this heading">#</a></h3>
<p>Before training any ML model, we can quickly check for fundamental issues in our setup with cleanlab. To audit all of our data at once, we merge the training and test sets into one dataset, from which we construct a <code class="docutils literal notranslate"><span class="pre">Datalab</span></code> object. Datalab automatically detects many types of common issues in a dataset, but requires a trained ML model for a comprehensive audit. We haven’t trained any model yet, so here we instruct Datalab to only check for specific data issues: near duplicates, and whether
the data appears non-IID (violations of the IID assumption include: data drift or lack of statistical independence between data points).</p>
<p>Datalab can detect many additional types of data issues, depending on what inputs it is given. Below we provide <code class="docutils literal notranslate"><span class="pre">features</span> <span class="pre">=</span> <span class="pre">features_df</span></code> as the sole input to <code class="docutils literal notranslate"><span class="pre">Datalab.find_issues()</span></code>, which solely contains numerical values here. If you have heterogenoues/complex data types (eg. text or images), you could instead provide vector feature representations (eg. pretrained model embeddings) of your data as the <code class="docutils literal notranslate"><span class="pre">features</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">preprocessed_train_data</span><span class="p">,</span> <span class="n">preprocessed_test_data</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">features_df</span> <span class="o">=</span> <span class="n">full_df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">,</span> <span class="s2">&quot;stud_ID&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># can instead use model embeddings</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lab</span> <span class="o">=</span> <span class="n">Datalab</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">full_df</span><span class="p">,</span> <span class="n">label_name</span><span class="o">=</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">lab</span><span class="o">.</span><span class="n">find_issues</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">features_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(),</span> <span class="n">issue_types</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;near_duplicate&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;non_iid&quot;</span><span class="p">:</span> <span class="p">{}})</span>
<span class="n">lab</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">show_summary_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_all_issues</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Finding near_duplicate issues ...
Finding non_iid issues ...

Audit complete. 100 issues found in the dataset.
Dataset Information: num_examples: 749, num_classes: 5

Here is a summary of various issues found in your data:

    issue_type    score  num_issues
near_duplicate 0.583745         100
       non_iid 0.291382           0

(Note: A lower score indicates a more severe issue across all examples in the dataset.)

Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html
See which examples in your dataset exhibit each issue via: `datalab.get_issues(&lt;ISSUE_NAME&gt;)`

Data indices corresponding to top examples of each issue are shown below.


------------------ near_duplicate issues -------------------

About this issue:
        A (near) duplicate issue refers to two or more examples in
    a dataset that are extremely similar to each other, relative
    to the rest of the dataset.  The examples flagged with this issue
    may be exactly duplicated, or lie atypically close together when
    represented as vectors (i.e. feature embeddings).


Number of examples with this issue: 100
Overall dataset quality in terms of this issue: 0.5837

Examples representing most severe instances of this issue:
     is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor
748                     True                   0.0               [604]                           0.0
510                     True                   0.0               [227]                           0.0
71                      True                   0.0               [719]                           0.0
65                      True                   0.0          [690, 444]                           0.0
547                     True                   0.0               [647]                           0.0


---------------------- non_iid issues ----------------------

About this issue:
        Whether the dataset exhibits statistically significant
    violations of the IID assumption like:
    changepoints or shift, drift, autocorrelation, etc.
    The specific violation considered is whether the
    examples are ordered such that almost adjacent examples
    tend to have more similar feature values.


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.2914

Examples representing most severe instances of this issue:
     is_non_iid_issue  non_iid_score
611             False       0.687869
610             False       0.687883
612             False       0.688146
609             False       0.688189
613             False       0.688713

Additional Information:
p-value: 0.2913818469137725
</pre></div></div>
</div>
<p>cleanlab does not find significant evidence that our data is non-<a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">IID</a>, which is good. Otherwise, we’d need to further consider where our data came from and whether conclusions/predictions from this dataset can really generalize to our population of interest.</p>
<p>But cleanlab did detect many near duplicates in the dataset. We see some exact duplicates between our training and test data, which may indicate data leakage! Since we didn’t expect these duplicates in our dataset, let’s drop the extra duplicated copies of test data points found in our training set from this training set. This helps ensure that our model evaluations reflect generalization capabilities. Here’s how we can review the near duplicates detected via Datalab.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_duplicate_results</span> <span class="o">=</span> <span class="n">lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;near_duplicate&quot;</span><span class="p">)</span>
<span class="n">full_duplicate_results</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;near_duplicate_score&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>is_near_duplicate_issue</th>
      <th>near_duplicate_score</th>
      <th>near_duplicate_sets</th>
      <th>distance_to_nearest_neighbor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>748</th>
      <td>True</td>
      <td>0.0</td>
      <td>[604]</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>510</th>
      <td>True</td>
      <td>0.0</td>
      <td>[227]</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>71</th>
      <td>True</td>
      <td>0.0</td>
      <td>[719]</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>65</th>
      <td>True</td>
      <td>0.0</td>
      <td>[690, 444]</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>547</th>
      <td>True</td>
      <td>0.0</td>
      <td>[647]</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>To distinguish between near vs. exact duplicates, we can filter where the <code class="docutils literal notranslate"><span class="pre">distance_to_nearest_neighbor</span></code> column has value = 0. We specifically filter for exact duplicates between our training and test set in order to drop the extra copies of such data points from our training set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_idx_cutoff</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">preprocessed_train_data</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># last index of training data in the merged dataset</span>

<span class="c1"># Create column to list which duplicate sets include some test data:</span>
<span class="n">full_duplicate_results</span><span class="p">[</span><span class="s1">&#39;nd_set_has_index_over_training_cutoff&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">full_duplicate_results</span><span class="p">[</span><span class="s1">&#39;near_duplicate_sets&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">any</span><span class="p">(</span><span class="n">i</span> <span class="o">&gt;</span> <span class="n">train_idx_cutoff</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>

<span class="n">exact_duplicates</span> <span class="o">=</span> <span class="n">full_duplicate_results</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;is_near_duplicate_issue == True and near_duplicate_score == 0.0 and nd_set_has_index_over_training_cutoff == True&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;near_duplicate_score&quot;</span><span class="p">)</span>
<span class="n">exact_duplicates</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>is_near_duplicate_issue</th>
      <th>near_duplicate_score</th>
      <th>near_duplicate_sets</th>
      <th>distance_to_nearest_neighbor</th>
      <th>nd_set_has_index_over_training_cutoff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>33</th>
      <td>True</td>
      <td>0.0</td>
      <td>[627]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>53</th>
      <td>True</td>
      <td>0.0</td>
      <td>[678]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>65</th>
      <td>True</td>
      <td>0.0</td>
      <td>[690, 444]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>71</th>
      <td>True</td>
      <td>0.0</td>
      <td>[719]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>82</th>
      <td>True</td>
      <td>0.0</td>
      <td>[709]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>100</th>
      <td>True</td>
      <td>0.0</td>
      <td>[615]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>292</th>
      <td>True</td>
      <td>0.0</td>
      <td>[620]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>420</th>
      <td>True</td>
      <td>0.0</td>
      <td>[704]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>431</th>
      <td>True</td>
      <td>0.0</td>
      <td>[688]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>459</th>
      <td>True</td>
      <td>0.0</td>
      <td>[672]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>547</th>
      <td>True</td>
      <td>0.0</td>
      <td>[647]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>564</th>
      <td>True</td>
      <td>0.0</td>
      <td>[696]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>604</th>
      <td>True</td>
      <td>0.0</td>
      <td>[748]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
    <tr>
      <th>605</th>
      <td>True</td>
      <td>0.0</td>
      <td>[723]</td>
      <td>0.0</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exact_duplicates_indices</span> <span class="o">=</span> <span class="n">exact_duplicates</span><span class="o">.</span><span class="n">index</span>
<span class="n">exact_duplicates_indices</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Index([33, 53, 65, 71, 82, 100, 292, 420, 431, 459, 547, 564, 604, 605], dtype=&#39;int64&#39;)
</pre></div></div>
</div>
<p>Below we remove the exact duplicates that occur between our training and test sets from the training data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indices_of_duplicates_to_drop</span> <span class="o">=</span> <span class="p">[</span><span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">exact_duplicates_indices</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;=</span> <span class="n">train_idx_cutoff</span><span class="p">]</span>
<span class="n">indices_of_duplicates_to_drop</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[33, 53, 65, 71, 82, 100, 292, 420, 431, 459, 547, 564, 604, 605]
</pre></div></div>
</div>
<p>Here are the examples we’ll drop from our <em>training</em> data, since they are exact duplicates of <em>test</em> examples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">full_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">indices_of_duplicates_to_drop</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>exam_1</th>
      <th>exam_2</th>
      <th>exam_3</th>
      <th>notes</th>
      <th>noisy_letter_grade</th>
      <th>stud_ID</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>33</th>
      <td>83.0</td>
      <td>92.0</td>
      <td>80.0</td>
      <td>3</td>
      <td>2</td>
      <td>4a3f75</td>
    </tr>
    <tr>
      <th>53</th>
      <td>91.0</td>
      <td>0.0</td>
      <td>94.0</td>
      <td>0</td>
      <td>3</td>
      <td>d030b5</td>
    </tr>
    <tr>
      <th>65</th>
      <td>93.0</td>
      <td>73.0</td>
      <td>82.0</td>
      <td>5</td>
      <td>1</td>
      <td>ddd0ba</td>
    </tr>
    <tr>
      <th>71</th>
      <td>90.0</td>
      <td>95.0</td>
      <td>75.0</td>
      <td>1</td>
      <td>0</td>
      <td>8e6d24</td>
    </tr>
    <tr>
      <th>82</th>
      <td>78.0</td>
      <td>81.0</td>
      <td>74.0</td>
      <td>4</td>
      <td>3</td>
      <td>464aab</td>
    </tr>
    <tr>
      <th>100</th>
      <td>80.0</td>
      <td>96.0</td>
      <td>83.0</td>
      <td>4</td>
      <td>2</td>
      <td>ee3387</td>
    </tr>
    <tr>
      <th>292</th>
      <td>79.0</td>
      <td>62.0</td>
      <td>82.0</td>
      <td>5</td>
      <td>2</td>
      <td>61e807</td>
    </tr>
    <tr>
      <th>420</th>
      <td>99.0</td>
      <td>53.0</td>
      <td>76.0</td>
      <td>5</td>
      <td>2</td>
      <td>71d7b9</td>
    </tr>
    <tr>
      <th>431</th>
      <td>90.0</td>
      <td>92.0</td>
      <td>88.0</td>
      <td>2</td>
      <td>0</td>
      <td>83e31f</td>
    </tr>
    <tr>
      <th>459</th>
      <td>70.0</td>
      <td>63.0</td>
      <td>95.0</td>
      <td>2</td>
      <td>1</td>
      <td>edeb53</td>
    </tr>
    <tr>
      <th>547</th>
      <td>68.0</td>
      <td>93.0</td>
      <td>73.0</td>
      <td>5</td>
      <td>2</td>
      <td>cd52b5</td>
    </tr>
    <tr>
      <th>564</th>
      <td>84.0</td>
      <td>92.0</td>
      <td>86.0</td>
      <td>5</td>
      <td>1</td>
      <td>454e51</td>
    </tr>
    <tr>
      <th>604</th>
      <td>87.0</td>
      <td>74.0</td>
      <td>95.0</td>
      <td>3</td>
      <td>2</td>
      <td>042686</td>
    </tr>
    <tr>
      <th>605</th>
      <td>96.0</td>
      <td>83.0</td>
      <td>73.0</td>
      <td>1</td>
      <td>0</td>
      <td>12a73f</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_of_duplicates_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_of_duplicates_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_of_duplicates_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="4.-Train-model-with-original-(noisy)-training-data">
<h3>4. Train model with original (noisy) training data<a class="headerlink" href="#4.-Train-model-with-original-(noisy)-training-data" title="Permalink to this heading">#</a></h3>
<p>After handling fundamental issues in our training/test setup, let’s fit our ML model to the training data. Here we use XGBoost as an example, but the same ideas of this tutorial apply to any other ML model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">]</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">tree_method</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span> <span class="n">enable_categorical</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=True, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;XGBClassifier<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=True, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div></div>
</div>
</section>
</section>
<section id="Compute-out-of-sample-predicted-probabilities-for-the-test-data-from-this-baseline-model">
<h2>Compute out-of-sample predicted probabilities for the test data from this baseline model<a class="headerlink" href="#Compute-out-of-sample-predicted-probabilities-for-the-test-data-from-this-baseline-model" title="Permalink to this heading">#</a></h2>
<p>Make sure that the columns of your predicted class probabilities are properly ordered with respect to the ordering of classes, which for Datalab is: lexicographically sorted by class name.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_pred_probs</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="5.-Check-for-issues-in-test-data-and-manually-address-them">
<h3>5. Check for issues in test data and manually address them<a class="headerlink" href="#5.-Check-for-issues-in-test-data-and-manually-address-them" title="Permalink to this heading">#</a></h3>
<p>While we could evaluate our model’s accuracy using the predictions above, this will be unreliable if the test data have issues. Based on the given labels, model predictions, and feature representations, Datalab can automatically detect issues lurking in our test data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_lab</span> <span class="o">=</span> <span class="n">Datalab</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_test</span><span class="p">,</span> <span class="n">label_name</span><span class="o">=</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">test_features_array</span> <span class="o">=</span> <span class="n">test_features</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>  <span class="c1"># could alternatively be model embeddings</span>
<span class="n">test_lab</span><span class="o">.</span><span class="n">find_issues</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">test_features_array</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">test_pred_probs</span><span class="p">)</span>
<span class="n">test_lab</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">show_summary_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_all_issues</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Finding null issues ...
Finding label issues ...
Finding outlier issues ...
Finding near_duplicate issues ...
Finding non_iid issues ...
Finding class_imbalance issues ...
Finding underperforming_group issues ...

Audit complete. 30 issues found in the dataset.
Dataset Information: num_examples: 134, num_classes: 5

Here is a summary of various issues found in your data:

           issue_type    score  num_issues
                label 0.798507          25
              outlier 0.370259           5
                 null 1.000000           0
       near_duplicate 0.625352           0
              non_iid 0.524042           0
      class_imbalance 0.097015           0
underperforming_group 1.000000           0

(Note: A lower score indicates a more severe issue across all examples in the dataset.)

Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html
See which examples in your dataset exhibit each issue via: `datalab.get_issues(&lt;ISSUE_NAME&gt;)`

Data indices corresponding to top examples of each issue are shown below.


----------------------- label issues -----------------------

About this issue:
        Examples whose given label is estimated to be potentially incorrect
    (e.g. due to annotation error) are flagged as having label issues.


Number of examples with this issue: 25
Overall dataset quality in terms of this issue: 0.7985

Examples representing most severe instances of this issue:
     is_label_issue  label_score given_label predicted_label
70             True     0.000537           F               A
90            False     0.000903           F               C
79            False     0.001743           F               C
106            True     0.001853           F               A
46             True     0.002121           F               A


---------------------- outlier issues ----------------------

About this issue:
        Examples that are very different from the rest of the dataset
    (i.e. potentially out-of-distribution or rare/anomalous instances).


Number of examples with this issue: 5
Overall dataset quality in terms of this issue: 0.3703

Examples representing most severe instances of this issue:
    is_outlier_issue  outlier_score
63              True   4.752463e-99
89              True   3.784418e-09
40              True   5.477741e-06
57              True   1.134230e-05
32              True   7.153555e-03


----------------------- null issues ------------------------

About this issue:
        Examples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 1.0000

Examples representing most severe instances of this issue:
    is_null_issue  null_score
0           False         1.0
97          False         1.0
96          False         1.0
95          False         1.0
94          False         1.0


------------------ near_duplicate issues -------------------

About this issue:
        A (near) duplicate issue refers to two or more examples in
    a dataset that are extremely similar to each other, relative
    to the rest of the dataset.  The examples flagged with this issue
    may be exactly duplicated, or lie atypically close together when
    represented as vectors (i.e. feature embeddings).


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.6254

Examples representing most severe instances of this issue:
    is_near_duplicate_issue  near_duplicate_score near_duplicate_sets  distance_to_nearest_neighbor
43                    False              0.143272                  []                      0.000016
93                    False              0.143272                  []                      0.000016
20                    False              0.146501                  []                      0.000016
83                    False              0.146501                  []                      0.000016
75                    False              0.161431                  []                      0.000018


---------------------- non_iid issues ----------------------

About this issue:
        Whether the dataset exhibits statistically significant
    violations of the IID assumption like:
    changepoints or shift, drift, autocorrelation, etc.
    The specific violation considered is whether the
    examples are ordered such that almost adjacent examples
    tend to have more similar feature values.


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.5240

Examples representing most severe instances of this issue:
     is_non_iid_issue  non_iid_score
12              False       0.765240
35              False       0.771221
28              False       0.801589
7               False       0.801652
112             False       0.810735

Additional Information:
p-value: 0.5240417899434826


------------------ class_imbalance issues ------------------

About this issue:
        Examples belonging to the most under-represented class in the dataset.

Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.0970

Examples representing most severe instances of this issue:
    is_class_imbalance_issue  class_imbalance_score given_label
88                     False               0.097015           F
70                     False               0.097015           F
2                      False               0.097015           F
71                     False               0.097015           F
46                     False               0.097015           F

Additional Information:
Rarest Class: NA


--------------- underperforming_group issues ---------------

About this issue:
        An underperforming group refers to a cluster of similar examples
    (i.e. a slice) in the dataset for which the ML model predictions
    are particularly poor (loss evaluation over this subpopulation is high).


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 1.0000

Examples representing most severe instances of this issue:
    is_underperforming_group_issue  underperforming_group_score
0                            False                          1.0
97                           False                          1.0
96                           False                          1.0
95                           False                          1.0
94                           False                          1.0
</pre></div></div>
</div>
<p>Datalab automatically audits our dataset for various common issues. The report above indicates many label issues in our data.</p>
<p>We can see which examples are estimated to be mislabeled (as well as a numeric quality score quantifying how likely their label is correct) via the <code class="docutils literal notranslate"><span class="pre">get_issues()</span></code> method. To review the most likely label errors, we sort our data by the <code class="docutils literal notranslate"><span class="pre">label_score</span></code> (a lower score represents that the label is less likely to be correct).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_label_issue_results</span> <span class="o">=</span> <span class="n">test_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">test_label_issues_ordered</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">test_label_issue_results</span><span class="p">)</span>
<span class="n">test_label_issues_ordered</span> <span class="o">=</span> <span class="n">test_label_issues_ordered</span><span class="p">[</span><span class="n">test_label_issue_results</span><span class="p">[</span><span class="s2">&quot;is_label_issue&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">]</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;label_score&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">test_label_issues_ordered</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
    stud_ID  exam_1  exam_2  exam_3                           notes  \
70   2bd759    93.0    79.0    97.0         great participation +10
106  34ccdd    90.0   100.0    89.0         great participation +10
46   bb3bab    97.0    88.0    74.0         great participation +10
103  bf1b14    66.0    83.0    96.0                             NaN
97   4787de    73.0    84.0    68.0         great participation +10
92   865cbd    95.0    87.0    82.0     missed class frequently -10
72   32d53f    71.0    78.0    80.0    great final presentation +10
22   5b2f76    99.0    86.0    95.0     missed class frequently -10
3    28f8b4    67.0    82.0    98.0                             NaN
69   df814d    78.0    85.0    84.0                             NaN
45   f17261    95.0    88.0    69.0                             NaN
98   1db3ff    95.0    81.0    76.0                             NaN
109  ded944    86.0    85.0    89.0                             NaN
124  343dd3    67.0    87.0    95.0  missed homework frequently -10
20   8d904d    73.0    73.0    76.0     missed class frequently -10
83   e4f0d5    86.0    85.0    89.0  missed homework frequently -10
120  d6d208    97.0    97.0    92.0  missed homework frequently -10
29   76c083    91.0    92.0    74.0                             NaN
63   d030b5    91.0     0.0    94.0      cheated on exam, gets 0pts
23   695f96    96.0    69.0    92.0                             NaN
84   745c23    89.0    95.0    72.0                             NaN
10   13b36e    98.0    92.0    96.0                             NaN
89   71d7b9    99.0    53.0    76.0                             NaN
127  5ba892    98.0    97.0    93.0                             NaN
43   9f0216    94.0    79.0    89.0                             NaN

    noisy_letter_grade  is_label_issue  label_score given_label  \
70                   F            True     0.000537           F
106                  F            True     0.001853           F
46                   F            True     0.002121           F
103                  D            True     0.003628           D
97                   D            True     0.004006           D
92                   A            True     0.004031           A
72                   D            True     0.007930           D
22                   B            True     0.013226           B
3                    D            True     0.015255           D
69                   B            True     0.017692           B
45                   D            True     0.019767           D
98                   B            True     0.036197           B
109                  D            True     0.054746           D
124                  C            True     0.055110           C
20                   D            True     0.062675           D
83                   C            True     0.112695           C
120                  B            True     0.121059           B
29                   B            True     0.171280           B
63                   D            True     0.181689           D
23                   B            True     0.208001           B
84                   B            True     0.275028           B
10                   A            True     0.346032           A
89                   C            True     0.396350           C
127                  A            True     0.401493           A
43                   B            True     0.474349           B

    predicted_label
70                A
106               A
46                A
103               F
97                B
92                C
72                A
22                A
3                 B
69                D
45                B
98                D
109               B
124               B
20                B
83                A
120               A
29                D
63                B
23                D
84                D
10                F
89                D
127               F
43                D
</pre></div></div>
</div>
<p>The dataframe above shows the original label (<code class="docutils literal notranslate"><span class="pre">given_label</span></code>) for examples that cleanlab finds most likely to be mislabeled, as well as an alternative <code class="docutils literal notranslate"><span class="pre">predicted_label</span></code> for each example. These examples have likely been labeled incorrectly and should be carefully re-examined. After manually inspecting our label issues above, we can add the indices for the label issues we want to remove from our data to our previously defined list.</p>
<p>Remember to inspect and <strong>manually</strong> handle issues detected in your test data and to <strong>avoid</strong> handling them automatically. Otherwise you risk misleading model evaluations!</p>
<p>In this case, we manually found that the first 11 label issues with lowest <code class="docutils literal notranslate"><span class="pre">label_score</span></code> correspond to real label errors. We’ll drop those data points from our test set, in order to curate a cleaner test set. Here we solely address mislabeled data for brevity, but you can similarly address other issues detected in your test data to ensure the most reliable model evaluation.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indices_to_drop_from_test_data</span> <span class="o">=</span> <span class="n">test_label_issues_ordered</span><span class="o">.</span><span class="n">index</span><span class="p">[:</span><span class="mi">11</span><span class="p">]</span>  <span class="c1"># found by manually inspecting test_label_issues_ordered</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_test_cleaned</span> <span class="o">=</span> <span class="n">df_test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_to_drop_from_test_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_features</span> <span class="o">=</span> <span class="n">test_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_to_drop_from_test_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">test_labels</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">indices_to_drop_from_test_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-noisy-training-data">
<h2>Use clean test data to evaluate the performance of model trained on noisy training data<a class="headerlink" href="#Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-noisy-training-data" title="Permalink to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
<span class="n">acc_original</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">preds</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Accuracy of model fit to noisy training data, measured on clean test data: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">acc_original</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Accuracy of model fit to noisy training data, measured on clean test data: 78.0%
</pre></div></div>
</div>
<p>Although curating clean test data does not directly help train a better ML model, more reliable model evaluation can improve your overall ML project. For instance, clean test data enables better informed decisions regarding when to deploy a model and better model/hyperparameter selection. While manually curating data can be tedious, <a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab Studio</a> offers data correction interfaces to streamline this work.</p>
<section id="6.-Check-for-issues-in-training-data-and-algorithmically-correct-them">
<h3>6. Check for issues in training data and algorithmically correct them<a class="headerlink" href="#6.-Check-for-issues-in-training-data-and-algorithmically-correct-them" title="Permalink to this heading">#</a></h3>
<p>To run Datalab on our training set, we first compute out-of-sample predicted probabilities for our training data (via cross-validation).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="n">num_crossval_folds</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">pred_probs</span> <span class="o">=</span> <span class="n">cross_val_predict</span><span class="p">(</span>
    <span class="n">clf</span><span class="p">,</span>
    <span class="n">train_features</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">num_crossval_folds</span><span class="p">,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;predict_proba&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Based on these ML model outputs, we similarly run Datalab to detect issues in our training data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_features_array</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>  <span class="c1"># could alternatively be model embeddings</span>

<span class="n">train_lab</span> <span class="o">=</span> <span class="n">Datalab</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">df_train</span><span class="p">,</span> <span class="n">label_name</span><span class="o">=</span><span class="s2">&quot;noisy_letter_grade&quot;</span><span class="p">,</span> <span class="n">task</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">)</span>
<span class="n">train_lab</span><span class="o">.</span><span class="n">find_issues</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">train_features_array</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">)</span>
<span class="n">train_lab</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">show_summary_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">show_all_issues</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Finding null issues ...
Finding label issues ...
Finding outlier issues ...
Finding near_duplicate issues ...
Finding non_iid issues ...
Finding class_imbalance issues ...
Finding underperforming_group issues ...

Audit complete. 318 issues found in the dataset.
Dataset Information: num_examples: 601, num_classes: 5

Here is a summary of various issues found in your data:

           issue_type    score  num_issues
                label 0.740433         175
              outlier 0.344154          72
       near_duplicate 0.588290          71
                 null 1.000000           0
              non_iid 0.437267           0
      class_imbalance 0.146423           0
underperforming_group 0.977223           0

(Note: A lower score indicates a more severe issue across all examples in the dataset.)

Learn about each issue: https://docs.cleanlab.ai/stable/cleanlab/datalab/guide/issue_type_description.html
See which examples in your dataset exhibit each issue via: `datalab.get_issues(&lt;ISSUE_NAME&gt;)`

Data indices corresponding to top examples of each issue are shown below.


----------------------- label issues -----------------------

About this issue:
        Examples whose given label is estimated to be potentially incorrect
    (e.g. due to annotation error) are flagged as having label issues.


Number of examples with this issue: 175
Overall dataset quality in terms of this issue: 0.7404

Examples representing most severe instances of this issue:
     is_label_issue  label_score given_label predicted_label
162            True     0.000072           F               A
348            True     0.000161           B               D
232            True     0.000256           F               B
205            True     0.000458           F               A
400            True     0.000738           C               D


---------------------- outlier issues ----------------------

About this issue:
        Examples that are very different from the rest of the dataset
    (i.e. potentially out-of-distribution or rare/anomalous instances).


Number of examples with this issue: 72
Overall dataset quality in terms of this issue: 0.3442

Examples representing most severe instances of this issue:
     is_outlier_issue  outlier_score
588              True   2.358961e-46
336              True   2.490911e-36
269              True   3.122475e-28
321              True   5.374139e-22
311              True   1.358617e-17


------------------ near_duplicate issues -------------------

About this issue:
        A (near) duplicate issue refers to two or more examples in
    a dataset that are extremely similar to each other, relative
    to the rest of the dataset.  The examples flagged with this issue
    may be exactly duplicated, or lie atypically close together when
    represented as vectors (i.e. feature embeddings).


Number of examples with this issue: 71
Overall dataset quality in terms of this issue: 0.5883

Examples representing most severe instances of this issue:
     is_near_duplicate_issue  near_duplicate_score                       near_duplicate_sets  distance_to_nearest_neighbor
600                     True                   0.0  [592, 593, 594, 595, 596, 597, 598, 599]                  0.000000e+00
221                     True                   0.0                                     [500]                  0.000000e+00
222                     True                   0.0                                [315, 332]                  7.791060e-09
243                     True                   0.0                                     [540]                  2.379106e-09
599                     True                   0.0  [592, 593, 594, 595, 596, 597, 598, 600]                  0.000000e+00


----------------------- null issues ------------------------

About this issue:
        Examples identified with the null issue correspond to rows that have null/missing values across all feature columns (i.e. the entire row is missing values).


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 1.0000

Examples representing most severe instances of this issue:
     is_null_issue  null_score
0            False         1.0
396          False         1.0
397          False         1.0
398          False         1.0
399          False         1.0


---------------------- non_iid issues ----------------------

About this issue:
        Whether the dataset exhibits statistically significant
    violations of the IID assumption like:
    changepoints or shift, drift, autocorrelation, etc.
    The specific violation considered is whether the
    examples are ordered such that almost adjacent examples
    tend to have more similar feature values.


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.4373

Examples representing most severe instances of this issue:
     is_non_iid_issue  non_iid_score
165             False       0.550374
598             False       0.627357
599             False       0.627496
597             False       0.627502
600             False       0.627919

Additional Information:
p-value: 0.43726734378061227


------------------ class_imbalance issues ------------------

About this issue:
        Examples belonging to the most under-represented class in the dataset.

Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.1464

Examples representing most severe instances of this issue:
     is_class_imbalance_issue  class_imbalance_score given_label
321                     False               0.146423           F
112                     False               0.146423           F
506                     False               0.146423           F
393                     False               0.146423           F
508                     False               0.146423           F

Additional Information:
Rarest Class: NA


--------------- underperforming_group issues ---------------

About this issue:
        An underperforming group refers to a cluster of similar examples
    (i.e. a slice) in the dataset for which the ML model predictions
    are particularly poor (loss evaluation over this subpopulation is high).


Number of examples with this issue: 0
Overall dataset quality in terms of this issue: 0.9772

Examples representing most severe instances of this issue:
     is_underperforming_group_issue  underperforming_group_score
0                             False                     0.977223
402                           False                     0.977223
401                           False                     0.977223
400                           False                     0.977223
399                           False                     0.977223
</pre></div></div>
</div>
<p>Now instead of manually inspecting the detected issues in our training data, we will <strong>automatically filter</strong> all data points out of the training set that cleanlab has flagged as being likely mislabeled, outliers, or near duplicates. Unlike the test data which cannot be blindly auto-curated because we must ensure reliable model evaluation, the training data can be more aggressively modified as long as we’re able to faithfully evaluate the resulting fitted model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_issue_results</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">)</span>
<span class="n">label_issues_idx</span> <span class="o">=</span> <span class="n">label_issue_results</span><span class="p">[</span><span class="n">label_issue_results</span><span class="p">[</span><span class="s2">&quot;is_label_issue&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">label_issues_idx</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Index([  2,   7,  12,  21,  23,  25,  26,  29,  32,  33,
       ...
       566, 568, 571, 572, 574, 576, 578, 585, 587, 590],
      dtype=&#39;int64&#39;, length=175)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">near_duplicates</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;near_duplicate&quot;</span><span class="p">)</span>
<span class="n">near_duplicates_idx</span> <span class="o">=</span> <span class="n">near_duplicates</span><span class="p">[</span><span class="n">near_duplicates</span><span class="p">[</span><span class="s2">&quot;is_near_duplicate_issue&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">near_duplicates_idx</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Index([ 19,  29,  41,  43,  71,  83,  85,  88, 101, 106, 117, 122, 146, 155,
       156, 173, 187, 196, 221, 222, 224, 243, 252, 272, 277, 279, 288, 292,
       300, 315, 329, 332, 342, 352, 363, 365, 366, 384, 388, 393, 394, 397,
       404, 431, 436, 474, 480, 494, 500, 506, 508, 515, 516, 536, 537, 539,
       540, 542, 559, 575, 576, 582, 592, 593, 594, 595, 596, 597, 598, 599,
       600],
      dtype=&#39;int64&#39;)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">outliers</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;outlier&quot;</span><span class="p">)</span>
<span class="n">outliers_idx</span> <span class="o">=</span> <span class="n">outliers</span><span class="p">[</span><span class="n">outliers</span><span class="p">[</span><span class="s2">&quot;is_outlier_issue&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="kc">True</span><span class="p">]</span><span class="o">.</span><span class="n">index</span>
<span class="n">outliers_idx</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Index([  0,   1,   3,   7,  26,  46,  52,  77,  89,  99, 101, 131, 132, 143,
       153, 155, 159, 163, 193, 194, 195, 199, 208, 212, 240, 241, 242, 247,
       256, 269, 287, 295, 299, 307, 311, 313, 321, 330, 336, 337, 340, 350,
       361, 378, 379, 388, 392, 419, 432, 444, 476, 479, 484, 485, 489, 492,
       504, 510, 511, 522, 523, 535, 543, 546, 547, 567, 571, 578, 579, 585,
       588, 591],
      dtype=&#39;int64&#39;)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">idx_to_drop</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">label_issues_idx</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">near_duplicates_idx</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">outliers_idx</span><span class="p">)))</span>
<span class="nb">len</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
276
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_train_curated</span> <span class="o">=</span> <span class="n">df_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_features</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_labels</span> <span class="o">=</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="7.-Train-model-on-cleaned-training-data">
<h3>7. Train model on cleaned training data<a class="headerlink" href="#7.-Train-model-on-cleaned-training-data" title="Permalink to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clean_clf</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">tree_method</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span> <span class="n">enable_categorical</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">clean_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=True, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;XGBClassifier<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=True, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=None,
              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div></div>
</div>
<p><strong>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</strong></p>
</section>
</section>
<section id="Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-cleaned-training-data">
<h2>Use clean test data to evaluate the performance of model trained on cleaned training data<a class="headerlink" href="#Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-cleaned-training-data" title="Permalink to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clean_preds</span> <span class="o">=</span> <span class="n">clean_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
<span class="n">acc_clean</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">clean_preds</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Accuracy of model fit to clean training data, measured on clean test data: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">acc_clean</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Accuracy of model fit to clean training data, measured on clean test data: 78.9%
</pre></div></div>
</div>
<p>Although this simple data filtering may not be the maximally effective training set curation (particularly if the initial ML model was poor-quality and hence the detected issues are inaccurate), we can at least faithfully assess its effect using our clean test data. In this case, we do see the resulting ML model has improved, even with this simple training data filtering.</p>
<section id="8.-Identifying-better-training-data-curation-strategies-via-hyperparameter-optimization-techniques">
<h3>8. Identifying better training data curation strategies via hyperparameter optimization techniques<a class="headerlink" href="#8.-Identifying-better-training-data-curation-strategies-via-hyperparameter-optimization-techniques" title="Permalink to this heading">#</a></h3>
<p>Thus far, we’ve seen how to detect issues in the training and test data to improve model training and evaluation. While we should manually curate the test data to ensure faithful evaluation, we are free to algorithmically curate the training data. Since the simple filtering strategy above is not necessarily optimal, here we consider how to identify a better algorithmic curation strategy. Note however that the <strong>best strategy</strong> will be a hybrid of automated and manual data corrections, as you can
efficiently do via the data correction interface in <a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab Studio</a>.</p>
<p>Above we made basic training data edits to improve test performance, where each one of these data edits can be quantitatively parameterized (eg. what fraction of each issue to filter from the dataset). We can use (hyper)parameter-tuning techniques to automatically search for combinations of training data edits that result in particularly accurate models. Here we apply this hyperparameter optimization to maximize test set performance for brevity, but in practice you should use a separate
<em>validation</em> set (which you can curate similarly to the test data in this tutorial, in order to ensure reliable model evaluations).</p>
<p>We define a dict to parameterize our dataset changes:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">default_edit_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;drop_label_issue&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s2">&quot;drop_outlier&quot;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s2">&quot;drop_near_duplicate&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="p">}</span>
</pre></div>
</div>
</div>
<p>These example values translate into the following training data edits:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">drop_label_issue</span></code>: We filter the top 50% of the datapoints flagged with label issues (with most severe label score).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_outlier</span></code>: We filter the top 50% most severe outliers based on outlier score (amongst the set of flagged outliers).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_near_duplicate</span></code>: We drop <strong>extra copies</strong> of the top 20% of near duplicates (based on near duplicate score). Amongst each set of near duplicates, we keep the data point that has highest self-confidence score for its given label.</p></li>
</ul>
<p>We will search over various values for these parameters, fit a model to each corresponding training dataset edited based on the parameter values, and see which combination of values yields the best model.</p>
<p><strong>Note:</strong> Datalab detects other issue types that could also be considered in this algorithmic data curation.</p>
<p>To more easily apply candidate training data edits, we first sort our data points flagged with each issue type based on the corresponding severity score:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_issues</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;label&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_label_issue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;label_score&quot;</span><span class="p">)</span>
<span class="n">near_duplicates</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;near_duplicate&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_near_duplicate_issue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;near_duplicate_score&quot;</span><span class="p">)</span>
<span class="n">outliers</span> <span class="o">=</span> <span class="n">train_lab</span><span class="o">.</span><span class="n">get_issues</span><span class="p">(</span><span class="s2">&quot;outlier&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;is_outlier_issue&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;outlier_score&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We introduce a <code class="docutils literal notranslate"><span class="pre">edit_data</span></code> function to implement candidate training data edits, fit a model to the edited training set, and evaluate it on our cleaned test data (can skip these details).</p>
<details><summary><p>See the implementation of <code class="docutils literal notranslate"><span class="pre">edit_data</span></code> <strong>(click to expand)</strong></p>
</summary><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note: This pulldown content is for docs.cleanlab.ai, if running on local Jupyter or Colab, please ignore it.</span>

<span class="k">def</span> <span class="nf">edit_data</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">,</span> <span class="n">near_duplicates</span><span class="p">,</span> <span class="n">outliers</span><span class="p">,</span>
              <span class="n">drop_label_issue</span><span class="p">,</span> <span class="n">drop_near_duplicate</span><span class="p">,</span> <span class="n">drop_outlier</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Edits the training data by dropping a specified percentage of data points identified as label issues,</span>
<span class="sd">    near duplicates, and outliers based on the full datasets provided for each issue type.</span>

<span class="sd">    Args:</span>
<span class="sd">        train_features (pd.DataFrame): DataFrame containing the training features.</span>
<span class="sd">        train_labels (pd.Series): Series containing the training labels.</span>
<span class="sd">        label_issues (pd.DataFrame): DataFrame containing data points with label issues.</span>
<span class="sd">        near_duplicates (pd.DataFrame): DataFrame containing data points identified as near duplicates.</span>
<span class="sd">        outliers (pd.DataFrame): DataFrame containing data points identified as outliers.</span>
<span class="sd">        drop_label_issue (float): Percentage of label issue data points to drop.</span>
<span class="sd">        drop_near_duplicate (float): Percentage of near duplicate data points to drop.</span>
<span class="sd">        drop_outlier (float): Percentage of outlier data points to drop.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: The cleaned training features.</span>
<span class="sd">        pd.Series: The cleaned training labels.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Extract indices for each type of issue</span>
    <span class="n">label_issues_idx</span> <span class="o">=</span> <span class="n">label_issues</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">near_duplicates_idx</span> <span class="o">=</span> <span class="n">near_duplicates</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="n">outliers_idx</span> <span class="o">=</span> <span class="n">outliers</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="c1"># Calculate the number of each type of data point to drop except near duplicates, which requires separate logic</span>
    <span class="n">num_label_issues_to_drop</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">label_issues_idx</span><span class="p">)</span> <span class="o">*</span> <span class="n">drop_label_issue</span><span class="p">)</span>
    <span class="n">num_outliers_to_drop</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">outliers_idx</span><span class="p">)</span> <span class="o">*</span> <span class="n">drop_outlier</span><span class="p">)</span>

    <span class="c1"># Calculate number of near duplicates to drop</span>
    <span class="c1"># Assuming the &#39;near_duplicate_sets&#39; are lists of indices (integers) of near duplicates</span>
    <span class="n">clusters</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">near_duplicates_idx</span><span class="p">:</span>
        <span class="c1"># Create a set for each cluster, add the current index to its near duplicate set</span>
        <span class="n">cluster</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">near_duplicates</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;near_duplicate_sets&#39;</span><span class="p">])</span>
        <span class="n">cluster</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
        <span class="n">clusters</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>

    <span class="c1"># Deduplicate clusters by converting the list of sets to a set of frozensets</span>
    <span class="n">unique_clusters</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">frozenset</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">)</span>

    <span class="c1"># If you need the unique clusters back in list of lists format:</span>
    <span class="n">unique_clusters_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span> <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">unique_clusters</span><span class="p">]</span>

    <span class="n">near_duplicates_idx_to_drop</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">unique_clusters_list</span><span class="p">:</span>
        <span class="c1"># Calculate the number of rows to drop, ensuring at least one datapoint remains</span>
        <span class="n">n_drop</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span> <span class="o">*</span> <span class="n">drop_near_duplicate</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Drop at least k% or 1 row</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">n_drop</span><span class="p">:</span>  <span class="c1"># Ensure we keep at least one datapoint</span>
            <span class="c1"># Randomly select datapoints to drop</span>
            <span class="n">drops</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">cluster</span><span class="p">,</span> <span class="n">n_drop</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># If the cluster is too small, adjust the number to keep at least one datapoint</span>
            <span class="n">drops</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">cluster</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Keep at least one</span>
        <span class="n">near_duplicates_idx_to_drop</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">drops</span><span class="p">)</span>

    <span class="c1"># Determine the specific indices to drop</span>
    <span class="n">label_issues_idx_to_drop</span> <span class="o">=</span> <span class="n">label_issues_idx</span><span class="p">[:</span><span class="n">num_label_issues_to_drop</span><span class="p">]</span>
    <span class="n">outliers_idx_to_drop</span> <span class="o">=</span> <span class="n">outliers_idx</span><span class="p">[:</span><span class="n">num_outliers_to_drop</span><span class="p">]</span>

    <span class="c1"># Combine the indices to drop</span>
    <span class="n">idx_to_drop</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">label_issues_idx_to_drop</span> <span class="o">+</span> <span class="n">near_duplicates_idx_to_drop</span> <span class="o">+</span> <span class="n">outliers_idx_to_drop</span><span class="p">))</span>

    <span class="c1"># Drop the rows from the training data</span>
    <span class="n">train_features_cleaned</span> <span class="o">=</span> <span class="n">train_features</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">train_labels_cleaned</span> <span class="o">=</span> <span class="n">train_labels</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">idx_to_drop</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_features_cleaned</span><span class="p">,</span> <span class="n">train_labels_cleaned</span>
</pre></div>
</div>
</details><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>

<span class="c1"># List of possible values for each data edit parameter to search over (finer grid will yield better results but longer runtimes)</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;drop_label_issue&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span>
    <span class="s1">&#39;drop_near_duplicate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="s1">&#39;drop_outlier&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># Generate all combinations of parameters</span>
<span class="n">param_combinations</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">product</span><span class="p">(</span><span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;drop_label_issue&#39;</span><span class="p">],</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;drop_near_duplicate&#39;</span><span class="p">],</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;drop_outlier&#39;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_score</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="kc">None</span>

<span class="k">for</span> <span class="n">drop_label_issue</span><span class="p">,</span> <span class="n">drop_near_duplicate</span><span class="p">,</span> <span class="n">drop_outlier</span> <span class="ow">in</span> <span class="n">param_combinations</span><span class="p">:</span>
    <span class="c1"># Preprocess the data for the current combination of parameters</span>
    <span class="n">train_features_preprocessed</span><span class="p">,</span> <span class="n">train_labels_preprocessed</span> <span class="o">=</span> <span class="n">edit_data</span><span class="p">(</span>
        <span class="n">train_features_v2</span><span class="p">,</span> <span class="n">train_labels_v2</span><span class="p">,</span> <span class="n">label_issues</span><span class="p">,</span> <span class="n">near_duplicates</span><span class="p">,</span> <span class="n">outliers</span><span class="p">,</span>
        <span class="n">drop_label_issue</span><span class="p">,</span> <span class="n">drop_near_duplicate</span><span class="p">,</span> <span class="n">drop_outlier</span><span class="p">)</span>

    <span class="c1"># Train and evaluate the model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">XGBClassifier</span><span class="p">(</span><span class="n">tree_method</span><span class="o">=</span><span class="s2">&quot;hist&quot;</span><span class="p">,</span> <span class="n">enable_categorical</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_features_preprocessed</span><span class="p">,</span> <span class="n">train_labels_preprocessed</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_features</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">predictions</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">))</span>

    <span class="c1"># Update the best score and parameters if the current model is better</span>
    <span class="k">if</span> <span class="n">accuracy</span> <span class="o">&gt;</span> <span class="n">best_score</span><span class="p">:</span>
        <span class="n">best_score</span> <span class="o">=</span> <span class="n">accuracy</span>
        <span class="n">best_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;drop_label_issue&#39;</span><span class="p">:</span> <span class="n">drop_label_issue</span><span class="p">,</span> <span class="s1">&#39;drop_near_duplicate&#39;</span><span class="p">:</span> <span class="n">drop_near_duplicate</span><span class="p">,</span> <span class="s1">&#39;drop_outlier&#39;</span><span class="p">:</span> <span class="n">drop_outlier</span><span class="p">}</span>

<span class="c1"># Print the best parameters and score</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best parameters found in search: </span><span class="si">{</span><span class="n">best_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Best parameters found in search: {&#39;drop_label_issue&#39;: 0.5, &#39;drop_near_duplicate&#39;: 0.0, &#39;drop_outlier&#39;: 0.7}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;Accuracy of model fit to optimally cleaned training data, measured on clean test data: </span><span class="si">{</span><span class="nb">round</span><span class="p">(</span><span class="n">best_score</span><span class="o">*</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">%&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Accuracy of model fit to optimally cleaned training data, measured on clean test data: 82.1%
</pre></div></div>
</div>
</section>
<section id="9.-Conclusion">
<h3>9. Conclusion<a class="headerlink" href="#9.-Conclusion" title="Permalink to this heading">#</a></h3>
<p>This tutorial demonstrated how you can properly use cleanlab to improve your own ML model. When dealing with noisy data, you should <strong>first manually curate your test data to ensure reliable model evaluation</strong>. After that, you can <strong>algorithmically curate your training data</strong>. We demonstrated a simple hyperparameter tuning technique to identify effective training data edits that produce an accurate model. As well as how cleanlab can help catch fundamental problems in the overall train/test setup
like duplicates/leakage and data drift.</p>
<p>Note that we never evaluated different models with different test set versions (which does <strong>not</strong> yield meaningful comparisons). We curated the test data to be as high-quality as possible and then based all model evaluations on this fixed version of the test data.</p>
<p>For brevity, this tutorial focused mostly around label issues and data pruning strategies. For classification tasks where you already have high-quality test data and solely want to handle label errors in your training data: cleanlab’s <code class="docutils literal notranslate"><span class="pre">CleanLearning</span></code> class offers an <em>alternative</em> convenience method to <strong>train a robust ML model</strong>. You can achieve <strong>better results</strong> by considering additional data issues beyond label errors and curation strategies like fixing incorrect values – this is all
streamlined via the intelligent data correction interface of <a class="reference external" href="https://cleanlab.ai/blog/data-centric-ai/">Cleanlab Studio</a>.</p>
</section>
</section>
</section>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          <a class="next-page" href="clean_learning/index.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">CleanLearning Tutorials</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="datalab/workflows.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Miscellaneous workflows with Datalab</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Improving ML Performance via Data Curation with Train vs Test Splits</a><ul>
<li><a class="reference internal" href="#Why-did-you-make-this-tutorial?">Why did you make this tutorial?</a><ul>
<li><a class="reference internal" href="#1.-Install-dependencies">1. Install dependencies</a></li>
<li><a class="reference internal" href="#2.-Preprocess-the-data">2. Preprocess the data</a></li>
<li><a class="reference internal" href="#3.-Check-for-fundamental-problems-in-the-train/test-setup">3. Check for fundamental problems in the train/test setup</a></li>
<li><a class="reference internal" href="#4.-Train-model-with-original-(noisy)-training-data">4. Train model with original (noisy) training data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Compute-out-of-sample-predicted-probabilities-for-the-test-data-from-this-baseline-model">Compute out-of-sample predicted probabilities for the test data from this baseline model</a><ul>
<li><a class="reference internal" href="#5.-Check-for-issues-in-test-data-and-manually-address-them">5. Check for issues in test data and manually address them</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-noisy-training-data">Use clean test data to evaluate the performance of model trained on noisy training data</a><ul>
<li><a class="reference internal" href="#6.-Check-for-issues-in-training-data-and-algorithmically-correct-them">6. Check for issues in training data and algorithmically correct them</a></li>
<li><a class="reference internal" href="#7.-Train-model-on-cleaned-training-data">7. Train model on cleaned training data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Use-clean-test-data-to-evaluate-the-performance-of-model-trained-on-cleaned-training-data">Use clean test data to evaluate the performance of model trained on cleaned training data</a><ul>
<li><a class="reference internal" href="#8.-Identifying-better-training-data-curation-strategies-via-hyperparameter-optimization-techniques">8. Identifying better training data curation strategies via hyperparameter optimization techniques</a></li>
<li><a class="reference internal" href="#9.-Conclusion">9. Conclusion</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=2b91c5f0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/scripts/furo.js?v=32e29ea5"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=30646c52"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>